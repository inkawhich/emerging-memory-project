nbits:1
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018076 train_acc: 0.109375
[0/10][100/469] train_loss: 0.004523 train_acc: 0.829131
[0/10][200/469] train_loss: 0.002850 train_acc: 0.891947
[0/10][300/469] train_loss: 0.002180 train_acc: 0.917125
[0/10][400/469] train_loss: 0.001805 train_acc: 0.931051
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.139782 val_acc: 0.002600
AT dataset testing:[0/10] val_loss: 0.065574 val_acc: 0.000100
Clean dataset testing:[0/10] val_loss: 0.000421 val_acc: 0.983000
[1/10][0/469] train_loss: 0.000194 train_acc: 0.992188
[1/10][100/469] train_loss: 0.000468 train_acc: 0.982519
[1/10][200/469] train_loss: 0.000442 train_acc: 0.982976
[1/10][300/469] train_loss: 0.000429 train_acc: 0.983285
[1/10][400/469] train_loss: 0.000428 train_acc: 0.983109
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.183204 val_acc: 0.005200
AT dataset testing:[1/10] val_loss: 0.081834 val_acc: 0.000200
Clean dataset testing:[1/10] val_loss: 0.000384 val_acc: 0.984500
[2/10][0/469] train_loss: 0.000233 train_acc: 0.992188
[2/10][100/469] train_loss: 0.000257 train_acc: 0.989558
[2/10][200/469] train_loss: 0.000268 train_acc: 0.989078
[2/10][300/469] train_loss: 0.000281 train_acc: 0.988476
[2/10][400/469] train_loss: 0.000283 train_acc: 0.988349
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.185423 val_acc: 0.000200
AT dataset testing:[2/10] val_loss: 0.078644 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000248 val_acc: 0.989200
[3/10][0/469] train_loss: 0.000087 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000185 train_acc: 0.992806
[3/10][200/469] train_loss: 0.000186 train_acc: 0.992071
[3/10][300/469] train_loss: 0.000200 train_acc: 0.992162
[3/10][400/469] train_loss: 0.000199 train_acc: 0.991993
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.195501 val_acc: 0.003300
AT dataset testing:[3/10] val_loss: 0.084490 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000216 val_acc: 0.991100
[4/10][0/469] train_loss: 0.000028 train_acc: 1.000000
[4/10][100/469] train_loss: 0.000117 train_acc: 0.995050
[4/10][200/469] train_loss: 0.000132 train_acc: 0.994714
[4/10][300/469] train_loss: 0.000147 train_acc: 0.994082
[4/10][400/469] train_loss: 0.000158 train_acc: 0.993766
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.234993 val_acc: 0.002300
AT dataset testing:[4/10] val_loss: 0.098277 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000265 val_acc: 0.989200
[5/10][0/469] train_loss: 0.000053 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000108 train_acc: 0.995900
[5/10][200/469] train_loss: 0.000135 train_acc: 0.994753
[5/10][300/469] train_loss: 0.000133 train_acc: 0.994498
[5/10][400/469] train_loss: 0.000130 train_acc: 0.994506
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.248812 val_acc: 0.000800
AT dataset testing:[5/10] val_loss: 0.104470 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000218 val_acc: 0.992000
[6/10][0/469] train_loss: 0.000468 train_acc: 0.976562
[6/10][100/469] train_loss: 0.000096 train_acc: 0.995591
[6/10][200/469] train_loss: 0.000100 train_acc: 0.995686
[6/10][300/469] train_loss: 0.000096 train_acc: 0.995977
[6/10][400/469] train_loss: 0.000096 train_acc: 0.995889
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.268691 val_acc: 0.014300
AT dataset testing:[6/10] val_loss: 0.115242 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000283 val_acc: 0.989000
[7/10][0/469] train_loss: 0.000017 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000098 train_acc: 0.995823
[7/10][200/469] train_loss: 0.000091 train_acc: 0.996269
[7/10][300/469] train_loss: 0.000093 train_acc: 0.996366
[7/10][400/469] train_loss: 0.000089 train_acc: 0.996415
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.317737 val_acc: 0.003600
AT dataset testing:[7/10] val_loss: 0.131245 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000240 val_acc: 0.990600
[8/10][0/469] train_loss: 0.000006 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000058 train_acc: 0.997061
[8/10][200/469] train_loss: 0.000075 train_acc: 0.996657
[8/10][300/469] train_loss: 0.000083 train_acc: 0.996392
[8/10][400/469] train_loss: 0.000078 train_acc: 0.996610
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.333078 val_acc: 0.003400
AT dataset testing:[8/10] val_loss: 0.137761 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000234 val_acc: 0.991600
[9/10][0/469] train_loss: 0.000091 train_acc: 0.992188
[9/10][100/469] train_loss: 0.000072 train_acc: 0.996906
[9/10][200/469] train_loss: 0.000061 train_acc: 0.997629
[9/10][300/469] train_loss: 0.000058 train_acc: 0.997716
[9/10][400/469] train_loss: 0.000069 train_acc: 0.997175
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.344460 val_acc: 0.007200
AT dataset testing:[9/10] val_loss: 0.139128 val_acc: 0.000200
Clean dataset testing:[9/10] val_loss: 0.000292 val_acc: 0.990800
nbits:2
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.017968 train_acc: 0.039062
[0/10][100/469] train_loss: 0.004449 train_acc: 0.833926
[0/10][200/469] train_loss: 0.002809 train_acc: 0.894590
[0/10][300/469] train_loss: 0.002150 train_acc: 0.919072
[0/10][400/469] train_loss: 0.001778 train_acc: 0.932376
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.263127 val_acc: 0.013900
AT dataset testing:[0/10] val_loss: 0.066276 val_acc: 0.000600
Clean dataset testing:[0/10] val_loss: 0.000381 val_acc: 0.983700
[1/10][0/469] train_loss: 0.000599 train_acc: 0.984375
[1/10][100/469] train_loss: 0.000419 train_acc: 0.983524
[1/10][200/469] train_loss: 0.000442 train_acc: 0.982976
[1/10][300/469] train_loss: 0.000427 train_acc: 0.983311
[1/10][400/469] train_loss: 0.000421 train_acc: 0.983498
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.377687 val_acc: 0.017000
AT dataset testing:[1/10] val_loss: 0.085269 val_acc: 0.000000
Clean dataset testing:[1/10] val_loss: 0.000297 val_acc: 0.987900
[2/10][0/469] train_loss: 0.000454 train_acc: 0.976562
[2/10][100/469] train_loss: 0.000308 train_acc: 0.988011
[2/10][200/469] train_loss: 0.000308 train_acc: 0.987523
[2/10][300/469] train_loss: 0.000295 train_acc: 0.987853
[2/10][400/469] train_loss: 0.000294 train_acc: 0.987921
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.436024 val_acc: 0.038000
AT dataset testing:[2/10] val_loss: 0.089511 val_acc: 0.001600
Clean dataset testing:[2/10] val_loss: 0.000264 val_acc: 0.988600
[3/10][0/469] train_loss: 0.000094 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000204 train_acc: 0.992420
[3/10][200/469] train_loss: 0.000207 train_acc: 0.991954
[3/10][300/469] train_loss: 0.000199 train_acc: 0.992188
[3/10][400/469] train_loss: 0.000204 train_acc: 0.991993
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.018190 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.457256 val_acc: 0.037900
AT dataset testing:[3/10] val_loss: 0.090852 val_acc: 0.000100
Clean dataset testing:[3/10] val_loss: 0.000268 val_acc: 0.987900
[4/10][0/469] train_loss: 0.000545 train_acc: 0.976562
[4/10][100/469] train_loss: 0.000153 train_acc: 0.993967
[4/10][200/469] train_loss: 0.000155 train_acc: 0.993509
[4/10][300/469] train_loss: 0.000155 train_acc: 0.993797
[4/10][400/469] train_loss: 0.000163 train_acc: 0.993395
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.018450 val_acc: 0.098000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.525183 val_acc: 0.040500
AT dataset testing:[4/10] val_loss: 0.099571 val_acc: 0.000300
Clean dataset testing:[4/10] val_loss: 0.000231 val_acc: 0.990300
[5/10][0/469] train_loss: 0.000097 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000124 train_acc: 0.995204
[5/10][200/469] train_loss: 0.000127 train_acc: 0.994908
[5/10][300/469] train_loss: 0.000132 train_acc: 0.994653
[5/10][400/469] train_loss: 0.000140 train_acc: 0.994116
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.018550 val_acc: 0.046700
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.601356 val_acc: 0.076600
AT dataset testing:[5/10] val_loss: 0.115581 val_acc: 0.000700
Clean dataset testing:[5/10] val_loss: 0.000223 val_acc: 0.990300
[6/10][0/469] train_loss: 0.000016 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000090 train_acc: 0.996983
[6/10][200/469] train_loss: 0.000083 train_acc: 0.996657
[6/10][300/469] train_loss: 0.000098 train_acc: 0.996003
[6/10][400/469] train_loss: 0.000098 train_acc: 0.995967
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.018646 val_acc: 0.033400
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.643211 val_acc: 0.089300
AT dataset testing:[6/10] val_loss: 0.123607 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000253 val_acc: 0.990300
[7/10][0/469] train_loss: 0.000035 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000081 train_acc: 0.997370
[7/10][200/469] train_loss: 0.000077 train_acc: 0.997163
[7/10][300/469] train_loss: 0.000083 train_acc: 0.996418
[7/10][400/469] train_loss: 0.000092 train_acc: 0.996142
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.018928 val_acc: 0.068300
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.644094 val_acc: 0.130900
AT dataset testing:[7/10] val_loss: 0.126644 val_acc: 0.000100
Clean dataset testing:[7/10] val_loss: 0.000206 val_acc: 0.992400
[8/10][0/469] train_loss: 0.000020 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000064 train_acc: 0.997215
[8/10][200/469] train_loss: 0.000071 train_acc: 0.996580
[8/10][300/469] train_loss: 0.000069 train_acc: 0.996652
[8/10][400/469] train_loss: 0.000071 train_acc: 0.996707
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.019664 val_acc: 0.044600
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.633439 val_acc: 0.205900
AT dataset testing:[8/10] val_loss: 0.133765 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000229 val_acc: 0.991200
[9/10][0/469] train_loss: 0.000085 train_acc: 0.992188
[9/10][100/469] train_loss: 0.000040 train_acc: 0.998530
[9/10][200/469] train_loss: 0.000051 train_acc: 0.997979
[9/10][300/469] train_loss: 0.000062 train_acc: 0.997482
[9/10][400/469] train_loss: 0.000066 train_acc: 0.997331
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.020494 val_acc: 0.001500
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.662368 val_acc: 0.240900
AT dataset testing:[9/10] val_loss: 0.141380 val_acc: 0.000700
Clean dataset testing:[9/10] val_loss: 0.000228 val_acc: 0.990500
nbits:3
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018008 train_acc: 0.117188
[0/10][100/469] train_loss: 0.004417 train_acc: 0.834236
[0/10][200/469] train_loss: 0.002802 train_acc: 0.893074
[0/10][300/469] train_loss: 0.002117 train_acc: 0.919331
[0/10][400/469] train_loss: 0.001740 train_acc: 0.933662
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.021435 val_acc: 0.000600
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.476013 val_acc: 0.060500
AT dataset testing:[0/10] val_loss: 0.067882 val_acc: 0.000300
Clean dataset testing:[0/10] val_loss: 0.000484 val_acc: 0.980500
[1/10][0/469] train_loss: 0.000590 train_acc: 0.968750
[1/10][100/469] train_loss: 0.000408 train_acc: 0.983988
[1/10][200/469] train_loss: 0.000403 train_acc: 0.984258
[1/10][300/469] train_loss: 0.000402 train_acc: 0.983752
[1/10][400/469] train_loss: 0.000396 train_acc: 0.983927
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.025377 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.554046 val_acc: 0.133600
AT dataset testing:[1/10] val_loss: 0.075379 val_acc: 0.000200
Clean dataset testing:[1/10] val_loss: 0.000264 val_acc: 0.989700
[2/10][0/469] train_loss: 0.000099 train_acc: 1.000000
[2/10][100/469] train_loss: 0.000269 train_acc: 0.989558
[2/10][200/469] train_loss: 0.000272 train_acc: 0.989855
[2/10][300/469] train_loss: 0.000267 train_acc: 0.989774
[2/10][400/469] train_loss: 0.000266 train_acc: 0.989694
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.031165 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.573097 val_acc: 0.337900
AT dataset testing:[2/10] val_loss: 0.084048 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000283 val_acc: 0.989000
[3/10][0/469] train_loss: 0.000254 train_acc: 0.992188
[3/10][100/469] train_loss: 0.000193 train_acc: 0.991569
[3/10][200/469] train_loss: 0.000205 train_acc: 0.991527
[3/10][300/469] train_loss: 0.000206 train_acc: 0.991357
[3/10][400/469] train_loss: 0.000203 train_acc: 0.991739
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.039287 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.556052 val_acc: 0.496500
AT dataset testing:[3/10] val_loss: 0.089553 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000250 val_acc: 0.988900
[4/10][0/469] train_loss: 0.000089 train_acc: 1.000000
[4/10][100/469] train_loss: 0.000127 train_acc: 0.994972
[4/10][200/469] train_loss: 0.000133 train_acc: 0.994481
[4/10][300/469] train_loss: 0.000156 train_acc: 0.993693
[4/10][400/469] train_loss: 0.000153 train_acc: 0.993863
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.048151 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.454369 val_acc: 0.637000
AT dataset testing:[4/10] val_loss: 0.094756 val_acc: 0.000100
Clean dataset testing:[4/10] val_loss: 0.000205 val_acc: 0.991500
[5/10][0/469] train_loss: 0.000030 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000106 train_acc: 0.995823
[5/10][200/469] train_loss: 0.000108 train_acc: 0.995608
[5/10][300/469] train_loss: 0.000117 train_acc: 0.995224
[5/10][400/469] train_loss: 0.000121 train_acc: 0.995032
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.061586 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.396815 val_acc: 0.737100
AT dataset testing:[5/10] val_loss: 0.102699 val_acc: 0.000300
Clean dataset testing:[5/10] val_loss: 0.000200 val_acc: 0.992500
[6/10][0/469] train_loss: 0.000017 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000068 train_acc: 0.997138
[6/10][200/469] train_loss: 0.000091 train_acc: 0.995802
[6/10][300/469] train_loss: 0.000093 train_acc: 0.995821
[6/10][400/469] train_loss: 0.000096 train_acc: 0.995870
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.065859 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.653219 val_acc: 0.569600
AT dataset testing:[6/10] val_loss: 0.114773 val_acc: 0.000300
Clean dataset testing:[6/10] val_loss: 0.000237 val_acc: 0.991600
[7/10][0/469] train_loss: 0.000108 train_acc: 0.992188
[7/10][100/469] train_loss: 0.000078 train_acc: 0.996906
[7/10][200/469] train_loss: 0.000083 train_acc: 0.996152
[7/10][300/469] train_loss: 0.000080 train_acc: 0.996314
[7/10][400/469] train_loss: 0.000078 train_acc: 0.996532
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.095926 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.470965 val_acc: 0.734900
AT dataset testing:[7/10] val_loss: 0.128675 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000236 val_acc: 0.990500
[8/10][0/469] train_loss: 0.000009 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000054 train_acc: 0.998298
[8/10][200/469] train_loss: 0.000070 train_acc: 0.997474
[8/10][300/469] train_loss: 0.000069 train_acc: 0.997482
[8/10][400/469] train_loss: 0.000073 train_acc: 0.997311
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.090161 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.366987 val_acc: 0.798700
AT dataset testing:[8/10] val_loss: 0.119604 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000244 val_acc: 0.990900
[9/10][0/469] train_loss: 0.000025 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000048 train_acc: 0.998298
[9/10][200/469] train_loss: 0.000068 train_acc: 0.997201
[9/10][300/469] train_loss: 0.000064 train_acc: 0.997379
[9/10][400/469] train_loss: 0.000066 train_acc: 0.997331
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.115755 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.430648 val_acc: 0.821600
AT dataset testing:[9/10] val_loss: 0.142545 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000238 val_acc: 0.991500
nbits:4
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018038 train_acc: 0.101562
[0/10][100/469] train_loss: 0.004719 train_acc: 0.811262
[0/10][200/469] train_loss: 0.002930 train_acc: 0.884717
[0/10][300/469] train_loss: 0.002229 train_acc: 0.912479
[0/10][400/469] train_loss: 0.001833 train_acc: 0.927973
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.070114 val_acc: 0.000500
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.685261 val_acc: 0.260600
AT dataset testing:[0/10] val_loss: 0.065787 val_acc: 0.000400
Clean dataset testing:[0/10] val_loss: 0.000529 val_acc: 0.979300
[1/10][0/469] train_loss: 0.000537 train_acc: 0.968750
[1/10][100/469] train_loss: 0.000499 train_acc: 0.981204
[1/10][200/469] train_loss: 0.000455 train_acc: 0.982432
[1/10][300/469] train_loss: 0.000432 train_acc: 0.983077
[1/10][400/469] train_loss: 0.000408 train_acc: 0.983927
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.087362 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.527993 val_acc: 0.726800
AT dataset testing:[1/10] val_loss: 0.079943 val_acc: 0.000000
Clean dataset testing:[1/10] val_loss: 0.000333 val_acc: 0.985900
[2/10][0/469] train_loss: 0.000526 train_acc: 0.984375
[2/10][100/469] train_loss: 0.000315 train_acc: 0.988088
[2/10][200/469] train_loss: 0.000300 train_acc: 0.988145
[2/10][300/469] train_loss: 0.000303 train_acc: 0.987827
[2/10][400/469] train_loss: 0.000287 train_acc: 0.988369
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.094927 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.416474 val_acc: 0.871300
AT dataset testing:[2/10] val_loss: 0.087322 val_acc: 0.000100
Clean dataset testing:[2/10] val_loss: 0.000240 val_acc: 0.988800
[3/10][0/469] train_loss: 0.000313 train_acc: 0.984375
[3/10][100/469] train_loss: 0.000195 train_acc: 0.991259
[3/10][200/469] train_loss: 0.000211 train_acc: 0.991294
[3/10][300/469] train_loss: 0.000208 train_acc: 0.991591
[3/10][400/469] train_loss: 0.000199 train_acc: 0.991856
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.097026 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.398292 val_acc: 0.897600
AT dataset testing:[3/10] val_loss: 0.093544 val_acc: 0.000300
Clean dataset testing:[3/10] val_loss: 0.000244 val_acc: 0.989700
[4/10][0/469] train_loss: 0.000093 train_acc: 0.992188
[4/10][100/469] train_loss: 0.000155 train_acc: 0.993038
[4/10][200/469] train_loss: 0.000162 train_acc: 0.993315
[4/10][300/469] train_loss: 0.000158 train_acc: 0.993589
[4/10][400/469] train_loss: 0.000165 train_acc: 0.993181
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.103338 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.353703 val_acc: 0.922200
AT dataset testing:[4/10] val_loss: 0.101563 val_acc: 0.000200
Clean dataset testing:[4/10] val_loss: 0.000209 val_acc: 0.990900
[5/10][0/469] train_loss: 0.000007 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000132 train_acc: 0.994585
[5/10][200/469] train_loss: 0.000128 train_acc: 0.994675
[5/10][300/469] train_loss: 0.000127 train_acc: 0.994887
[5/10][400/469] train_loss: 0.000128 train_acc: 0.994623
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.111836 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.290207 val_acc: 0.942400
AT dataset testing:[5/10] val_loss: 0.109637 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000189 val_acc: 0.992300
[6/10][0/469] train_loss: 0.000031 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000097 train_acc: 0.996364
[6/10][200/469] train_loss: 0.000088 train_acc: 0.996346
[6/10][300/469] train_loss: 0.000088 train_acc: 0.996262
[6/10][400/469] train_loss: 0.000088 train_acc: 0.996337
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.132331 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.593919 val_acc: 0.907900
AT dataset testing:[6/10] val_loss: 0.128622 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000240 val_acc: 0.990800
[7/10][0/469] train_loss: 0.000012 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000089 train_acc: 0.996132
[7/10][200/469] train_loss: 0.000088 train_acc: 0.996035
[7/10][300/469] train_loss: 0.000089 train_acc: 0.996107
[7/10][400/469] train_loss: 0.000099 train_acc: 0.995753
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.141061 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.349814 val_acc: 0.945500
AT dataset testing:[7/10] val_loss: 0.130851 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000248 val_acc: 0.991200
[8/10][0/469] train_loss: 0.000002 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000084 train_acc: 0.995823
[8/10][200/469] train_loss: 0.000069 train_acc: 0.996813
[8/10][300/469] train_loss: 0.000074 train_acc: 0.996808
[8/10][400/469] train_loss: 0.000077 train_acc: 0.996785
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.155187 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.507957 val_acc: 0.929400
AT dataset testing:[8/10] val_loss: 0.145731 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000244 val_acc: 0.990700
[9/10][0/469] train_loss: 0.000006 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000054 train_acc: 0.997757
[9/10][200/469] train_loss: 0.000052 train_acc: 0.997746
[9/10][300/469] train_loss: 0.000053 train_acc: 0.997716
[9/10][400/469] train_loss: 0.000060 train_acc: 0.997487
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.155769 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.431181 val_acc: 0.944600
AT dataset testing:[9/10] val_loss: 0.149991 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000261 val_acc: 0.990200
nbits:5
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.017981 train_acc: 0.093750
[0/10][100/469] train_loss: 0.004499 train_acc: 0.829981
[0/10][200/469] train_loss: 0.002868 train_acc: 0.890547
[0/10][300/469] train_loss: 0.002175 train_acc: 0.916736
[0/10][400/469] train_loss: 0.001803 train_acc: 0.930701
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.066824 val_acc: 0.003400
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.551074 val_acc: 0.593400
AT dataset testing:[0/10] val_loss: 0.066644 val_acc: 0.004200
Clean dataset testing:[0/10] val_loss: 0.000524 val_acc: 0.979500
[1/10][0/469] train_loss: 0.001021 train_acc: 0.960938
[1/10][100/469] train_loss: 0.000460 train_acc: 0.981513
[1/10][200/469] train_loss: 0.000458 train_acc: 0.982198
[1/10][300/469] train_loss: 0.000437 train_acc: 0.983103
[1/10][400/469] train_loss: 0.000421 train_acc: 0.983362
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.072579 val_acc: 0.000600
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.423401 val_acc: 0.815900
AT dataset testing:[1/10] val_loss: 0.070332 val_acc: 0.000800
Clean dataset testing:[1/10] val_loss: 0.000296 val_acc: 0.987400
[2/10][0/469] train_loss: 0.000626 train_acc: 0.976562
[2/10][100/469] train_loss: 0.000280 train_acc: 0.989171
[2/10][200/469] train_loss: 0.000275 train_acc: 0.988961
[2/10][300/469] train_loss: 0.000278 train_acc: 0.988632
[2/10][400/469] train_loss: 0.000278 train_acc: 0.988914
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.096034 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.293448 val_acc: 0.916600
AT dataset testing:[2/10] val_loss: 0.091107 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000233 val_acc: 0.988900
[3/10][0/469] train_loss: 0.000029 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000225 train_acc: 0.991182
[3/10][200/469] train_loss: 0.000217 train_acc: 0.991410
[3/10][300/469] train_loss: 0.000211 train_acc: 0.991409
[3/10][400/469] train_loss: 0.000211 train_acc: 0.991467
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.097387 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.304205 val_acc: 0.931600
AT dataset testing:[3/10] val_loss: 0.096795 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000239 val_acc: 0.990500
[4/10][0/469] train_loss: 0.000050 train_acc: 1.000000
[4/10][100/469] train_loss: 0.000140 train_acc: 0.995668
[4/10][200/469] train_loss: 0.000151 train_acc: 0.994597
[4/10][300/469] train_loss: 0.000143 train_acc: 0.994420
[4/10][400/469] train_loss: 0.000151 train_acc: 0.994116
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.097648 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.295754 val_acc: 0.942900
AT dataset testing:[4/10] val_loss: 0.097508 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000269 val_acc: 0.989200
[5/10][0/469] train_loss: 0.000078 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000096 train_acc: 0.996055
[5/10][200/469] train_loss: 0.000095 train_acc: 0.995997
[5/10][300/469] train_loss: 0.000101 train_acc: 0.995769
[5/10][400/469] train_loss: 0.000121 train_acc: 0.995285
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.108334 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.342114 val_acc: 0.941700
AT dataset testing:[5/10] val_loss: 0.110931 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000277 val_acc: 0.988200
[6/10][0/469] train_loss: 0.000026 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000093 train_acc: 0.995978
[6/10][200/469] train_loss: 0.000097 train_acc: 0.995802
[6/10][300/469] train_loss: 0.000101 train_acc: 0.995691
[6/10][400/469] train_loss: 0.000107 train_acc: 0.995402
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.119915 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.251616 val_acc: 0.963600
AT dataset testing:[6/10] val_loss: 0.118864 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000212 val_acc: 0.991600
[7/10][0/469] train_loss: 0.000006 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000074 train_acc: 0.997215
[7/10][200/469] train_loss: 0.000087 train_acc: 0.996385
[7/10][300/469] train_loss: 0.000083 train_acc: 0.996600
[7/10][400/469] train_loss: 0.000089 train_acc: 0.996318
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.129725 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.291613 val_acc: 0.963300
AT dataset testing:[7/10] val_loss: 0.127444 val_acc: 0.000100
Clean dataset testing:[7/10] val_loss: 0.000226 val_acc: 0.991700
[8/10][0/469] train_loss: 0.000129 train_acc: 0.992188
[8/10][100/469] train_loss: 0.000077 train_acc: 0.997061
[8/10][200/469] train_loss: 0.000075 train_acc: 0.997124
[8/10][300/469] train_loss: 0.000080 train_acc: 0.996989
[8/10][400/469] train_loss: 0.000076 train_acc: 0.997039
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.139361 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.304632 val_acc: 0.966600
AT dataset testing:[8/10] val_loss: 0.137996 val_acc: 0.000300
Clean dataset testing:[8/10] val_loss: 0.000228 val_acc: 0.992200
[9/10][0/469] train_loss: 0.000003 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000075 train_acc: 0.996983
[9/10][200/469] train_loss: 0.000060 train_acc: 0.997396
[9/10][300/469] train_loss: 0.000057 train_acc: 0.997508
[9/10][400/469] train_loss: 0.000058 train_acc: 0.997428
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.159142 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.269642 val_acc: 0.973600
AT dataset testing:[9/10] val_loss: 0.156353 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000221 val_acc: 0.992500
nbits:6
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018018 train_acc: 0.085938
[0/10][100/469] train_loss: 0.004729 train_acc: 0.821395
[0/10][200/469] train_loss: 0.002917 train_acc: 0.889148
[0/10][300/469] train_loss: 0.002206 train_acc: 0.916087
[0/10][400/469] train_loss: 0.001817 train_acc: 0.930837
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.066711 val_acc: 0.000800
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.491579 val_acc: 0.760800
AT dataset testing:[0/10] val_loss: 0.066072 val_acc: 0.000500
Clean dataset testing:[0/10] val_loss: 0.000430 val_acc: 0.982200
[1/10][0/469] train_loss: 0.000426 train_acc: 0.976562
[1/10][100/469] train_loss: 0.000452 train_acc: 0.982364
[1/10][200/469] train_loss: 0.000454 train_acc: 0.982198
[1/10][300/469] train_loss: 0.000428 train_acc: 0.983051
[1/10][400/469] train_loss: 0.000409 train_acc: 0.983576
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.080203 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.463866 val_acc: 0.905700
AT dataset testing:[1/10] val_loss: 0.079626 val_acc: 0.000000
Clean dataset testing:[1/10] val_loss: 0.000289 val_acc: 0.988500
[2/10][0/469] train_loss: 0.000318 train_acc: 0.984375
[2/10][100/469] train_loss: 0.000248 train_acc: 0.989712
[2/10][200/469] train_loss: 0.000243 train_acc: 0.989506
[2/10][300/469] train_loss: 0.000250 train_acc: 0.989358
[2/10][400/469] train_loss: 0.000255 train_acc: 0.989421
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.086401 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.444754 val_acc: 0.927300
AT dataset testing:[2/10] val_loss: 0.086584 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000229 val_acc: 0.990100
[3/10][0/469] train_loss: 0.000245 train_acc: 0.992188
[3/10][100/469] train_loss: 0.000165 train_acc: 0.993580
[3/10][200/469] train_loss: 0.000197 train_acc: 0.991954
[3/10][300/469] train_loss: 0.000195 train_acc: 0.992291
[3/10][400/469] train_loss: 0.000200 train_acc: 0.992071
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.098843 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.493250 val_acc: 0.938700
AT dataset testing:[3/10] val_loss: 0.098160 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000199 val_acc: 0.991500
[4/10][0/469] train_loss: 0.000270 train_acc: 0.984375
[4/10][100/469] train_loss: 0.000122 train_acc: 0.995282
[4/10][200/469] train_loss: 0.000137 train_acc: 0.994831
[4/10][300/469] train_loss: 0.000149 train_acc: 0.994082
[4/10][400/469] train_loss: 0.000151 train_acc: 0.994155
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.113306 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.418095 val_acc: 0.961900
AT dataset testing:[4/10] val_loss: 0.113604 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000201 val_acc: 0.991400
[5/10][0/469] train_loss: 0.000043 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000117 train_acc: 0.995746
[5/10][200/469] train_loss: 0.000125 train_acc: 0.995141
[5/10][300/469] train_loss: 0.000125 train_acc: 0.995120
[5/10][400/469] train_loss: 0.000131 train_acc: 0.994876
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.116539 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.694826 val_acc: 0.947000
AT dataset testing:[5/10] val_loss: 0.115247 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000162 val_acc: 0.993400
[6/10][0/469] train_loss: 0.000242 train_acc: 0.984375
[6/10][100/469] train_loss: 0.000071 train_acc: 0.997061
[6/10][200/469] train_loss: 0.000101 train_acc: 0.996346
[6/10][300/469] train_loss: 0.000098 train_acc: 0.996211
[6/10][400/469] train_loss: 0.000097 train_acc: 0.996201
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.122020 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.482610 val_acc: 0.964700
AT dataset testing:[6/10] val_loss: 0.122087 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000224 val_acc: 0.991300
[7/10][0/469] train_loss: 0.000005 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000067 train_acc: 0.997679
[7/10][200/469] train_loss: 0.000076 train_acc: 0.997046
[7/10][300/469] train_loss: 0.000074 train_acc: 0.997275
[7/10][400/469] train_loss: 0.000078 train_acc: 0.996922
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.146206 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.611593 val_acc: 0.962800
AT dataset testing:[7/10] val_loss: 0.146070 val_acc: 0.000200
Clean dataset testing:[7/10] val_loss: 0.000252 val_acc: 0.990200
[8/10][0/469] train_loss: 0.000156 train_acc: 0.992188
[8/10][100/469] train_loss: 0.000071 train_acc: 0.996906
[8/10][200/469] train_loss: 0.000077 train_acc: 0.996657
[8/10][300/469] train_loss: 0.000082 train_acc: 0.996574
[8/10][400/469] train_loss: 0.000084 train_acc: 0.996532
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.145429 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.605643 val_acc: 0.963200
AT dataset testing:[8/10] val_loss: 0.143339 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000228 val_acc: 0.991100
[9/10][0/469] train_loss: 0.000018 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000038 train_acc: 0.998608
[9/10][200/469] train_loss: 0.000052 train_acc: 0.997707
[9/10][300/469] train_loss: 0.000059 train_acc: 0.997301
[9/10][400/469] train_loss: 0.000060 train_acc: 0.997370
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.161754 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.453501 val_acc: 0.975000
AT dataset testing:[9/10] val_loss: 0.161523 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000227 val_acc: 0.991800
nbits:7
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018040 train_acc: 0.085938
[0/10][100/469] train_loss: 0.004155 train_acc: 0.851330
[0/10][200/469] train_loss: 0.002639 train_acc: 0.903840
[0/10][300/469] train_loss: 0.002032 train_acc: 0.925353
[0/10][400/469] train_loss: 0.001698 train_acc: 0.937305
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.070695 val_acc: 0.002200
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.547711 val_acc: 0.829700
AT dataset testing:[0/10] val_loss: 0.069947 val_acc: 0.002200
Clean dataset testing:[0/10] val_loss: 0.000411 val_acc: 0.982800
[1/10][0/469] train_loss: 0.000521 train_acc: 0.984375
[1/10][100/469] train_loss: 0.000464 train_acc: 0.982673
[1/10][200/469] train_loss: 0.000445 train_acc: 0.983170
[1/10][300/469] train_loss: 0.000435 train_acc: 0.983103
[1/10][400/469] train_loss: 0.000424 train_acc: 0.983596
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.082041 val_acc: 0.001300
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.674537 val_acc: 0.903300
AT dataset testing:[1/10] val_loss: 0.082105 val_acc: 0.001200
Clean dataset testing:[1/10] val_loss: 0.000361 val_acc: 0.985400
[2/10][0/469] train_loss: 0.000214 train_acc: 0.984375
[2/10][100/469] train_loss: 0.000269 train_acc: 0.989171
[2/10][200/469] train_loss: 0.000303 train_acc: 0.987679
[2/10][300/469] train_loss: 0.000301 train_acc: 0.987879
[2/10][400/469] train_loss: 0.000288 train_acc: 0.988505
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.083480 val_acc: 0.001000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.407483 val_acc: 0.953400
AT dataset testing:[2/10] val_loss: 0.083831 val_acc: 0.000800
Clean dataset testing:[2/10] val_loss: 0.000243 val_acc: 0.990200
[3/10][0/469] train_loss: 0.000026 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000194 train_acc: 0.992574
[3/10][200/469] train_loss: 0.000209 train_acc: 0.992576
[3/10][300/469] train_loss: 0.000206 train_acc: 0.992291
[3/10][400/469] train_loss: 0.000206 train_acc: 0.992051
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.091994 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.487287 val_acc: 0.961900
AT dataset testing:[3/10] val_loss: 0.091517 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000259 val_acc: 0.990500
[4/10][0/469] train_loss: 0.000166 train_acc: 0.984375
[4/10][100/469] train_loss: 0.000154 train_acc: 0.993193
[4/10][200/469] train_loss: 0.000159 train_acc: 0.993392
[4/10][300/469] train_loss: 0.000155 train_acc: 0.993485
[4/10][400/469] train_loss: 0.000163 train_acc: 0.993279
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.100915 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.596688 val_acc: 0.961500
AT dataset testing:[4/10] val_loss: 0.101015 val_acc: 0.000300
Clean dataset testing:[4/10] val_loss: 0.000207 val_acc: 0.991900
[5/10][0/469] train_loss: 0.000280 train_acc: 0.984375
[5/10][100/469] train_loss: 0.000125 train_acc: 0.995436
[5/10][200/469] train_loss: 0.000119 train_acc: 0.995336
[5/10][300/469] train_loss: 0.000116 train_acc: 0.995302
[5/10][400/469] train_loss: 0.000123 train_acc: 0.995051
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.111478 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.509889 val_acc: 0.967200
AT dataset testing:[5/10] val_loss: 0.111432 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000249 val_acc: 0.989600
[6/10][0/469] train_loss: 0.000129 train_acc: 0.984375
[6/10][100/469] train_loss: 0.000106 train_acc: 0.995127
[6/10][200/469] train_loss: 0.000110 train_acc: 0.995647
[6/10][300/469] train_loss: 0.000106 train_acc: 0.995743
[6/10][400/469] train_loss: 0.000101 train_acc: 0.995909
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.121378 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.456738 val_acc: 0.973600
AT dataset testing:[6/10] val_loss: 0.121814 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000243 val_acc: 0.989900
[7/10][0/469] train_loss: 0.000304 train_acc: 0.984375
[7/10][100/469] train_loss: 0.000093 train_acc: 0.995514
[7/10][200/469] train_loss: 0.000081 train_acc: 0.996074
[7/10][300/469] train_loss: 0.000084 train_acc: 0.996211
[7/10][400/469] train_loss: 0.000090 train_acc: 0.996084
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.132017 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 1.216216 val_acc: 0.942200
AT dataset testing:[7/10] val_loss: 0.131620 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000366 val_acc: 0.987800
[8/10][0/469] train_loss: 0.000129 train_acc: 0.992188
[8/10][100/469] train_loss: 0.000045 train_acc: 0.998685
[8/10][200/469] train_loss: 0.000062 train_acc: 0.997979
[8/10][300/469] train_loss: 0.000067 train_acc: 0.997456
[8/10][400/469] train_loss: 0.000078 train_acc: 0.996863
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.140505 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.662266 val_acc: 0.969400
AT dataset testing:[8/10] val_loss: 0.140332 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000255 val_acc: 0.990700
[9/10][0/469] train_loss: 0.000037 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000045 train_acc: 0.998298
[9/10][200/469] train_loss: 0.000052 train_acc: 0.997979
[9/10][300/469] train_loss: 0.000064 train_acc: 0.997379
[9/10][400/469] train_loss: 0.000065 train_acc: 0.997350
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.149434 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.581236 val_acc: 0.976700
AT dataset testing:[9/10] val_loss: 0.149040 val_acc: 0.000100
Clean dataset testing:[9/10] val_loss: 0.000232 val_acc: 0.991000
nbits:8
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018025 train_acc: 0.117188
[0/10][100/469] train_loss: 0.004207 train_acc: 0.838258
[0/10][200/469] train_loss: 0.002655 train_acc: 0.897777
[0/10][300/469] train_loss: 0.002008 train_acc: 0.922732
[0/10][400/469] train_loss: 0.001658 train_acc: 0.936039
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.059902 val_acc: 0.000800
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.690545 val_acc: 0.709600
AT dataset testing:[0/10] val_loss: 0.060136 val_acc: 0.000600
Clean dataset testing:[0/10] val_loss: 0.000442 val_acc: 0.982100
[1/10][0/469] train_loss: 0.001117 train_acc: 0.960938
[1/10][100/469] train_loss: 0.000451 train_acc: 0.982519
[1/10][200/469] train_loss: 0.000421 train_acc: 0.983364
[1/10][300/469] train_loss: 0.000421 train_acc: 0.983752
[1/10][400/469] train_loss: 0.000404 train_acc: 0.984219
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.082942 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.361944 val_acc: 0.919200
AT dataset testing:[1/10] val_loss: 0.082928 val_acc: 0.000000
Clean dataset testing:[1/10] val_loss: 0.000285 val_acc: 0.987800
[2/10][0/469] train_loss: 0.000115 train_acc: 0.992188
[2/10][100/469] train_loss: 0.000286 train_acc: 0.988243
[2/10][200/469] train_loss: 0.000262 train_acc: 0.989350
[2/10][300/469] train_loss: 0.000268 train_acc: 0.989410
[2/10][400/469] train_loss: 0.000266 train_acc: 0.989363
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.081719 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.296729 val_acc: 0.944500
AT dataset testing:[2/10] val_loss: 0.081885 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000225 val_acc: 0.990100
[3/10][0/469] train_loss: 0.000319 train_acc: 0.984375
[3/10][100/469] train_loss: 0.000188 train_acc: 0.992342
[3/10][200/469] train_loss: 0.000186 train_acc: 0.992343
[3/10][300/469] train_loss: 0.000191 train_acc: 0.992213
[3/10][400/469] train_loss: 0.000194 train_acc: 0.992149
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.091705 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.390345 val_acc: 0.947000
AT dataset testing:[3/10] val_loss: 0.092174 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000194 val_acc: 0.991600
[4/10][0/469] train_loss: 0.000032 train_acc: 1.000000
[4/10][100/469] train_loss: 0.000139 train_acc: 0.993889
[4/10][200/469] train_loss: 0.000143 train_acc: 0.993820
[4/10][300/469] train_loss: 0.000152 train_acc: 0.993875
[4/10][400/469] train_loss: 0.000149 train_acc: 0.993999
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.101925 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.388319 val_acc: 0.957300
AT dataset testing:[4/10] val_loss: 0.101757 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000230 val_acc: 0.990600
[5/10][0/469] train_loss: 0.000047 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000102 train_acc: 0.995746
[5/10][200/469] train_loss: 0.000126 train_acc: 0.994947
[5/10][300/469] train_loss: 0.000120 train_acc: 0.995069
[5/10][400/469] train_loss: 0.000124 train_acc: 0.994584
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.111957 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.590587 val_acc: 0.954000
AT dataset testing:[5/10] val_loss: 0.112272 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000247 val_acc: 0.989800
[6/10][0/469] train_loss: 0.000135 train_acc: 0.992188
[6/10][100/469] train_loss: 0.000094 train_acc: 0.996055
[6/10][200/469] train_loss: 0.000089 train_acc: 0.996230
[6/10][300/469] train_loss: 0.000088 train_acc: 0.996055
[6/10][400/469] train_loss: 0.000104 train_acc: 0.995402
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.116811 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.467989 val_acc: 0.962500
AT dataset testing:[6/10] val_loss: 0.116574 val_acc: 0.000200
Clean dataset testing:[6/10] val_loss: 0.000224 val_acc: 0.991400
[7/10][0/469] train_loss: 0.000046 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000070 train_acc: 0.996906
[7/10][200/469] train_loss: 0.000062 train_acc: 0.997318
[7/10][300/469] train_loss: 0.000073 train_acc: 0.996911
[7/10][400/469] train_loss: 0.000078 train_acc: 0.996649
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.135806 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.496518 val_acc: 0.966600
AT dataset testing:[7/10] val_loss: 0.135586 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000275 val_acc: 0.988900
[8/10][0/469] train_loss: 0.000039 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000040 train_acc: 0.998298
[8/10][200/469] train_loss: 0.000053 train_acc: 0.997629
[8/10][300/469] train_loss: 0.000072 train_acc: 0.996937
[8/10][400/469] train_loss: 0.000076 train_acc: 0.996649
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.153303 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.646300 val_acc: 0.964000
AT dataset testing:[8/10] val_loss: 0.153278 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000268 val_acc: 0.990700
[9/10][0/469] train_loss: 0.000044 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000049 train_acc: 0.998144
[9/10][200/469] train_loss: 0.000057 train_acc: 0.997707
[9/10][300/469] train_loss: 0.000058 train_acc: 0.997612
[9/10][400/469] train_loss: 0.000065 train_acc: 0.997292
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.136550 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.690325 val_acc: 0.960300
AT dataset testing:[9/10] val_loss: 0.136509 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000305 val_acc: 0.989600
nbits:9
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018021 train_acc: 0.070312
[0/10][100/469] train_loss: 0.004471 train_acc: 0.836556
[0/10][200/469] train_loss: 0.002795 train_acc: 0.895756
[0/10][300/469] train_loss: 0.002120 train_acc: 0.920915
[0/10][400/469] train_loss: 0.001755 train_acc: 0.934188
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.070206 val_acc: 0.003600
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.452979 val_acc: 0.895200
AT dataset testing:[0/10] val_loss: 0.070228 val_acc: 0.003300
Clean dataset testing:[0/10] val_loss: 0.000510 val_acc: 0.979500
[1/10][0/469] train_loss: 0.000864 train_acc: 0.968750
[1/10][100/469] train_loss: 0.000419 train_acc: 0.984143
[1/10][200/469] train_loss: 0.000404 train_acc: 0.984064
[1/10][300/469] train_loss: 0.000409 train_acc: 0.984064
[1/10][400/469] train_loss: 0.000391 train_acc: 0.984433
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.070652 val_acc: 0.000800
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.657822 val_acc: 0.911300
AT dataset testing:[1/10] val_loss: 0.070544 val_acc: 0.000200
Clean dataset testing:[1/10] val_loss: 0.000282 val_acc: 0.988400
[2/10][0/469] train_loss: 0.000163 train_acc: 1.000000
[2/10][100/469] train_loss: 0.000243 train_acc: 0.991027
[2/10][200/469] train_loss: 0.000255 train_acc: 0.990438
[2/10][300/469] train_loss: 0.000257 train_acc: 0.990007
[2/10][400/469] train_loss: 0.000261 train_acc: 0.989772
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.090641 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.751842 val_acc: 0.927900
AT dataset testing:[2/10] val_loss: 0.090436 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000288 val_acc: 0.988100
[3/10][0/469] train_loss: 0.000203 train_acc: 0.992188
[3/10][100/469] train_loss: 0.000184 train_acc: 0.991723
[3/10][200/469] train_loss: 0.000181 train_acc: 0.991915
[3/10][300/469] train_loss: 0.000191 train_acc: 0.991798
[3/10][400/469] train_loss: 0.000206 train_acc: 0.991486
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.087075 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.488470 val_acc: 0.958800
AT dataset testing:[3/10] val_loss: 0.087136 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000189 val_acc: 0.991100
[4/10][0/469] train_loss: 0.000147 train_acc: 0.992188
[4/10][100/469] train_loss: 0.000150 train_acc: 0.993889
[4/10][200/469] train_loss: 0.000142 train_acc: 0.994286
[4/10][300/469] train_loss: 0.000148 train_acc: 0.994108
[4/10][400/469] train_loss: 0.000147 train_acc: 0.994116
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.099127 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.353673 val_acc: 0.974400
AT dataset testing:[4/10] val_loss: 0.099167 val_acc: 0.000100
Clean dataset testing:[4/10] val_loss: 0.000211 val_acc: 0.991600
[5/10][0/469] train_loss: 0.000079 train_acc: 0.992188
[5/10][100/469] train_loss: 0.000103 train_acc: 0.996287
[5/10][200/469] train_loss: 0.000105 train_acc: 0.996074
[5/10][300/469] train_loss: 0.000118 train_acc: 0.995484
[5/10][400/469] train_loss: 0.000112 train_acc: 0.995870
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.099443 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.480567 val_acc: 0.966200
AT dataset testing:[5/10] val_loss: 0.099465 val_acc: 0.000100
Clean dataset testing:[5/10] val_loss: 0.000204 val_acc: 0.992000
[6/10][0/469] train_loss: 0.000152 train_acc: 0.984375
[6/10][100/469] train_loss: 0.000080 train_acc: 0.996364
[6/10][200/469] train_loss: 0.000072 train_acc: 0.996852
[6/10][300/469] train_loss: 0.000083 train_acc: 0.996574
[6/10][400/469] train_loss: 0.000084 train_acc: 0.996591
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.109572 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.424538 val_acc: 0.974100
AT dataset testing:[6/10] val_loss: 0.109414 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000191 val_acc: 0.991700
[7/10][0/469] train_loss: 0.000259 train_acc: 0.976562
[7/10][100/469] train_loss: 0.000080 train_acc: 0.996519
[7/10][200/469] train_loss: 0.000083 train_acc: 0.996230
[7/10][300/469] train_loss: 0.000081 train_acc: 0.996340
[7/10][400/469] train_loss: 0.000080 train_acc: 0.996415
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.131657 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.564497 val_acc: 0.976300
AT dataset testing:[7/10] val_loss: 0.132071 val_acc: 0.000200
Clean dataset testing:[7/10] val_loss: 0.000188 val_acc: 0.992600
[8/10][0/469] train_loss: 0.000026 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000077 train_acc: 0.996751
[8/10][200/469] train_loss: 0.000080 train_acc: 0.996385
[8/10][300/469] train_loss: 0.000074 train_acc: 0.996522
[8/10][400/469] train_loss: 0.000074 train_acc: 0.996688
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.126930 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 1.338232 val_acc: 0.943900
AT dataset testing:[8/10] val_loss: 0.127241 val_acc: 0.000100
Clean dataset testing:[8/10] val_loss: 0.000323 val_acc: 0.988700
[9/10][0/469] train_loss: 0.000050 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000065 train_acc: 0.997061
[9/10][200/469] train_loss: 0.000061 train_acc: 0.997396
[9/10][300/469] train_loss: 0.000074 train_acc: 0.997015
[9/10][400/469] train_loss: 0.000075 train_acc: 0.996941
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.136794 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.838569 val_acc: 0.966100
AT dataset testing:[9/10] val_loss: 0.137095 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000282 val_acc: 0.989900
nbits:10
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018012 train_acc: 0.070312
[0/10][100/469] train_loss: 0.004378 train_acc: 0.837949
[0/10][200/469] train_loss: 0.002784 train_acc: 0.895289
[0/10][300/469] train_loss: 0.002131 train_acc: 0.919721
[0/10][400/469] train_loss: 0.001762 train_acc: 0.933409
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.071562 val_acc: 0.000900
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 1.118875 val_acc: 0.793300
AT dataset testing:[0/10] val_loss: 0.071605 val_acc: 0.000900
Clean dataset testing:[0/10] val_loss: 0.000411 val_acc: 0.984500
[1/10][0/469] train_loss: 0.000825 train_acc: 0.976562
[1/10][100/469] train_loss: 0.000434 train_acc: 0.982054
[1/10][200/469] train_loss: 0.000435 train_acc: 0.982004
[1/10][300/469] train_loss: 0.000415 train_acc: 0.983051
[1/10][400/469] train_loss: 0.000405 train_acc: 0.983557
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.083008 val_acc: 0.001600
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.826068 val_acc: 0.924300
AT dataset testing:[1/10] val_loss: 0.082945 val_acc: 0.001900
Clean dataset testing:[1/10] val_loss: 0.000308 val_acc: 0.987100
[2/10][0/469] train_loss: 0.000290 train_acc: 0.992188
[2/10][100/469] train_loss: 0.000289 train_acc: 0.987778
[2/10][200/469] train_loss: 0.000278 train_acc: 0.988417
[2/10][300/469] train_loss: 0.000274 train_acc: 0.988943
[2/10][400/469] train_loss: 0.000278 train_acc: 0.989012
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.084408 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.476687 val_acc: 0.965200
AT dataset testing:[2/10] val_loss: 0.084447 val_acc: 0.000100
Clean dataset testing:[2/10] val_loss: 0.000272 val_acc: 0.989300
[3/10][0/469] train_loss: 0.000221 train_acc: 0.984375
[3/10][100/469] train_loss: 0.000179 train_acc: 0.992188
[3/10][200/469] train_loss: 0.000198 train_acc: 0.991799
[3/10][300/469] train_loss: 0.000196 train_acc: 0.992317
[3/10][400/469] train_loss: 0.000202 train_acc: 0.991954
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.111579 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 1.167860 val_acc: 0.947900
AT dataset testing:[3/10] val_loss: 0.111416 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000264 val_acc: 0.988600
[4/10][0/469] train_loss: 0.000296 train_acc: 0.992188
[4/10][100/469] train_loss: 0.000138 train_acc: 0.994353
[4/10][200/469] train_loss: 0.000156 train_acc: 0.993548
[4/10][300/469] train_loss: 0.000158 train_acc: 0.993485
[4/10][400/469] train_loss: 0.000159 train_acc: 0.993395
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.106104 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 1.240343 val_acc: 0.945400
AT dataset testing:[4/10] val_loss: 0.106234 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000191 val_acc: 0.992000
[5/10][0/469] train_loss: 0.000018 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000096 train_acc: 0.996442
[5/10][200/469] train_loss: 0.000111 train_acc: 0.995880
[5/10][300/469] train_loss: 0.000115 train_acc: 0.995458
[5/10][400/469] train_loss: 0.000121 train_acc: 0.995324
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.114471 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 1.472632 val_acc: 0.945500
AT dataset testing:[5/10] val_loss: 0.114297 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000210 val_acc: 0.992000
[6/10][0/469] train_loss: 0.000037 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000058 train_acc: 0.997989
[6/10][200/469] train_loss: 0.000079 train_acc: 0.997007
[6/10][300/469] train_loss: 0.000089 train_acc: 0.996470
[6/10][400/469] train_loss: 0.000097 train_acc: 0.996298
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.130387 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 1.072585 val_acc: 0.962100
AT dataset testing:[6/10] val_loss: 0.130587 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000266 val_acc: 0.990000
[7/10][0/469] train_loss: 0.000081 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000081 train_acc: 0.996287
[7/10][200/469] train_loss: 0.000078 train_acc: 0.996580
[7/10][300/469] train_loss: 0.000078 train_acc: 0.996522
[7/10][400/469] train_loss: 0.000087 train_acc: 0.996065
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.135874 val_acc: 0.000400
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.836844 val_acc: 0.973300
AT dataset testing:[7/10] val_loss: 0.135899 val_acc: 0.000400
Clean dataset testing:[7/10] val_loss: 0.000236 val_acc: 0.991500
[8/10][0/469] train_loss: 0.000036 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000066 train_acc: 0.997061
[8/10][200/469] train_loss: 0.000064 train_acc: 0.997512
[8/10][300/469] train_loss: 0.000070 train_acc: 0.997145
[8/10][400/469] train_loss: 0.000072 train_acc: 0.997019
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.158265 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 2.268239 val_acc: 0.944700
AT dataset testing:[8/10] val_loss: 0.158391 val_acc: 0.000100
Clean dataset testing:[8/10] val_loss: 0.000229 val_acc: 0.991900
[9/10][0/469] train_loss: 0.000062 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000049 train_acc: 0.998453
[9/10][200/469] train_loss: 0.000053 train_acc: 0.998134
[9/10][300/469] train_loss: 0.000050 train_acc: 0.998027
[9/10][400/469] train_loss: 0.000057 train_acc: 0.997662
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.153297 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 1.181900 val_acc: 0.972800
AT dataset testing:[9/10] val_loss: 0.153602 val_acc: 0.000300
Clean dataset testing:[9/10] val_loss: 0.000262 val_acc: 0.990700
nbits:11
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.017999 train_acc: 0.070312
[0/10][100/469] train_loss: 0.004587 train_acc: 0.825031
[0/10][200/469] train_loss: 0.002916 train_acc: 0.888604
[0/10][300/469] train_loss: 0.002223 train_acc: 0.914530
[0/10][400/469] train_loss: 0.001814 train_acc: 0.930311
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.065480 val_acc: 0.001500
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.564469 val_acc: 0.926900
AT dataset testing:[0/10] val_loss: 0.065432 val_acc: 0.001400
Clean dataset testing:[0/10] val_loss: 0.000413 val_acc: 0.983600
[1/10][0/469] train_loss: 0.000514 train_acc: 0.984375
[1/10][100/469] train_loss: 0.000428 train_acc: 0.982828
[1/10][200/469] train_loss: 0.000424 train_acc: 0.983287
[1/10][300/469] train_loss: 0.000417 train_acc: 0.983752
[1/10][400/469] train_loss: 0.000400 train_acc: 0.984472
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.073589 val_acc: 0.000300
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 1.192055 val_acc: 0.933400
AT dataset testing:[1/10] val_loss: 0.073742 val_acc: 0.000400
Clean dataset testing:[1/10] val_loss: 0.000269 val_acc: 0.988700
[2/10][0/469] train_loss: 0.000064 train_acc: 1.000000
[2/10][100/469] train_loss: 0.000294 train_acc: 0.988629
[2/10][200/469] train_loss: 0.000279 train_acc: 0.989234
[2/10][300/469] train_loss: 0.000274 train_acc: 0.989514
[2/10][400/469] train_loss: 0.000269 train_acc: 0.989830
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.079635 val_acc: 0.000300
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 1.093762 val_acc: 0.964400
AT dataset testing:[2/10] val_loss: 0.079674 val_acc: 0.000400
Clean dataset testing:[2/10] val_loss: 0.000225 val_acc: 0.991300
[3/10][0/469] train_loss: 0.000014 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000179 train_acc: 0.992033
[3/10][200/469] train_loss: 0.000186 train_acc: 0.991954
[3/10][300/469] train_loss: 0.000184 train_acc: 0.992136
[3/10][400/469] train_loss: 0.000202 train_acc: 0.991700
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.092582 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 1.818337 val_acc: 0.960700
AT dataset testing:[3/10] val_loss: 0.092722 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000222 val_acc: 0.990400
[4/10][0/469] train_loss: 0.000015 train_acc: 1.000000
[4/10][100/469] train_loss: 0.000138 train_acc: 0.995127
[4/10][200/469] train_loss: 0.000143 train_acc: 0.994558
[4/10][300/469] train_loss: 0.000144 train_acc: 0.994394
[4/10][400/469] train_loss: 0.000153 train_acc: 0.993999
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.101383 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 3.005204 val_acc: 0.942100
AT dataset testing:[4/10] val_loss: 0.101344 val_acc: 0.000100
Clean dataset testing:[4/10] val_loss: 0.000231 val_acc: 0.991300
[5/10][0/469] train_loss: 0.000041 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000104 train_acc: 0.995591
[5/10][200/469] train_loss: 0.000117 train_acc: 0.995180
[5/10][300/469] train_loss: 0.000115 train_acc: 0.995328
[5/10][400/469] train_loss: 0.000117 train_acc: 0.995441
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.113748 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 4.859568 val_acc: 0.926200
AT dataset testing:[5/10] val_loss: 0.113713 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000198 val_acc: 0.991600
[6/10][0/469] train_loss: 0.000051 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000072 train_acc: 0.996751
[6/10][200/469] train_loss: 0.000091 train_acc: 0.995997
[6/10][300/469] train_loss: 0.000097 train_acc: 0.995743
[6/10][400/469] train_loss: 0.000097 train_acc: 0.995987
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.116640 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 3.905426 val_acc: 0.949400
AT dataset testing:[6/10] val_loss: 0.116421 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000220 val_acc: 0.991400
[7/10][0/469] train_loss: 0.000015 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000089 train_acc: 0.996364
[7/10][200/469] train_loss: 0.000088 train_acc: 0.996502
[7/10][300/469] train_loss: 0.000081 train_acc: 0.996885
[7/10][400/469] train_loss: 0.000086 train_acc: 0.996630
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.138905 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 4.465595 val_acc: 0.949000
AT dataset testing:[7/10] val_loss: 0.138990 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000190 val_acc: 0.992200
[8/10][0/469] train_loss: 0.000004 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000071 train_acc: 0.997215
[8/10][200/469] train_loss: 0.000061 train_acc: 0.997668
[8/10][300/469] train_loss: 0.000066 train_acc: 0.997508
[8/10][400/469] train_loss: 0.000066 train_acc: 0.997428
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.152832 val_acc: 0.000300
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 4.637935 val_acc: 0.950500
AT dataset testing:[8/10] val_loss: 0.152585 val_acc: 0.000100
Clean dataset testing:[8/10] val_loss: 0.000258 val_acc: 0.991000
[9/10][0/469] train_loss: 0.000016 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000029 train_acc: 0.999072
[9/10][200/469] train_loss: 0.000048 train_acc: 0.998095
[9/10][300/469] train_loss: 0.000053 train_acc: 0.997794
[9/10][400/469] train_loss: 0.000054 train_acc: 0.997701
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.135396 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 2.821220 val_acc: 0.963000
AT dataset testing:[9/10] val_loss: 0.135152 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000380 val_acc: 0.985500
nbits:12
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.017994 train_acc: 0.070312
[0/10][100/469] train_loss: 0.004466 train_acc: 0.828048
[0/10][200/469] train_loss: 0.002816 train_acc: 0.891830
[0/10][300/469] train_loss: 0.002151 train_acc: 0.917203
[0/10][400/469] train_loss: 0.001762 train_acc: 0.931870
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.062921 val_acc: 0.000300
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.420658 val_acc: 0.892700
AT dataset testing:[0/10] val_loss: 0.062989 val_acc: 0.000100
Clean dataset testing:[0/10] val_loss: 0.000402 val_acc: 0.983200
[1/10][0/469] train_loss: 0.000235 train_acc: 0.992188
[1/10][100/469] train_loss: 0.000480 train_acc: 0.981590
[1/10][200/469] train_loss: 0.000474 train_acc: 0.981693
[1/10][300/469] train_loss: 0.000435 train_acc: 0.982818
[1/10][400/469] train_loss: 0.000414 train_acc: 0.983440
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.069521 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.508686 val_acc: 0.930700
AT dataset testing:[1/10] val_loss: 0.069589 val_acc: 0.000000
Clean dataset testing:[1/10] val_loss: 0.000273 val_acc: 0.989600
[2/10][0/469] train_loss: 0.000215 train_acc: 0.992188
[2/10][100/469] train_loss: 0.000282 train_acc: 0.989093
[2/10][200/469] train_loss: 0.000274 train_acc: 0.988961
[2/10][300/469] train_loss: 0.000278 train_acc: 0.989047
[2/10][400/469] train_loss: 0.000274 train_acc: 0.989070
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.077188 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 1.223200 val_acc: 0.901900
AT dataset testing:[2/10] val_loss: 0.077128 val_acc: 0.000100
Clean dataset testing:[2/10] val_loss: 0.000234 val_acc: 0.989900
[3/10][0/469] train_loss: 0.000027 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000156 train_acc: 0.993348
[3/10][200/469] train_loss: 0.000179 train_acc: 0.992615
[3/10][300/469] train_loss: 0.000186 train_acc: 0.992603
[3/10][400/469] train_loss: 0.000196 train_acc: 0.992110
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.080671 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.803714 val_acc: 0.947500
AT dataset testing:[3/10] val_loss: 0.080643 val_acc: 0.000100
Clean dataset testing:[3/10] val_loss: 0.000198 val_acc: 0.991000
[4/10][0/469] train_loss: 0.000050 train_acc: 1.000000
[4/10][100/469] train_loss: 0.000152 train_acc: 0.993348
[4/10][200/469] train_loss: 0.000142 train_acc: 0.993975
[4/10][300/469] train_loss: 0.000153 train_acc: 0.993693
[4/10][400/469] train_loss: 0.000153 train_acc: 0.993805
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.098080 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 1.064313 val_acc: 0.950200
AT dataset testing:[4/10] val_loss: 0.098228 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000182 val_acc: 0.992500
[5/10][0/469] train_loss: 0.000038 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000099 train_acc: 0.996210
[5/10][200/469] train_loss: 0.000106 train_acc: 0.995958
[5/10][300/469] train_loss: 0.000117 train_acc: 0.995432
[5/10][400/469] train_loss: 0.000120 train_acc: 0.995227
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.100649 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 1.381513 val_acc: 0.935800
AT dataset testing:[5/10] val_loss: 0.100607 val_acc: 0.000100
Clean dataset testing:[5/10] val_loss: 0.000218 val_acc: 0.990400
[6/10][0/469] train_loss: 0.000127 train_acc: 0.992188
[6/10][100/469] train_loss: 0.000114 train_acc: 0.995282
[6/10][200/469] train_loss: 0.000103 train_acc: 0.995414
[6/10][300/469] train_loss: 0.000109 train_acc: 0.995432
[6/10][400/469] train_loss: 0.000108 train_acc: 0.995441
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.117555 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 1.606266 val_acc: 0.948100
AT dataset testing:[6/10] val_loss: 0.117555 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000211 val_acc: 0.992300
[7/10][0/469] train_loss: 0.000034 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000065 train_acc: 0.997138
[7/10][200/469] train_loss: 0.000083 train_acc: 0.996308
[7/10][300/469] train_loss: 0.000084 train_acc: 0.996444
[7/10][400/469] train_loss: 0.000084 train_acc: 0.996571
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.113923 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 1.351846 val_acc: 0.949400
AT dataset testing:[7/10] val_loss: 0.113878 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000219 val_acc: 0.991600
[8/10][0/469] train_loss: 0.000012 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000044 train_acc: 0.998221
[8/10][200/469] train_loss: 0.000059 train_acc: 0.997435
[8/10][300/469] train_loss: 0.000062 train_acc: 0.997223
[8/10][400/469] train_loss: 0.000066 train_acc: 0.997253
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.147010 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 1.472694 val_acc: 0.958000
AT dataset testing:[8/10] val_loss: 0.146949 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000275 val_acc: 0.991100
[9/10][0/469] train_loss: 0.000004 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000081 train_acc: 0.996519
[9/10][200/469] train_loss: 0.000080 train_acc: 0.996580
[9/10][300/469] train_loss: 0.000073 train_acc: 0.996859
[9/10][400/469] train_loss: 0.000077 train_acc: 0.996415
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.151020 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 1.633891 val_acc: 0.957300
AT dataset testing:[9/10] val_loss: 0.151259 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000221 val_acc: 0.991300
nbits:13
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.017935 train_acc: 0.023438
[0/10][100/469] train_loss: 0.004537 train_acc: 0.826655
[0/10][200/469] train_loss: 0.002858 train_acc: 0.890236
[0/10][300/469] train_loss: 0.002177 train_acc: 0.916009
[0/10][400/469] train_loss: 0.001791 train_acc: 0.930876
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.061420 val_acc: 0.001900
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.546631 val_acc: 0.845700
AT dataset testing:[0/10] val_loss: 0.061530 val_acc: 0.001800
Clean dataset testing:[0/10] val_loss: 0.000394 val_acc: 0.983300
[1/10][0/469] train_loss: 0.000485 train_acc: 0.976562
[1/10][100/469] train_loss: 0.000474 train_acc: 0.981900
[1/10][200/469] train_loss: 0.000434 train_acc: 0.982820
[1/10][300/469] train_loss: 0.000415 train_acc: 0.983518
[1/10][400/469] train_loss: 0.000413 train_acc: 0.983654
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.074813 val_acc: 0.000500
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.561280 val_acc: 0.929800
AT dataset testing:[1/10] val_loss: 0.074852 val_acc: 0.000300
Clean dataset testing:[1/10] val_loss: 0.000238 val_acc: 0.988700
[2/10][0/469] train_loss: 0.000171 train_acc: 0.992188
[2/10][100/469] train_loss: 0.000297 train_acc: 0.987314
[2/10][200/469] train_loss: 0.000284 train_acc: 0.988456
[2/10][300/469] train_loss: 0.000286 train_acc: 0.988684
[2/10][400/469] train_loss: 0.000271 train_acc: 0.989343
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.081319 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.509036 val_acc: 0.955400
AT dataset testing:[2/10] val_loss: 0.081129 val_acc: 0.000200
Clean dataset testing:[2/10] val_loss: 0.000271 val_acc: 0.988000
[3/10][0/469] train_loss: 0.000195 train_acc: 0.992188
[3/10][100/469] train_loss: 0.000221 train_acc: 0.991259
[3/10][200/469] train_loss: 0.000216 train_acc: 0.991371
[3/10][300/469] train_loss: 0.000203 train_acc: 0.991668
[3/10][400/469] train_loss: 0.000203 train_acc: 0.991681
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.098000 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.961013 val_acc: 0.937500
AT dataset testing:[3/10] val_loss: 0.098213 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000204 val_acc: 0.991900
[4/10][0/469] train_loss: 0.000234 train_acc: 0.992188
[4/10][100/469] train_loss: 0.000155 train_acc: 0.993425
[4/10][200/469] train_loss: 0.000158 train_acc: 0.993626
[4/10][300/469] train_loss: 0.000158 train_acc: 0.993537
[4/10][400/469] train_loss: 0.000158 train_acc: 0.993512
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.096305 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.536637 val_acc: 0.969000
AT dataset testing:[4/10] val_loss: 0.096144 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000202 val_acc: 0.992200
[5/10][0/469] train_loss: 0.000029 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000107 train_acc: 0.995359
[5/10][200/469] train_loss: 0.000126 train_acc: 0.994597
[5/10][300/469] train_loss: 0.000122 train_acc: 0.994783
[5/10][400/469] train_loss: 0.000128 train_acc: 0.994720
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.094894 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.767424 val_acc: 0.962800
AT dataset testing:[5/10] val_loss: 0.094911 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000199 val_acc: 0.992000
[6/10][0/469] train_loss: 0.000053 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000057 train_acc: 0.997912
[6/10][200/469] train_loss: 0.000078 train_acc: 0.996735
[6/10][300/469] train_loss: 0.000085 train_acc: 0.996470
[6/10][400/469] train_loss: 0.000086 train_acc: 0.996513
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.110465 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 1.331432 val_acc: 0.943300
AT dataset testing:[6/10] val_loss: 0.110404 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000300 val_acc: 0.989500
[7/10][0/469] train_loss: 0.000014 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000089 train_acc: 0.996364
[7/10][200/469] train_loss: 0.000079 train_acc: 0.996657
[7/10][300/469] train_loss: 0.000079 train_acc: 0.996496
[7/10][400/469] train_loss: 0.000083 train_acc: 0.996279
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.122382 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 1.000361 val_acc: 0.963700
AT dataset testing:[7/10] val_loss: 0.122493 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000196 val_acc: 0.991900
[8/10][0/469] train_loss: 0.000016 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000062 train_acc: 0.997447
[8/10][200/469] train_loss: 0.000060 train_acc: 0.997357
[8/10][300/469] train_loss: 0.000064 train_acc: 0.997223
[8/10][400/469] train_loss: 0.000062 train_acc: 0.997272
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.152172 val_acc: 0.000500
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 1.028324 val_acc: 0.968900
AT dataset testing:[8/10] val_loss: 0.152436 val_acc: 0.000200
Clean dataset testing:[8/10] val_loss: 0.000284 val_acc: 0.989000
[9/10][0/469] train_loss: 0.000264 train_acc: 0.992188
[9/10][100/469] train_loss: 0.000056 train_acc: 0.997061
[9/10][200/469] train_loss: 0.000071 train_acc: 0.996308
[9/10][300/469] train_loss: 0.000072 train_acc: 0.996496
[9/10][400/469] train_loss: 0.000068 train_acc: 0.996630
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.145940 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 1.077151 val_acc: 0.971100
AT dataset testing:[9/10] val_loss: 0.145984 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000229 val_acc: 0.991500
nbits:14
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.017959 train_acc: 0.132812
[0/10][100/469] train_loss: 0.004235 train_acc: 0.843054
[0/10][200/469] train_loss: 0.002706 train_acc: 0.899487
[0/10][300/469] train_loss: 0.002067 train_acc: 0.922446
[0/10][400/469] train_loss: 0.001721 train_acc: 0.935201
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.065619 val_acc: 0.000300
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 1.281710 val_acc: 0.670900
AT dataset testing:[0/10] val_loss: 0.065595 val_acc: 0.000000
Clean dataset testing:[0/10] val_loss: 0.000423 val_acc: 0.982100
[1/10][0/469] train_loss: 0.000580 train_acc: 0.968750
[1/10][100/469] train_loss: 0.000442 train_acc: 0.982364
[1/10][200/469] train_loss: 0.000449 train_acc: 0.981654
[1/10][300/469] train_loss: 0.000430 train_acc: 0.982532
[1/10][400/469] train_loss: 0.000412 train_acc: 0.983732
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.082216 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 2.643163 val_acc: 0.766500
AT dataset testing:[1/10] val_loss: 0.082292 val_acc: 0.000000
Clean dataset testing:[1/10] val_loss: 0.000423 val_acc: 0.982400
[2/10][0/469] train_loss: 0.000073 train_acc: 1.000000
[2/10][100/469] train_loss: 0.000289 train_acc: 0.988707
[2/10][200/469] train_loss: 0.000284 train_acc: 0.988884
[2/10][300/469] train_loss: 0.000284 train_acc: 0.988735
[2/10][400/469] train_loss: 0.000281 train_acc: 0.988544
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.080353 val_acc: 0.001400
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.866449 val_acc: 0.945700
AT dataset testing:[2/10] val_loss: 0.080299 val_acc: 0.001600
Clean dataset testing:[2/10] val_loss: 0.000257 val_acc: 0.989500
[3/10][0/469] train_loss: 0.000345 train_acc: 0.992188
[3/10][100/469] train_loss: 0.000202 train_acc: 0.991878
[3/10][200/469] train_loss: 0.000198 train_acc: 0.991760
[3/10][300/469] train_loss: 0.000200 train_acc: 0.991824
[3/10][400/469] train_loss: 0.000202 train_acc: 0.991739
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.087393 val_acc: 0.001900
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 1.409984 val_acc: 0.934600
AT dataset testing:[3/10] val_loss: 0.087352 val_acc: 0.001700
Clean dataset testing:[3/10] val_loss: 0.000238 val_acc: 0.990500
[4/10][0/469] train_loss: 0.000506 train_acc: 0.976562
[4/10][100/469] train_loss: 0.000161 train_acc: 0.993270
[4/10][200/469] train_loss: 0.000158 train_acc: 0.993626
[4/10][300/469] train_loss: 0.000152 train_acc: 0.993745
[4/10][400/469] train_loss: 0.000156 train_acc: 0.993317
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.094413 val_acc: 0.000400
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.986660 val_acc: 0.961100
AT dataset testing:[4/10] val_loss: 0.094576 val_acc: 0.000400
Clean dataset testing:[4/10] val_loss: 0.000210 val_acc: 0.991400
[5/10][0/469] train_loss: 0.000141 train_acc: 1.000000
[5/10][100/469] train_loss: 0.000113 train_acc: 0.994895
[5/10][200/469] train_loss: 0.000110 train_acc: 0.995491
[5/10][300/469] train_loss: 0.000109 train_acc: 0.995536
[5/10][400/469] train_loss: 0.000114 train_acc: 0.995207
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.109353 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 2.037927 val_acc: 0.941400
AT dataset testing:[5/10] val_loss: 0.109500 val_acc: 0.000100
Clean dataset testing:[5/10] val_loss: 0.000192 val_acc: 0.992100
[6/10][0/469] train_loss: 0.000079 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000081 train_acc: 0.996210
[6/10][200/469] train_loss: 0.000088 train_acc: 0.995997
[6/10][300/469] train_loss: 0.000091 train_acc: 0.995977
[6/10][400/469] train_loss: 0.000092 train_acc: 0.996006
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.107809 val_acc: 0.000400
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 2.143894 val_acc: 0.940000
AT dataset testing:[6/10] val_loss: 0.107555 val_acc: 0.000700
Clean dataset testing:[6/10] val_loss: 0.000265 val_acc: 0.990200
[7/10][0/469] train_loss: 0.000039 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000081 train_acc: 0.996597
[7/10][200/469] train_loss: 0.000084 train_acc: 0.996541
[7/10][300/469] train_loss: 0.000077 train_acc: 0.996808
[7/10][400/469] train_loss: 0.000088 train_acc: 0.996298
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.120458 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 1.766440 val_acc: 0.956200
AT dataset testing:[7/10] val_loss: 0.120513 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000201 val_acc: 0.992000
[8/10][0/469] train_loss: 0.000042 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000064 train_acc: 0.997679
[8/10][200/469] train_loss: 0.000073 train_acc: 0.996852
[8/10][300/469] train_loss: 0.000067 train_acc: 0.997197
[8/10][400/469] train_loss: 0.000067 train_acc: 0.997214
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.135074 val_acc: 0.000500
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 1.387100 val_acc: 0.967600
AT dataset testing:[8/10] val_loss: 0.135195 val_acc: 0.000800
Clean dataset testing:[8/10] val_loss: 0.000252 val_acc: 0.990000
[9/10][0/469] train_loss: 0.000036 train_acc: 1.000000
[9/10][100/469] train_loss: 0.000050 train_acc: 0.997912
[9/10][200/469] train_loss: 0.000053 train_acc: 0.997629
[9/10][300/469] train_loss: 0.000060 train_acc: 0.997327
[9/10][400/469] train_loss: 0.000070 train_acc: 0.997136
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.141918 val_acc: 0.001300
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 2.698283 val_acc: 0.943800
AT dataset testing:[9/10] val_loss: 0.142400 val_acc: 0.000900
Clean dataset testing:[9/10] val_loss: 0.000205 val_acc: 0.991700
nbits:15
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.018061 train_acc: 0.054688
[0/10][100/469] train_loss: 0.004964 train_acc: 0.814124
[0/10][200/469] train_loss: 0.003112 train_acc: 0.882152
[0/10][300/469] train_loss: 0.002361 train_acc: 0.910013
[0/10][400/469] train_loss: 0.001931 train_acc: 0.926025
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.072227 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.733224 val_acc: 0.918900
AT dataset testing:[0/10] val_loss: 0.072321 val_acc: 0.000000
Clean dataset testing:[0/10] val_loss: 0.000391 val_acc: 0.984100
[1/10][0/469] train_loss: 0.000553 train_acc: 0.968750
[1/10][100/469] train_loss: 0.000498 train_acc: 0.981126
[1/10][200/469] train_loss: 0.000461 train_acc: 0.981965
[1/10][300/469] train_loss: 0.000444 train_acc: 0.982870
[1/10][400/469] train_loss: 0.000434 train_acc: 0.982953
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.074415 val_acc: 0.000700
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.782972 val_acc: 0.956800
AT dataset testing:[1/10] val_loss: 0.074437 val_acc: 0.000200
Clean dataset testing:[1/10] val_loss: 0.000371 val_acc: 0.985500
[2/10][0/469] train_loss: 0.000486 train_acc: 0.984375
[2/10][100/469] train_loss: 0.000314 train_acc: 0.987392
[2/10][200/469] train_loss: 0.000304 train_acc: 0.987795
[2/10][300/469] train_loss: 0.000297 train_acc: 0.988398
[2/10][400/469] train_loss: 0.000294 train_acc: 0.988388
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.079373 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 1.074085 val_acc: 0.958900
AT dataset testing:[2/10] val_loss: 0.079365 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000265 val_acc: 0.988400
[3/10][0/469] train_loss: 0.000140 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000224 train_acc: 0.991182
[3/10][200/469] train_loss: 0.000206 train_acc: 0.992110
[3/10][300/469] train_loss: 0.000208 train_acc: 0.991876
[3/10][400/469] train_loss: 0.000208 train_acc: 0.991623
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.089423 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 2.592675 val_acc: 0.934400
AT dataset testing:[3/10] val_loss: 0.089354 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000202 val_acc: 0.991200
[4/10][0/469] train_loss: 0.000080 train_acc: 0.992188
[4/10][100/469] train_loss: 0.000156 train_acc: 0.993425
[4/10][200/469] train_loss: 0.000139 train_acc: 0.994248
[4/10][300/469] train_loss: 0.000157 train_acc: 0.993615
[4/10][400/469] train_loss: 0.000153 train_acc: 0.993532
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.099823 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 2.057677 val_acc: 0.954900
AT dataset testing:[4/10] val_loss: 0.099719 val_acc: 0.000100
Clean dataset testing:[4/10] val_loss: 0.000219 val_acc: 0.990900
[5/10][0/469] train_loss: 0.000236 train_acc: 0.984375
[5/10][100/469] train_loss: 0.000119 train_acc: 0.994740
[5/10][200/469] train_loss: 0.000128 train_acc: 0.994675
[5/10][300/469] train_loss: 0.000135 train_acc: 0.994342
[5/10][400/469] train_loss: 0.000129 train_acc: 0.994506
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.104850 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 2.788741 val_acc: 0.944900
AT dataset testing:[5/10] val_loss: 0.104983 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000285 val_acc: 0.988000
[6/10][0/469] train_loss: 0.000090 train_acc: 0.992188
[6/10][100/469] train_loss: 0.000109 train_acc: 0.995359
[6/10][200/469] train_loss: 0.000107 train_acc: 0.995452
[6/10][300/469] train_loss: 0.000105 train_acc: 0.995458
[6/10][400/469] train_loss: 0.000116 train_acc: 0.995207
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.117280 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 2.948467 val_acc: 0.952800
AT dataset testing:[6/10] val_loss: 0.117233 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000231 val_acc: 0.990700
[7/10][0/469] train_loss: 0.000070 train_acc: 0.992188
[7/10][100/469] train_loss: 0.000088 train_acc: 0.995823
[7/10][200/469] train_loss: 0.000090 train_acc: 0.995997
[7/10][300/469] train_loss: 0.000091 train_acc: 0.996133
[7/10][400/469] train_loss: 0.000091 train_acc: 0.996142
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.123904 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 2.353855 val_acc: 0.963400
AT dataset testing:[7/10] val_loss: 0.123989 val_acc: 0.000100
Clean dataset testing:[7/10] val_loss: 0.000223 val_acc: 0.991700
[8/10][0/469] train_loss: 0.000006 train_acc: 1.000000
[8/10][100/469] train_loss: 0.000085 train_acc: 0.996519
[8/10][200/469] train_loss: 0.000070 train_acc: 0.997163
[8/10][300/469] train_loss: 0.000075 train_acc: 0.997041
[8/10][400/469] train_loss: 0.000072 train_acc: 0.996980
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.118200 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 2.075027 val_acc: 0.964200
AT dataset testing:[8/10] val_loss: 0.118101 val_acc: 0.000100
Clean dataset testing:[8/10] val_loss: 0.000209 val_acc: 0.991600
[9/10][0/469] train_loss: 0.000110 train_acc: 0.992188
[9/10][100/469] train_loss: 0.000063 train_acc: 0.997602
[9/10][200/469] train_loss: 0.000051 train_acc: 0.997940
[9/10][300/469] train_loss: 0.000046 train_acc: 0.998287
[9/10][400/469] train_loss: 0.000055 train_acc: 0.998052
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.132793 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 6.777955 val_acc: 0.894200
AT dataset testing:[9/10] val_loss: 0.132891 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000297 val_acc: 0.989200
nbits:16
conv_and_fc(
  (features): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=800, out_features=500, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=500, out_features=10, bias=True)
  )
)
[0/10][0/469] train_loss: 0.017952 train_acc: 0.187500
[0/10][100/469] train_loss: 0.004228 train_acc: 0.843750
[0/10][200/469] train_loss: 0.002620 train_acc: 0.901936
[0/10][300/469] train_loss: 0.001978 train_acc: 0.925976
[0/10][400/469] train_loss: 0.001644 train_acc: 0.938299
[Normal training Linear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.066935 val_acc: 0.000200
[Normal training NonLinear Quantilized testing]AT dataset testing:[0/10] val_loss: 0.473880 val_acc: 0.942300
AT dataset testing:[0/10] val_loss: 0.066892 val_acc: 0.000200
Clean dataset testing:[0/10] val_loss: 0.000346 val_acc: 0.985100
[1/10][0/469] train_loss: 0.000178 train_acc: 0.992188
[1/10][100/469] train_loss: 0.000448 train_acc: 0.981513
[1/10][200/469] train_loss: 0.000417 train_acc: 0.982665
[1/10][300/469] train_loss: 0.000399 train_acc: 0.983518
[1/10][400/469] train_loss: 0.000400 train_acc: 0.983732
[Normal training Linear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.075618 val_acc: 0.000100
[Normal training NonLinear Quantilized testing]AT dataset testing:[1/10] val_loss: 0.826204 val_acc: 0.956300
AT dataset testing:[1/10] val_loss: 0.075648 val_acc: 0.000000
Clean dataset testing:[1/10] val_loss: 0.000263 val_acc: 0.988600
[2/10][0/469] train_loss: 0.000071 train_acc: 1.000000
[2/10][100/469] train_loss: 0.000268 train_acc: 0.989480
[2/10][200/469] train_loss: 0.000279 train_acc: 0.988923
[2/10][300/469] train_loss: 0.000268 train_acc: 0.988969
[2/10][400/469] train_loss: 0.000254 train_acc: 0.989635
[Normal training Linear Quantilized testing]AT dataset testing:[2/10] val_loss: 0.086773 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[2/10] val_loss: 1.276286 val_acc: 0.957800
AT dataset testing:[2/10] val_loss: 0.086698 val_acc: 0.000000
Clean dataset testing:[2/10] val_loss: 0.000247 val_acc: 0.989700
[3/10][0/469] train_loss: 0.000051 train_acc: 1.000000
[3/10][100/469] train_loss: 0.000188 train_acc: 0.992188
[3/10][200/469] train_loss: 0.000194 train_acc: 0.991954
[3/10][300/469] train_loss: 0.000201 train_acc: 0.991772
[3/10][400/469] train_loss: 0.000203 train_acc: 0.991700
[Normal training Linear Quantilized testing]AT dataset testing:[3/10] val_loss: 0.099247 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[3/10] val_loss: 2.081797 val_acc: 0.951700
AT dataset testing:[3/10] val_loss: 0.099102 val_acc: 0.000000
Clean dataset testing:[3/10] val_loss: 0.000205 val_acc: 0.990900
[4/10][0/469] train_loss: 0.000206 train_acc: 0.992188
[4/10][100/469] train_loss: 0.000108 train_acc: 0.995514
[4/10][200/469] train_loss: 0.000133 train_acc: 0.994481
[4/10][300/469] train_loss: 0.000141 train_acc: 0.994030
[4/10][400/469] train_loss: 0.000145 train_acc: 0.993727
[Normal training Linear Quantilized testing]AT dataset testing:[4/10] val_loss: 0.105490 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[4/10] val_loss: 1.361327 val_acc: 0.974600
AT dataset testing:[4/10] val_loss: 0.105453 val_acc: 0.000000
Clean dataset testing:[4/10] val_loss: 0.000206 val_acc: 0.990900
[5/10][0/469] train_loss: 0.000103 train_acc: 0.992188
[5/10][100/469] train_loss: 0.000078 train_acc: 0.996906
[5/10][200/469] train_loss: 0.000089 train_acc: 0.996152
[5/10][300/469] train_loss: 0.000114 train_acc: 0.995172
[5/10][400/469] train_loss: 0.000110 train_acc: 0.995324
[Normal training Linear Quantilized testing]AT dataset testing:[5/10] val_loss: 0.122261 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[5/10] val_loss: 3.680473 val_acc: 0.941600
AT dataset testing:[5/10] val_loss: 0.122305 val_acc: 0.000000
Clean dataset testing:[5/10] val_loss: 0.000186 val_acc: 0.991700
[6/10][0/469] train_loss: 0.000017 train_acc: 1.000000
[6/10][100/469] train_loss: 0.000066 train_acc: 0.997447
[6/10][200/469] train_loss: 0.000082 train_acc: 0.996463
[6/10][300/469] train_loss: 0.000086 train_acc: 0.996392
[6/10][400/469] train_loss: 0.000100 train_acc: 0.995889
[Normal training Linear Quantilized testing]AT dataset testing:[6/10] val_loss: 0.130423 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[6/10] val_loss: 3.443853 val_acc: 0.955300
AT dataset testing:[6/10] val_loss: 0.130462 val_acc: 0.000000
Clean dataset testing:[6/10] val_loss: 0.000174 val_acc: 0.992800
[7/10][0/469] train_loss: 0.000007 train_acc: 1.000000
[7/10][100/469] train_loss: 0.000086 train_acc: 0.995746
[7/10][200/469] train_loss: 0.000082 train_acc: 0.996385
[7/10][300/469] train_loss: 0.000081 train_acc: 0.996548
[7/10][400/469] train_loss: 0.000078 train_acc: 0.996649
[Normal training Linear Quantilized testing]AT dataset testing:[7/10] val_loss: 0.152547 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[7/10] val_loss: 3.281828 val_acc: 0.962400
AT dataset testing:[7/10] val_loss: 0.152423 val_acc: 0.000000
Clean dataset testing:[7/10] val_loss: 0.000242 val_acc: 0.991200
[8/10][0/469] train_loss: 0.000057 train_acc: 0.992188
[8/10][100/469] train_loss: 0.000046 train_acc: 0.997757
[8/10][200/469] train_loss: 0.000064 train_acc: 0.997163
[8/10][300/469] train_loss: 0.000062 train_acc: 0.997379
[8/10][400/469] train_loss: 0.000066 train_acc: 0.997195
[Normal training Linear Quantilized testing]AT dataset testing:[8/10] val_loss: 0.155580 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[8/10] val_loss: 3.133307 val_acc: 0.970500
AT dataset testing:[8/10] val_loss: 0.154968 val_acc: 0.000000
Clean dataset testing:[8/10] val_loss: 0.000217 val_acc: 0.992100
[9/10][0/469] train_loss: 0.000291 train_acc: 0.992188
[9/10][100/469] train_loss: 0.000047 train_acc: 0.997912
[9/10][200/469] train_loss: 0.000048 train_acc: 0.997746
[9/10][300/469] train_loss: 0.000055 train_acc: 0.997560
[9/10][400/469] train_loss: 0.000055 train_acc: 0.997448
[Normal training Linear Quantilized testing]AT dataset testing:[9/10] val_loss: 0.169832 val_acc: 0.000000
[Normal training NonLinear Quantilized testing]AT dataset testing:[9/10] val_loss: 7.945893 val_acc: 0.924300
AT dataset testing:[9/10] val_loss: 0.169717 val_acc: 0.000000
Clean dataset testing:[9/10] val_loss: 0.000228 val_acc: 0.991300
