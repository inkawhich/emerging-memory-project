nbits:1
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017997 train_acc: 0.101562
[0/20][100/469] train_loss: 0.010029 train_acc: 0.586247
[0/20][200/469] train_loss: 0.006556 train_acc: 0.731421
[0/20][300/469] train_loss: 0.005188 train_acc: 0.789348
[0/20][400/469] train_loss: 0.004476 train_acc: 0.820118
Clean dataset testing:[0/20] val_loss: 0.001540 val_acc: 0.940500
AT dataset testing:[0/20] val_loss: 0.236767 val_acc: 0.000000
[1/20][0/469] train_loss: 0.001806 train_acc: 0.937500
[1/20][100/469] train_loss: 0.001893 train_acc: 0.928914
[1/20][200/469] train_loss: 0.002067 train_acc: 0.924984
[1/20][300/469] train_loss: 0.002019 train_acc: 0.926625
[1/20][400/469] train_loss: 0.001939 train_acc: 0.928519
Clean dataset testing:[1/20] val_loss: 0.001566 val_acc: 0.942600
AT dataset testing:[1/20] val_loss: 0.236215 val_acc: 0.000000
[2/20][0/469] train_loss: 0.002077 train_acc: 0.914062
[2/20][100/469] train_loss: 0.001658 train_acc: 0.940903
[2/20][200/469] train_loss: 0.001805 train_acc: 0.936256
[2/20][300/469] train_loss: 0.001926 train_acc: 0.932750
[2/20][400/469] train_loss: 0.001896 train_acc: 0.933370
Clean dataset testing:[2/20] val_loss: 0.001147 val_acc: 0.956300
AT dataset testing:[2/20] val_loss: 0.266901 val_acc: 0.000000
[3/20][0/469] train_loss: 0.001523 train_acc: 0.960938
[3/20][100/469] train_loss: 0.001467 train_acc: 0.946550
[3/20][200/469] train_loss: 0.001583 train_acc: 0.942397
[3/20][300/469] train_loss: 0.001637 train_acc: 0.940303
[3/20][400/469] train_loss: 0.001632 train_acc: 0.940578
Clean dataset testing:[3/20] val_loss: 0.001115 val_acc: 0.956700
AT dataset testing:[3/20] val_loss: 0.181582 val_acc: 0.000000
[4/20][0/469] train_loss: 0.001058 train_acc: 0.968750
[4/20][100/469] train_loss: 0.001324 train_acc: 0.948793
[4/20][200/469] train_loss: 0.001542 train_acc: 0.942669
[4/20][300/469] train_loss: 0.001596 train_acc: 0.941705
[4/20][400/469] train_loss: 0.001623 train_acc: 0.940033
Clean dataset testing:[4/20] val_loss: 0.001461 val_acc: 0.939400
AT dataset testing:[4/20] val_loss: 0.246746 val_acc: 0.000000
[5/20][0/469] train_loss: 0.001147 train_acc: 0.937500
[5/20][100/469] train_loss: 0.001793 train_acc: 0.934483
[5/20][200/469] train_loss: 0.001597 train_acc: 0.940571
[5/20][300/469] train_loss: 0.001553 train_acc: 0.942821
[5/20][400/469] train_loss: 0.001580 train_acc: 0.941767
Clean dataset testing:[5/20] val_loss: 0.001319 val_acc: 0.952500
AT dataset testing:[5/20] val_loss: 0.284480 val_acc: 0.000000
[6/20][0/469] train_loss: 0.002300 train_acc: 0.929688
[6/20][100/469] train_loss: 0.002001 train_acc: 0.931467
[6/20][200/469] train_loss: 0.001944 train_acc: 0.933691
[6/20][300/469] train_loss: 0.001938 train_acc: 0.933840
[6/20][400/469] train_loss: 0.001940 train_acc: 0.933409
Clean dataset testing:[6/20] val_loss: 0.001670 val_acc: 0.941100
AT dataset testing:[6/20] val_loss: 0.308397 val_acc: 0.000000
[7/20][0/469] train_loss: 0.002518 train_acc: 0.906250
[7/20][100/469] train_loss: 0.002201 train_acc: 0.924582
[7/20][200/469] train_loss: 0.002201 train_acc: 0.925567
[7/20][300/469] train_loss: 0.002136 train_acc: 0.928026
[7/20][400/469] train_loss: 0.002426 train_acc: 0.921115
Clean dataset testing:[7/20] val_loss: 0.001694 val_acc: 0.934900
AT dataset testing:[7/20] val_loss: 0.293713 val_acc: 0.000000
[8/20][0/469] train_loss: 0.001440 train_acc: 0.937500
[8/20][100/469] train_loss: 0.003022 train_acc: 0.909189
[8/20][200/469] train_loss: 0.003123 train_acc: 0.903607
[8/20][300/469] train_loss: 0.003173 train_acc: 0.905627
[8/20][400/469] train_loss: 0.003248 train_acc: 0.902529
Clean dataset testing:[8/20] val_loss: 0.002728 val_acc: 0.914700
AT dataset testing:[8/20] val_loss: 0.388929 val_acc: 0.000000
[9/20][0/469] train_loss: 0.002920 train_acc: 0.875000
[9/20][100/469] train_loss: 0.003750 train_acc: 0.893951
[9/20][200/469] train_loss: 0.004397 train_acc: 0.872823
[9/20][300/469] train_loss: 0.004364 train_acc: 0.874507
[9/20][400/469] train_loss: 0.004255 train_acc: 0.876792
Clean dataset testing:[9/20] val_loss: 0.002617 val_acc: 0.912300
AT dataset testing:[9/20] val_loss: 0.506626 val_acc: 0.000000
[10/20][0/469] train_loss: 0.002352 train_acc: 0.906250
[10/20][100/469] train_loss: 0.004520 train_acc: 0.859839
[10/20][200/469] train_loss: 0.004371 train_acc: 0.870219
[10/20][300/469] train_loss: 0.004709 train_acc: 0.854677
[10/20][400/469] train_loss: 0.004959 train_acc: 0.853647
Clean dataset testing:[10/20] val_loss: 0.003562 val_acc: 0.884300
AT dataset testing:[10/20] val_loss: 0.317792 val_acc: 0.000200
[11/20][0/469] train_loss: 0.003875 train_acc: 0.875000
[11/20][100/469] train_loss: 0.005069 train_acc: 0.843363
[11/20][200/469] train_loss: 0.005058 train_acc: 0.839280
[11/20][300/469] train_loss: 0.004786 train_acc: 0.847799
[11/20][400/469] train_loss: 0.004808 train_acc: 0.844919
Clean dataset testing:[11/20] val_loss: 0.006003 val_acc: 0.789100
AT dataset testing:[11/20] val_loss: 0.193879 val_acc: 0.000000
[12/20][0/469] train_loss: 0.006883 train_acc: 0.757812
[12/20][100/469] train_loss: 0.006223 train_acc: 0.798499
[12/20][200/469] train_loss: 0.005646 train_acc: 0.811839
[12/20][300/469] train_loss: 0.005696 train_acc: 0.817276
[12/20][400/469] train_loss: 0.005613 train_acc: 0.822280
Clean dataset testing:[12/20] val_loss: 0.003420 val_acc: 0.869100
AT dataset testing:[12/20] val_loss: 0.100741 val_acc: 0.027700
[13/20][0/469] train_loss: 0.002944 train_acc: 0.890625
[13/20][100/469] train_loss: 0.005011 train_acc: 0.841584
[13/20][200/469] train_loss: 0.004904 train_acc: 0.845072
[13/20][300/469] train_loss: 0.005201 train_acc: 0.836872
[13/20][400/469] train_loss: 0.005317 train_acc: 0.833853
Clean dataset testing:[13/20] val_loss: 0.005393 val_acc: 0.806200
AT dataset testing:[13/20] val_loss: 0.300316 val_acc: 0.000400
[14/20][0/469] train_loss: 0.006247 train_acc: 0.789062
[14/20][100/469] train_loss: 0.006386 train_acc: 0.801052
[14/20][200/469] train_loss: 0.006353 train_acc: 0.806942
[14/20][300/469] train_loss: 0.006986 train_acc: 0.790360
[14/20][400/469] train_loss: 0.007165 train_acc: 0.784718
Clean dataset testing:[14/20] val_loss: 0.005532 val_acc: 0.834600
AT dataset testing:[14/20] val_loss: 0.268142 val_acc: 0.000400
[15/20][0/469] train_loss: 0.005370 train_acc: 0.820312
[15/20][100/469] train_loss: 0.007246 train_acc: 0.772200
[15/20][200/469] train_loss: 0.008108 train_acc: 0.750428
[15/20][300/469] train_loss: 0.008270 train_acc: 0.747664
[15/20][400/469] train_loss: 0.008588 train_acc: 0.733187
Clean dataset testing:[15/20] val_loss: 0.007387 val_acc: 0.757100
AT dataset testing:[15/20] val_loss: 0.247229 val_acc: 0.008600
[16/20][0/469] train_loss: 0.006154 train_acc: 0.828125
[16/20][100/469] train_loss: 0.008623 train_acc: 0.711711
[16/20][200/469] train_loss: 0.009465 train_acc: 0.702309
[16/20][300/469] train_loss: 0.009209 train_acc: 0.705461
[16/20][400/469] train_loss: 0.009444 train_acc: 0.705424
Clean dataset testing:[16/20] val_loss: 0.006849 val_acc: 0.721700
AT dataset testing:[16/20] val_loss: 0.181442 val_acc: 0.016500
[17/20][0/469] train_loss: 0.008949 train_acc: 0.679688
[17/20][100/469] train_loss: 0.010843 train_acc: 0.657720
[17/20][200/469] train_loss: 0.009816 train_acc: 0.688549
[17/20][300/469] train_loss: 0.008999 train_acc: 0.717738
[17/20][400/469] train_loss: 0.008788 train_acc: 0.724264
Clean dataset testing:[17/20] val_loss: 0.009910 val_acc: 0.628800
AT dataset testing:[17/20] val_loss: 0.147264 val_acc: 0.018800
[18/20][0/469] train_loss: 0.009471 train_acc: 0.664062
[18/20][100/469] train_loss: 0.010845 train_acc: 0.644647
[18/20][200/469] train_loss: 0.010555 train_acc: 0.668221
[18/20][300/469] train_loss: 0.010463 train_acc: 0.673770
[18/20][400/469] train_loss: 0.010464 train_acc: 0.671057
Clean dataset testing:[18/20] val_loss: 0.014511 val_acc: 0.540200
AT dataset testing:[18/20] val_loss: 0.210108 val_acc: 0.010700
[19/20][0/469] train_loss: 0.017170 train_acc: 0.484375
[19/20][100/469] train_loss: 0.013286 train_acc: 0.608834
[19/20][200/469] train_loss: 0.013466 train_acc: 0.564132
[19/20][300/469] train_loss: 0.013636 train_acc: 0.563486
[19/20][400/469] train_loss: 0.013248 train_acc: 0.572962
Clean dataset testing:[19/20] val_loss: 0.007973 val_acc: 0.700500
AT dataset testing:[19/20] val_loss: 0.018996 val_acc: 0.096700
nbits:2
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018082 train_acc: 0.078125
[0/20][100/469] train_loss: 0.010612 train_acc: 0.544709
[0/20][200/469] train_loss: 0.006908 train_acc: 0.705613
[0/20][300/469] train_loss: 0.005481 train_acc: 0.768376
[0/20][400/469] train_loss: 0.004646 train_acc: 0.805369
Clean dataset testing:[0/20] val_loss: 0.001465 val_acc: 0.943800
AT dataset testing:[0/20] val_loss: 0.082617 val_acc: 0.000000
[1/20][0/469] train_loss: 0.002038 train_acc: 0.898438
[1/20][100/469] train_loss: 0.001871 train_acc: 0.926516
[1/20][200/469] train_loss: 0.001784 train_acc: 0.931670
[1/20][300/469] train_loss: 0.001678 train_acc: 0.936721
[1/20][400/469] train_loss: 0.001637 train_acc: 0.939175
Clean dataset testing:[1/20] val_loss: 0.001177 val_acc: 0.961000
AT dataset testing:[1/20] val_loss: 0.161562 val_acc: 0.000200
[2/20][0/469] train_loss: 0.001673 train_acc: 0.953125
[2/20][100/469] train_loss: 0.001532 train_acc: 0.941754
[2/20][200/469] train_loss: 0.001490 train_acc: 0.945002
[2/20][300/469] train_loss: 0.001396 train_acc: 0.948038
[2/20][400/469] train_loss: 0.001384 train_acc: 0.948430
Clean dataset testing:[2/20] val_loss: 0.002170 val_acc: 0.920400
AT dataset testing:[2/20] val_loss: 0.078477 val_acc: 0.000000
[3/20][0/469] train_loss: 0.002606 train_acc: 0.890625
[3/20][100/469] train_loss: 0.001307 train_acc: 0.952119
[3/20][200/469] train_loss: 0.001416 train_acc: 0.949433
[3/20][300/469] train_loss: 0.001387 train_acc: 0.949647
[3/20][400/469] train_loss: 0.001349 train_acc: 0.950982
Clean dataset testing:[3/20] val_loss: 0.000987 val_acc: 0.960100
AT dataset testing:[3/20] val_loss: 0.125133 val_acc: 0.000000
[4/20][0/469] train_loss: 0.001756 train_acc: 0.945312
[4/20][100/469] train_loss: 0.001189 train_acc: 0.957457
[4/20][200/469] train_loss: 0.001301 train_acc: 0.952931
[4/20][300/469] train_loss: 0.001298 train_acc: 0.953411
[4/20][400/469] train_loss: 0.001300 train_acc: 0.953982
Clean dataset testing:[4/20] val_loss: 0.000785 val_acc: 0.968400
AT dataset testing:[4/20] val_loss: 0.151457 val_acc: 0.000000
[5/20][0/469] train_loss: 0.001802 train_acc: 0.945312
[5/20][100/469] train_loss: 0.001468 train_acc: 0.950418
[5/20][200/469] train_loss: 0.001333 train_acc: 0.953747
[5/20][300/469] train_loss: 0.001332 train_acc: 0.953462
[5/20][400/469] train_loss: 0.001346 train_acc: 0.953125
Clean dataset testing:[5/20] val_loss: 0.001749 val_acc: 0.965200
AT dataset testing:[5/20] val_loss: 0.371575 val_acc: 0.001300
[6/20][0/469] train_loss: 0.001480 train_acc: 0.953125
[6/20][100/469] train_loss: 0.001343 train_acc: 0.957843
[6/20][200/469] train_loss: 0.001343 train_acc: 0.955146
[6/20][300/469] train_loss: 0.001460 train_acc: 0.951023
[6/20][400/469] train_loss: 0.001547 train_acc: 0.948449
Clean dataset testing:[6/20] val_loss: 0.002209 val_acc: 0.952000
AT dataset testing:[6/20] val_loss: 0.374448 val_acc: 0.000200
[7/20][0/469] train_loss: 0.003052 train_acc: 0.937500
[7/20][100/469] train_loss: 0.001772 train_acc: 0.950340
[7/20][200/469] train_loss: 0.001722 train_acc: 0.949083
[7/20][300/469] train_loss: 0.001756 train_acc: 0.948479
[7/20][400/469] train_loss: 0.001718 train_acc: 0.949638
Clean dataset testing:[7/20] val_loss: 0.001715 val_acc: 0.929700
AT dataset testing:[7/20] val_loss: 0.150284 val_acc: 0.000000
[8/20][0/469] train_loss: 0.001393 train_acc: 0.953125
[8/20][100/469] train_loss: 0.001789 train_acc: 0.944539
[8/20][200/469] train_loss: 0.001737 train_acc: 0.946206
[8/20][300/469] train_loss: 0.001892 train_acc: 0.943937
[8/20][400/469] train_loss: 0.001943 train_acc: 0.943520
Clean dataset testing:[8/20] val_loss: 0.004267 val_acc: 0.936500
AT dataset testing:[8/20] val_loss: 0.569493 val_acc: 0.000000
[9/20][0/469] train_loss: 0.004981 train_acc: 0.929688
[9/20][100/469] train_loss: 0.002263 train_acc: 0.950572
[9/20][200/469] train_loss: 0.002114 train_acc: 0.948539
[9/20][300/469] train_loss: 0.002034 train_acc: 0.948816
[9/20][400/469] train_loss: 0.001918 train_acc: 0.950729
Clean dataset testing:[9/20] val_loss: 0.001426 val_acc: 0.942300
AT dataset testing:[9/20] val_loss: 0.123040 val_acc: 0.000000
[10/20][0/469] train_loss: 0.001295 train_acc: 0.960938
[10/20][100/469] train_loss: 0.002093 train_acc: 0.945777
[10/20][200/469] train_loss: 0.002023 train_acc: 0.947878
[10/20][300/469] train_loss: 0.001910 train_acc: 0.950270
[10/20][400/469] train_loss: 0.001880 train_acc: 0.949443
Clean dataset testing:[10/20] val_loss: 0.001353 val_acc: 0.964900
AT dataset testing:[10/20] val_loss: 0.261582 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000282 train_acc: 0.992188
[11/20][100/469] train_loss: 0.003087 train_acc: 0.924273
[11/20][200/469] train_loss: 0.002997 train_acc: 0.927083
[11/20][300/469] train_loss: 0.002637 train_acc: 0.934697
[11/20][400/469] train_loss: 0.002628 train_acc: 0.934344
Clean dataset testing:[11/20] val_loss: 0.003442 val_acc: 0.898400
AT dataset testing:[11/20] val_loss: 0.257236 val_acc: 0.000000
[12/20][0/469] train_loss: 0.001909 train_acc: 0.929688
[12/20][100/469] train_loss: 0.002234 train_acc: 0.937732
[12/20][200/469] train_loss: 0.002193 train_acc: 0.939871
[12/20][300/469] train_loss: 0.002057 train_acc: 0.943288
[12/20][400/469] train_loss: 0.002016 train_acc: 0.944748
Clean dataset testing:[12/20] val_loss: 0.001017 val_acc: 0.968700
AT dataset testing:[12/20] val_loss: 0.185589 val_acc: 0.000000
[13/20][0/469] train_loss: 0.001292 train_acc: 0.976562
[13/20][100/469] train_loss: 0.001801 train_acc: 0.943611
[13/20][200/469] train_loss: 0.002061 train_acc: 0.945701
[13/20][300/469] train_loss: 0.002116 train_acc: 0.949232
[13/20][400/469] train_loss: 0.001969 train_acc: 0.951294
Clean dataset testing:[13/20] val_loss: 0.001847 val_acc: 0.961400
AT dataset testing:[13/20] val_loss: 0.046815 val_acc: 0.000000
[14/20][0/469] train_loss: 0.001648 train_acc: 0.960938
[14/20][100/469] train_loss: 0.002169 train_acc: 0.953434
[14/20][200/469] train_loss: 0.001886 train_acc: 0.952503
[14/20][300/469] train_loss: 0.002093 train_acc: 0.949362
[14/20][400/469] train_loss: 0.002074 train_acc: 0.949638
Clean dataset testing:[14/20] val_loss: 0.001033 val_acc: 0.959800
AT dataset testing:[14/20] val_loss: 0.086562 val_acc: 0.000100
[15/20][0/469] train_loss: 0.000802 train_acc: 0.968750
[15/20][100/469] train_loss: 0.002684 train_acc: 0.945003
[15/20][200/469] train_loss: 0.002570 train_acc: 0.944963
[15/20][300/469] train_loss: 0.002535 train_acc: 0.945702
[15/20][400/469] train_loss: 0.002326 train_acc: 0.947631
Clean dataset testing:[15/20] val_loss: 0.001697 val_acc: 0.942200
AT dataset testing:[15/20] val_loss: 0.221400 val_acc: 0.000000
[16/20][0/469] train_loss: 0.002615 train_acc: 0.921875
[16/20][100/469] train_loss: 0.002848 train_acc: 0.934947
[16/20][200/469] train_loss: 0.002331 train_acc: 0.943991
[16/20][300/469] train_loss: 0.002309 train_acc: 0.944170
[16/20][400/469] train_loss: 0.002071 train_acc: 0.947689
Clean dataset testing:[16/20] val_loss: 0.001140 val_acc: 0.962500
AT dataset testing:[16/20] val_loss: 0.131907 val_acc: 0.000000
[17/20][0/469] train_loss: 0.001456 train_acc: 0.953125
[17/20][100/469] train_loss: 0.001955 train_acc: 0.948948
[17/20][200/469] train_loss: 0.001652 train_acc: 0.952736
[17/20][300/469] train_loss: 0.001654 train_acc: 0.953618
[17/20][400/469] train_loss: 0.002003 train_acc: 0.952190
Clean dataset testing:[17/20] val_loss: 0.005223 val_acc: 0.962400
AT dataset testing:[17/20] val_loss: 1.072191 val_acc: 0.004200
[18/20][0/469] train_loss: 0.005640 train_acc: 0.945312
[18/20][100/469] train_loss: 0.003415 train_acc: 0.919787
[18/20][200/469] train_loss: 0.003823 train_acc: 0.922808
[18/20][300/469] train_loss: 0.003864 train_acc: 0.924367
[18/20][400/469] train_loss: 0.003896 train_acc: 0.926337
Clean dataset testing:[18/20] val_loss: 0.001581 val_acc: 0.957900
AT dataset testing:[18/20] val_loss: 0.172874 val_acc: 0.000000
[19/20][0/469] train_loss: 0.001164 train_acc: 0.960938
[19/20][100/469] train_loss: 0.004485 train_acc: 0.913366
[19/20][200/469] train_loss: 0.003778 train_acc: 0.918804
[19/20][300/469] train_loss: 0.003957 train_acc: 0.921044
[19/20][400/469] train_loss: 0.003957 train_acc: 0.921700
Clean dataset testing:[19/20] val_loss: 0.000803 val_acc: 0.970200
AT dataset testing:[19/20] val_loss: 0.125617 val_acc: 0.000000
nbits:3
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018020 train_acc: 0.085938
[0/20][100/469] train_loss: 0.011792 train_acc: 0.527614
[0/20][200/469] train_loss: 0.007863 train_acc: 0.687889
[0/20][300/469] train_loss: 0.006130 train_acc: 0.757527
[0/20][400/469] train_loss: 0.005107 train_acc: 0.799057
Clean dataset testing:[0/20] val_loss: 0.001693 val_acc: 0.933800
AT dataset testing:[0/20] val_loss: 0.081493 val_acc: 0.000200
[1/20][0/469] train_loss: 0.001628 train_acc: 0.945312
[1/20][100/469] train_loss: 0.001440 train_acc: 0.944616
[1/20][200/469] train_loss: 0.001396 train_acc: 0.946595
[1/20][300/469] train_loss: 0.001349 train_acc: 0.948453
[1/20][400/469] train_loss: 0.001308 train_acc: 0.949793
Clean dataset testing:[1/20] val_loss: 0.000973 val_acc: 0.960500
AT dataset testing:[1/20] val_loss: 0.093294 val_acc: 0.000000
[2/20][0/469] train_loss: 0.001281 train_acc: 0.945312
[2/20][100/469] train_loss: 0.001034 train_acc: 0.960241
[2/20][200/469] train_loss: 0.001061 train_acc: 0.958994
[2/20][300/469] train_loss: 0.001056 train_acc: 0.958887
[2/20][400/469] train_loss: 0.001022 train_acc: 0.960353
Clean dataset testing:[2/20] val_loss: 0.001081 val_acc: 0.954000
AT dataset testing:[2/20] val_loss: 0.128487 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000585 train_acc: 0.976562
[3/20][100/469] train_loss: 0.000973 train_acc: 0.961711
[3/20][200/469] train_loss: 0.000899 train_acc: 0.965019
[3/20][300/469] train_loss: 0.000869 train_acc: 0.966129
[3/20][400/469] train_loss: 0.000883 train_acc: 0.965711
Clean dataset testing:[3/20] val_loss: 0.000777 val_acc: 0.971400
AT dataset testing:[3/20] val_loss: 0.130572 val_acc: 0.000100
[4/20][0/469] train_loss: 0.001319 train_acc: 0.945312
[4/20][100/469] train_loss: 0.000785 train_acc: 0.970142
[4/20][200/469] train_loss: 0.000764 train_acc: 0.970460
[4/20][300/469] train_loss: 0.000745 train_acc: 0.971371
[4/20][400/469] train_loss: 0.000757 train_acc: 0.970776
Clean dataset testing:[4/20] val_loss: 0.000721 val_acc: 0.972200
AT dataset testing:[4/20] val_loss: 0.115732 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000470 train_acc: 0.968750
[5/20][100/469] train_loss: 0.000731 train_acc: 0.969291
[5/20][200/469] train_loss: 0.000676 train_acc: 0.972326
[5/20][300/469] train_loss: 0.000687 train_acc: 0.972358
[5/20][400/469] train_loss: 0.000693 train_acc: 0.972510
Clean dataset testing:[5/20] val_loss: 0.000506 val_acc: 0.979400
AT dataset testing:[5/20] val_loss: 0.134365 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000885 train_acc: 0.976562
[6/20][100/469] train_loss: 0.000600 train_acc: 0.975480
[6/20][200/469] train_loss: 0.000600 train_acc: 0.976446
[6/20][300/469] train_loss: 0.000610 train_acc: 0.976277
[6/20][400/469] train_loss: 0.000621 train_acc: 0.975705
Clean dataset testing:[6/20] val_loss: 0.000592 val_acc: 0.977000
AT dataset testing:[6/20] val_loss: 0.112258 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000386 train_acc: 0.968750
[7/20][100/469] train_loss: 0.000529 train_acc: 0.978264
[7/20][200/469] train_loss: 0.000579 train_acc: 0.977146
[7/20][300/469] train_loss: 0.000573 train_acc: 0.977341
[7/20][400/469] train_loss: 0.000571 train_acc: 0.977576
Clean dataset testing:[7/20] val_loss: 0.000477 val_acc: 0.980800
AT dataset testing:[7/20] val_loss: 0.100311 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000408 train_acc: 0.976562
[8/20][100/469] train_loss: 0.000540 train_acc: 0.978496
[8/20][200/469] train_loss: 0.000549 train_acc: 0.977884
[8/20][300/469] train_loss: 0.000530 train_acc: 0.978535
[8/20][400/469] train_loss: 0.000533 train_acc: 0.978686
Clean dataset testing:[8/20] val_loss: 0.000493 val_acc: 0.979000
AT dataset testing:[8/20] val_loss: 0.105369 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000704 train_acc: 0.968750
[9/20][100/469] train_loss: 0.000501 train_acc: 0.981126
[9/20][200/469] train_loss: 0.000495 train_acc: 0.980799
[9/20][300/469] train_loss: 0.000489 train_acc: 0.980871
[9/20][400/469] train_loss: 0.000494 train_acc: 0.980556
Clean dataset testing:[9/20] val_loss: 0.000481 val_acc: 0.980700
AT dataset testing:[9/20] val_loss: 0.137467 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000987 train_acc: 0.968750
[10/20][100/469] train_loss: 0.000511 train_acc: 0.979811
[10/20][200/469] train_loss: 0.000546 train_acc: 0.978273
[10/20][300/469] train_loss: 0.000532 train_acc: 0.978691
[10/20][400/469] train_loss: 0.000543 train_acc: 0.978589
Clean dataset testing:[10/20] val_loss: 0.000463 val_acc: 0.981500
AT dataset testing:[10/20] val_loss: 0.123286 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000307 train_acc: 0.992188
[11/20][100/469] train_loss: 0.000504 train_acc: 0.980817
[11/20][200/469] train_loss: 0.000467 train_acc: 0.981732
[11/20][300/469] train_loss: 0.000470 train_acc: 0.981754
[11/20][400/469] train_loss: 0.000474 train_acc: 0.981277
Clean dataset testing:[11/20] val_loss: 0.000418 val_acc: 0.983000
AT dataset testing:[11/20] val_loss: 0.116530 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000234 train_acc: 0.984375
[12/20][100/469] train_loss: 0.000428 train_acc: 0.983601
[12/20][200/469] train_loss: 0.000446 train_acc: 0.982315
[12/20][300/469] train_loss: 0.000450 train_acc: 0.982169
[12/20][400/469] train_loss: 0.000461 train_acc: 0.981764
Clean dataset testing:[12/20] val_loss: 0.000333 val_acc: 0.985600
AT dataset testing:[12/20] val_loss: 0.119935 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000121 train_acc: 1.000000
[13/20][100/469] train_loss: 0.000455 train_acc: 0.981513
[13/20][200/469] train_loss: 0.000437 train_acc: 0.982198
[13/20][300/469] train_loss: 0.000453 train_acc: 0.982247
[13/20][400/469] train_loss: 0.000455 train_acc: 0.982368
Clean dataset testing:[13/20] val_loss: 0.000521 val_acc: 0.981400
AT dataset testing:[13/20] val_loss: 0.202690 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000198 train_acc: 0.992188
[14/20][100/469] train_loss: 0.000426 train_acc: 0.983060
[14/20][200/469] train_loss: 0.000434 train_acc: 0.982470
[14/20][300/469] train_loss: 0.000450 train_acc: 0.981831
[14/20][400/469] train_loss: 0.000465 train_acc: 0.981121
Clean dataset testing:[14/20] val_loss: 0.000402 val_acc: 0.982900
AT dataset testing:[14/20] val_loss: 0.158507 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000574 train_acc: 0.992188
[15/20][100/469] train_loss: 0.000386 train_acc: 0.984530
[15/20][200/469] train_loss: 0.000395 train_acc: 0.984569
[15/20][300/469] train_loss: 0.000387 train_acc: 0.984479
[15/20][400/469] train_loss: 0.000399 train_acc: 0.984102
Clean dataset testing:[15/20] val_loss: 0.000391 val_acc: 0.984700
AT dataset testing:[15/20] val_loss: 0.127770 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000197 train_acc: 0.992188
[16/20][100/469] train_loss: 0.000400 train_acc: 0.983060
[16/20][200/469] train_loss: 0.000417 train_acc: 0.983053
[16/20][300/469] train_loss: 0.000405 train_acc: 0.983622
[16/20][400/469] train_loss: 0.000398 train_acc: 0.983927
Clean dataset testing:[16/20] val_loss: 0.000346 val_acc: 0.986400
AT dataset testing:[16/20] val_loss: 0.132330 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000078 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000347 train_acc: 0.985458
[17/20][200/469] train_loss: 0.000359 train_acc: 0.984725
[17/20][300/469] train_loss: 0.000366 train_acc: 0.984712
[17/20][400/469] train_loss: 0.000390 train_acc: 0.984083
Clean dataset testing:[17/20] val_loss: 0.000383 val_acc: 0.985400
AT dataset testing:[17/20] val_loss: 0.165002 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000272 train_acc: 0.976562
[18/20][100/469] train_loss: 0.000394 train_acc: 0.983911
[18/20][200/469] train_loss: 0.000376 train_acc: 0.985269
[18/20][300/469] train_loss: 0.000383 train_acc: 0.984998
[18/20][400/469] train_loss: 0.000382 train_acc: 0.985076
Clean dataset testing:[18/20] val_loss: 0.000323 val_acc: 0.986600
AT dataset testing:[18/20] val_loss: 0.126485 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000224 train_acc: 0.984375
[19/20][100/469] train_loss: 0.000396 train_acc: 0.983834
[19/20][200/469] train_loss: 0.000385 train_acc: 0.984841
[19/20][300/469] train_loss: 0.000391 train_acc: 0.984764
[19/20][400/469] train_loss: 0.000393 train_acc: 0.984706
Clean dataset testing:[19/20] val_loss: 0.000626 val_acc: 0.974600
AT dataset testing:[19/20] val_loss: 0.164051 val_acc: 0.000000
nbits:4
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017943 train_acc: 0.093750
[0/20][100/469] train_loss: 0.011510 train_acc: 0.531405
[0/20][200/469] train_loss: 0.007844 train_acc: 0.679688
[0/20][300/469] train_loss: 0.006117 train_acc: 0.751168
[0/20][400/469] train_loss: 0.005084 train_acc: 0.793972
Clean dataset testing:[0/20] val_loss: 0.001692 val_acc: 0.929100
AT dataset testing:[0/20] val_loss: 0.081477 val_acc: 0.000000
[1/20][0/469] train_loss: 0.002238 train_acc: 0.906250
[1/20][100/469] train_loss: 0.001502 train_acc: 0.940130
[1/20][200/469] train_loss: 0.001418 train_acc: 0.943719
[1/20][300/469] train_loss: 0.001365 train_acc: 0.945209
[1/20][400/469] train_loss: 0.001305 train_acc: 0.947572
Clean dataset testing:[1/20] val_loss: 0.000832 val_acc: 0.968300
AT dataset testing:[1/20] val_loss: 0.083852 val_acc: 0.000000
[2/20][0/469] train_loss: 0.001334 train_acc: 0.945312
[2/20][100/469] train_loss: 0.001089 train_acc: 0.957070
[2/20][200/469] train_loss: 0.000980 train_acc: 0.960432
[2/20][300/469] train_loss: 0.000953 train_acc: 0.961690
[2/20][400/469] train_loss: 0.000934 train_acc: 0.962438
Clean dataset testing:[2/20] val_loss: 0.000759 val_acc: 0.969100
AT dataset testing:[2/20] val_loss: 0.099089 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000917 train_acc: 0.960938
[3/20][100/469] train_loss: 0.000798 train_acc: 0.966275
[3/20][200/469] train_loss: 0.000783 train_acc: 0.968478
[3/20][300/469] train_loss: 0.000781 train_acc: 0.968231
[3/20][400/469] train_loss: 0.000769 train_acc: 0.968886
Clean dataset testing:[3/20] val_loss: 0.000575 val_acc: 0.976400
AT dataset testing:[3/20] val_loss: 0.099486 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000298 train_acc: 0.992188
[4/20][100/469] train_loss: 0.000649 train_acc: 0.973623
[4/20][200/469] train_loss: 0.000636 train_acc: 0.975008
[4/20][300/469] train_loss: 0.000657 train_acc: 0.974201
[4/20][400/469] train_loss: 0.000648 train_acc: 0.974010
Clean dataset testing:[4/20] val_loss: 0.000476 val_acc: 0.980500
AT dataset testing:[4/20] val_loss: 0.102669 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000487 train_acc: 0.992188
[5/20][100/469] train_loss: 0.000622 train_acc: 0.976098
[5/20][200/469] train_loss: 0.000595 train_acc: 0.976912
[5/20][300/469] train_loss: 0.000593 train_acc: 0.976770
[5/20][400/469] train_loss: 0.000593 train_acc: 0.976738
Clean dataset testing:[5/20] val_loss: 0.000525 val_acc: 0.978900
AT dataset testing:[5/20] val_loss: 0.114224 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000707 train_acc: 0.984375
[6/20][100/469] train_loss: 0.000558 train_acc: 0.979192
[6/20][200/469] train_loss: 0.000559 train_acc: 0.978506
[6/20][300/469] train_loss: 0.000536 train_acc: 0.979314
[6/20][400/469] train_loss: 0.000545 train_acc: 0.978472
Clean dataset testing:[6/20] val_loss: 0.000451 val_acc: 0.982200
AT dataset testing:[6/20] val_loss: 0.110747 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000486 train_acc: 0.984375
[7/20][100/469] train_loss: 0.000495 train_acc: 0.980043
[7/20][200/469] train_loss: 0.000502 train_acc: 0.979594
[7/20][300/469] train_loss: 0.000485 train_acc: 0.980274
[7/20][400/469] train_loss: 0.000492 train_acc: 0.980011
Clean dataset testing:[7/20] val_loss: 0.000436 val_acc: 0.981900
AT dataset testing:[7/20] val_loss: 0.123143 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000498 train_acc: 0.976562
[8/20][100/469] train_loss: 0.000452 train_acc: 0.982596
[8/20][200/469] train_loss: 0.000430 train_acc: 0.983092
[8/20][300/469] train_loss: 0.000432 train_acc: 0.983025
[8/20][400/469] train_loss: 0.000430 train_acc: 0.983050
Clean dataset testing:[8/20] val_loss: 0.000352 val_acc: 0.984400
AT dataset testing:[8/20] val_loss: 0.120029 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000181 train_acc: 1.000000
[9/20][100/469] train_loss: 0.000345 train_acc: 0.985613
[9/20][200/469] train_loss: 0.000376 train_acc: 0.984647
[9/20][300/469] train_loss: 0.000401 train_acc: 0.983700
[9/20][400/469] train_loss: 0.000397 train_acc: 0.983985
Clean dataset testing:[9/20] val_loss: 0.000366 val_acc: 0.984000
AT dataset testing:[9/20] val_loss: 0.132078 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000133 train_acc: 1.000000
[10/20][100/469] train_loss: 0.000335 train_acc: 0.986928
[10/20][200/469] train_loss: 0.000353 train_acc: 0.986435
[10/20][300/469] train_loss: 0.000359 train_acc: 0.985647
[10/20][400/469] train_loss: 0.000368 train_acc: 0.985486
Clean dataset testing:[10/20] val_loss: 0.000388 val_acc: 0.983500
AT dataset testing:[10/20] val_loss: 0.128360 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000385 train_acc: 0.984375
[11/20][100/469] train_loss: 0.000354 train_acc: 0.986309
[11/20][200/469] train_loss: 0.000341 train_acc: 0.986280
[11/20][300/469] train_loss: 0.000354 train_acc: 0.985803
[11/20][400/469] train_loss: 0.000359 train_acc: 0.985408
Clean dataset testing:[11/20] val_loss: 0.000352 val_acc: 0.985900
AT dataset testing:[11/20] val_loss: 0.131479 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000536 train_acc: 0.992188
[12/20][100/469] train_loss: 0.000333 train_acc: 0.987778
[12/20][200/469] train_loss: 0.000315 train_acc: 0.987718
[12/20][300/469] train_loss: 0.000327 train_acc: 0.986919
[12/20][400/469] train_loss: 0.000334 train_acc: 0.986479
Clean dataset testing:[12/20] val_loss: 0.000396 val_acc: 0.983600
AT dataset testing:[12/20] val_loss: 0.138234 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000435 train_acc: 0.976562
[13/20][100/469] train_loss: 0.000324 train_acc: 0.987237
[13/20][200/469] train_loss: 0.000308 train_acc: 0.988340
[13/20][300/469] train_loss: 0.000308 train_acc: 0.988528
[13/20][400/469] train_loss: 0.000307 train_acc: 0.988369
Clean dataset testing:[13/20] val_loss: 0.000290 val_acc: 0.987700
AT dataset testing:[13/20] val_loss: 0.138057 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000058 train_acc: 1.000000
[14/20][100/469] train_loss: 0.000282 train_acc: 0.989325
[14/20][200/469] train_loss: 0.000291 train_acc: 0.989156
[14/20][300/469] train_loss: 0.000292 train_acc: 0.988528
[14/20][400/469] train_loss: 0.000297 train_acc: 0.988116
Clean dataset testing:[14/20] val_loss: 0.000394 val_acc: 0.984600
AT dataset testing:[14/20] val_loss: 0.169165 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000395 train_acc: 0.992188
[15/20][100/469] train_loss: 0.000266 train_acc: 0.990099
[15/20][200/469] train_loss: 0.000294 train_acc: 0.988806
[15/20][300/469] train_loss: 0.000289 train_acc: 0.988917
[15/20][400/469] train_loss: 0.000286 train_acc: 0.989168
Clean dataset testing:[15/20] val_loss: 0.000311 val_acc: 0.987700
AT dataset testing:[15/20] val_loss: 0.164424 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000105 train_acc: 1.000000
[16/20][100/469] train_loss: 0.000243 train_acc: 0.989016
[16/20][200/469] train_loss: 0.000255 train_acc: 0.989156
[16/20][300/469] train_loss: 0.000260 train_acc: 0.989099
[16/20][400/469] train_loss: 0.000255 train_acc: 0.989226
Clean dataset testing:[16/20] val_loss: 0.000308 val_acc: 0.987200
AT dataset testing:[16/20] val_loss: 0.158072 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000026 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000238 train_acc: 0.988861
[17/20][200/469] train_loss: 0.000244 train_acc: 0.988534
[17/20][300/469] train_loss: 0.000244 train_acc: 0.989021
[17/20][400/469] train_loss: 0.000253 train_acc: 0.988778
Clean dataset testing:[17/20] val_loss: 0.000329 val_acc: 0.985600
AT dataset testing:[17/20] val_loss: 0.146258 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000262 train_acc: 0.976562
[18/20][100/469] train_loss: 0.000222 train_acc: 0.990254
[18/20][200/469] train_loss: 0.000237 train_acc: 0.990011
[18/20][300/469] train_loss: 0.000246 train_acc: 0.989644
[18/20][400/469] train_loss: 0.000243 train_acc: 0.989830
Clean dataset testing:[18/20] val_loss: 0.000312 val_acc: 0.987600
AT dataset testing:[18/20] val_loss: 0.165780 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000155 train_acc: 0.992188
[19/20][100/469] train_loss: 0.000239 train_acc: 0.989944
[19/20][200/469] train_loss: 0.000240 train_acc: 0.989855
[19/20][300/469] train_loss: 0.000242 train_acc: 0.990111
[19/20][400/469] train_loss: 0.000242 train_acc: 0.989947
Clean dataset testing:[19/20] val_loss: 0.000321 val_acc: 0.988000
AT dataset testing:[19/20] val_loss: 0.175473 val_acc: 0.000000
nbits:5
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018035 train_acc: 0.117188
[0/20][100/469] train_loss: 0.010746 train_acc: 0.582921
[0/20][200/469] train_loss: 0.006927 train_acc: 0.729516
[0/20][300/469] train_loss: 0.005323 train_acc: 0.791762
[0/20][400/469] train_loss: 0.004402 train_acc: 0.827560
Clean dataset testing:[0/20] val_loss: 0.001172 val_acc: 0.955400
AT dataset testing:[0/20] val_loss: 0.084373 val_acc: 0.000000
[1/20][0/469] train_loss: 0.001392 train_acc: 0.953125
[1/20][100/469] train_loss: 0.001287 train_acc: 0.949025
[1/20][200/469] train_loss: 0.001212 train_acc: 0.951337
[1/20][300/469] train_loss: 0.001174 train_acc: 0.953151
[1/20][400/469] train_loss: 0.001104 train_acc: 0.956047
Clean dataset testing:[1/20] val_loss: 0.000962 val_acc: 0.960100
AT dataset testing:[1/20] val_loss: 0.092709 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000508 train_acc: 0.976562
[2/20][100/469] train_loss: 0.000822 train_acc: 0.968131
[2/20][200/469] train_loss: 0.000839 train_acc: 0.967895
[2/20][300/469] train_loss: 0.000823 train_acc: 0.967426
[2/20][400/469] train_loss: 0.000817 train_acc: 0.967484
Clean dataset testing:[2/20] val_loss: 0.000676 val_acc: 0.971400
AT dataset testing:[2/20] val_loss: 0.100433 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000905 train_acc: 0.953125
[3/20][100/469] train_loss: 0.000752 train_acc: 0.969446
[3/20][200/469] train_loss: 0.000709 train_acc: 0.971393
[3/20][300/469] train_loss: 0.000699 train_acc: 0.972124
[3/20][400/469] train_loss: 0.000688 train_acc: 0.972471
Clean dataset testing:[3/20] val_loss: 0.000551 val_acc: 0.978700
AT dataset testing:[3/20] val_loss: 0.112733 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000806 train_acc: 0.976562
[4/20][100/469] train_loss: 0.000590 train_acc: 0.976176
[4/20][200/469] train_loss: 0.000589 train_acc: 0.976368
[4/20][300/469] train_loss: 0.000598 train_acc: 0.976017
[4/20][400/469] train_loss: 0.000597 train_acc: 0.976114
Clean dataset testing:[4/20] val_loss: 0.000469 val_acc: 0.980900
AT dataset testing:[4/20] val_loss: 0.113576 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000372 train_acc: 0.976562
[5/20][100/469] train_loss: 0.000495 train_acc: 0.980043
[5/20][200/469] train_loss: 0.000508 train_acc: 0.979711
[5/20][300/469] train_loss: 0.000519 train_acc: 0.978847
[5/20][400/469] train_loss: 0.000523 train_acc: 0.978667
Clean dataset testing:[5/20] val_loss: 0.000384 val_acc: 0.984700
AT dataset testing:[5/20] val_loss: 0.119885 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000257 train_acc: 0.984375
[6/20][100/469] train_loss: 0.000478 train_acc: 0.980817
[6/20][200/469] train_loss: 0.000462 train_acc: 0.981382
[6/20][300/469] train_loss: 0.000456 train_acc: 0.981286
[6/20][400/469] train_loss: 0.000459 train_acc: 0.981336
Clean dataset testing:[6/20] val_loss: 0.000411 val_acc: 0.982300
AT dataset testing:[6/20] val_loss: 0.126458 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000473 train_acc: 0.976562
[7/20][100/469] train_loss: 0.000393 train_acc: 0.984375
[7/20][200/469] train_loss: 0.000404 train_acc: 0.983714
[7/20][300/469] train_loss: 0.000408 train_acc: 0.983467
[7/20][400/469] train_loss: 0.000417 train_acc: 0.983070
Clean dataset testing:[7/20] val_loss: 0.000392 val_acc: 0.984400
AT dataset testing:[7/20] val_loss: 0.130321 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000524 train_acc: 0.976562
[8/20][100/469] train_loss: 0.000373 train_acc: 0.984839
[8/20][200/469] train_loss: 0.000354 train_acc: 0.985113
[8/20][300/469] train_loss: 0.000363 train_acc: 0.984894
[8/20][400/469] train_loss: 0.000391 train_acc: 0.983752
Clean dataset testing:[8/20] val_loss: 0.000334 val_acc: 0.986800
AT dataset testing:[8/20] val_loss: 0.129040 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000157 train_acc: 0.992188
[9/20][100/469] train_loss: 0.000362 train_acc: 0.986077
[9/20][200/469] train_loss: 0.000359 train_acc: 0.986046
[9/20][300/469] train_loss: 0.000361 train_acc: 0.985647
[9/20][400/469] train_loss: 0.000361 train_acc: 0.985447
Clean dataset testing:[9/20] val_loss: 0.000353 val_acc: 0.985100
AT dataset testing:[9/20] val_loss: 0.141102 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000068 train_acc: 1.000000
[10/20][100/469] train_loss: 0.000363 train_acc: 0.985381
[10/20][200/469] train_loss: 0.000343 train_acc: 0.986668
[10/20][300/469] train_loss: 0.000341 train_acc: 0.986451
[10/20][400/469] train_loss: 0.000336 train_acc: 0.986557
Clean dataset testing:[10/20] val_loss: 0.000474 val_acc: 0.979300
AT dataset testing:[10/20] val_loss: 0.143534 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000105 train_acc: 1.000000
[11/20][100/469] train_loss: 0.000346 train_acc: 0.985845
[11/20][200/469] train_loss: 0.000321 train_acc: 0.986863
[11/20][300/469] train_loss: 0.000335 train_acc: 0.986400
[11/20][400/469] train_loss: 0.000333 train_acc: 0.986518
Clean dataset testing:[11/20] val_loss: 0.000354 val_acc: 0.984900
AT dataset testing:[11/20] val_loss: 0.151261 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000249 train_acc: 0.976562
[12/20][100/469] train_loss: 0.000313 train_acc: 0.988088
[12/20][200/469] train_loss: 0.000293 train_acc: 0.988417
[12/20][300/469] train_loss: 0.000288 train_acc: 0.988320
[12/20][400/469] train_loss: 0.000295 train_acc: 0.988330
Clean dataset testing:[12/20] val_loss: 0.000305 val_acc: 0.988300
AT dataset testing:[12/20] val_loss: 0.147888 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000251 train_acc: 0.992188
[13/20][100/469] train_loss: 0.000245 train_acc: 0.990022
[13/20][200/469] train_loss: 0.000260 train_acc: 0.989817
[13/20][300/469] train_loss: 0.000269 train_acc: 0.989410
[13/20][400/469] train_loss: 0.000279 train_acc: 0.988914
Clean dataset testing:[13/20] val_loss: 0.000330 val_acc: 0.986700
AT dataset testing:[13/20] val_loss: 0.153866 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000214 train_acc: 0.992188
[14/20][100/469] train_loss: 0.000270 train_acc: 0.988088
[14/20][200/469] train_loss: 0.000269 train_acc: 0.988806
[14/20][300/469] train_loss: 0.000263 train_acc: 0.988787
[14/20][400/469] train_loss: 0.000265 train_acc: 0.989051
Clean dataset testing:[14/20] val_loss: 0.000399 val_acc: 0.982900
AT dataset testing:[14/20] val_loss: 0.167136 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000432 train_acc: 0.984375
[15/20][100/469] train_loss: 0.000264 train_acc: 0.989480
[15/20][200/469] train_loss: 0.000259 train_acc: 0.989544
[15/20][300/469] train_loss: 0.000253 train_acc: 0.989592
[15/20][400/469] train_loss: 0.000253 train_acc: 0.989694
Clean dataset testing:[15/20] val_loss: 0.000279 val_acc: 0.988400
AT dataset testing:[15/20] val_loss: 0.165052 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000496 train_acc: 0.992188
[16/20][100/469] train_loss: 0.000219 train_acc: 0.990254
[16/20][200/469] train_loss: 0.000228 train_acc: 0.990166
[16/20][300/469] train_loss: 0.000232 train_acc: 0.990241
[16/20][400/469] train_loss: 0.000236 train_acc: 0.990161
Clean dataset testing:[16/20] val_loss: 0.000286 val_acc: 0.987500
AT dataset testing:[16/20] val_loss: 0.170209 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000099 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000200 train_acc: 0.991801
[17/20][200/469] train_loss: 0.000211 train_acc: 0.991682
[17/20][300/469] train_loss: 0.000202 train_acc: 0.991954
[17/20][400/469] train_loss: 0.000218 train_acc: 0.990921
Clean dataset testing:[17/20] val_loss: 0.000286 val_acc: 0.988700
AT dataset testing:[17/20] val_loss: 0.171318 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000108 train_acc: 0.992188
[18/20][100/469] train_loss: 0.000201 train_acc: 0.990950
[18/20][200/469] train_loss: 0.000192 train_acc: 0.991410
[18/20][300/469] train_loss: 0.000212 train_acc: 0.990760
[18/20][400/469] train_loss: 0.000218 train_acc: 0.990551
Clean dataset testing:[18/20] val_loss: 0.000307 val_acc: 0.987300
AT dataset testing:[18/20] val_loss: 0.175055 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000048 train_acc: 1.000000
[19/20][100/469] train_loss: 0.000198 train_acc: 0.992188
[19/20][200/469] train_loss: 0.000196 train_acc: 0.992265
[19/20][300/469] train_loss: 0.000197 train_acc: 0.992239
[19/20][400/469] train_loss: 0.000213 train_acc: 0.991700
Clean dataset testing:[19/20] val_loss: 0.000283 val_acc: 0.988500
AT dataset testing:[19/20] val_loss: 0.179525 val_acc: 0.000000
nbits:6
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018071 train_acc: 0.093750
[0/20][100/469] train_loss: 0.011159 train_acc: 0.596844
[0/20][200/469] train_loss: 0.007014 train_acc: 0.743859
[0/20][300/469] train_loss: 0.005312 train_acc: 0.805284
[0/20][400/469] train_loss: 0.004357 train_acc: 0.840029
Clean dataset testing:[0/20] val_loss: 0.001121 val_acc: 0.957300
AT dataset testing:[0/20] val_loss: 0.089426 val_acc: 0.000000
[1/20][0/469] train_loss: 0.002049 train_acc: 0.921875
[1/20][100/469] train_loss: 0.001086 train_acc: 0.956219
[1/20][200/469] train_loss: 0.001026 train_acc: 0.959538
[1/20][300/469] train_loss: 0.000973 train_acc: 0.961301
[1/20][400/469] train_loss: 0.000946 train_acc: 0.962477
Clean dataset testing:[1/20] val_loss: 0.000627 val_acc: 0.975200
AT dataset testing:[1/20] val_loss: 0.103873 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000386 train_acc: 0.992188
[2/20][100/469] train_loss: 0.000654 train_acc: 0.974629
[2/20][200/469] train_loss: 0.000676 train_acc: 0.973647
[2/20][300/469] train_loss: 0.000686 train_acc: 0.972981
[2/20][400/469] train_loss: 0.000688 train_acc: 0.972939
Clean dataset testing:[2/20] val_loss: 0.000561 val_acc: 0.976700
AT dataset testing:[2/20] val_loss: 0.112101 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000635 train_acc: 0.976562
[3/20][100/469] train_loss: 0.000596 train_acc: 0.977104
[3/20][200/469] train_loss: 0.000599 train_acc: 0.976018
[3/20][300/469] train_loss: 0.000591 train_acc: 0.976173
[3/20][400/469] train_loss: 0.000577 train_acc: 0.976972
Clean dataset testing:[3/20] val_loss: 0.000438 val_acc: 0.982100
AT dataset testing:[3/20] val_loss: 0.120237 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000175 train_acc: 1.000000
[4/20][100/469] train_loss: 0.000466 train_acc: 0.982132
[4/20][200/469] train_loss: 0.000473 train_acc: 0.981304
[4/20][300/469] train_loss: 0.000471 train_acc: 0.981338
[4/20][400/469] train_loss: 0.000487 train_acc: 0.980790
Clean dataset testing:[4/20] val_loss: 0.000378 val_acc: 0.983400
AT dataset testing:[4/20] val_loss: 0.125711 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000239 train_acc: 0.992188
[5/20][100/469] train_loss: 0.000447 train_acc: 0.982673
[5/20][200/469] train_loss: 0.000449 train_acc: 0.982237
[5/20][300/469] train_loss: 0.000443 train_acc: 0.982169
[5/20][400/469] train_loss: 0.000438 train_acc: 0.982583
Clean dataset testing:[5/20] val_loss: 0.000464 val_acc: 0.981200
AT dataset testing:[5/20] val_loss: 0.137629 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000406 train_acc: 0.976562
[6/20][100/469] train_loss: 0.000404 train_acc: 0.984530
[6/20][200/469] train_loss: 0.000391 train_acc: 0.984803
[6/20][300/469] train_loss: 0.000398 train_acc: 0.984894
[6/20][400/469] train_loss: 0.000393 train_acc: 0.984706
Clean dataset testing:[6/20] val_loss: 0.000344 val_acc: 0.984700
AT dataset testing:[6/20] val_loss: 0.137403 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000334 train_acc: 0.984375
[7/20][100/469] train_loss: 0.000344 train_acc: 0.986618
[7/20][200/469] train_loss: 0.000352 train_acc: 0.986940
[7/20][300/469] train_loss: 0.000363 train_acc: 0.986400
[7/20][400/469] train_loss: 0.000364 train_acc: 0.986226
Clean dataset testing:[7/20] val_loss: 0.000312 val_acc: 0.986400
AT dataset testing:[7/20] val_loss: 0.144753 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000426 train_acc: 0.976562
[8/20][100/469] train_loss: 0.000346 train_acc: 0.986386
[8/20][200/469] train_loss: 0.000332 train_acc: 0.986707
[8/20][300/469] train_loss: 0.000333 train_acc: 0.986737
[8/20][400/469] train_loss: 0.000318 train_acc: 0.987278
Clean dataset testing:[8/20] val_loss: 0.000374 val_acc: 0.984100
AT dataset testing:[8/20] val_loss: 0.150402 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000443 train_acc: 0.976562
[9/20][100/469] train_loss: 0.000290 train_acc: 0.988784
[9/20][200/469] train_loss: 0.000289 train_acc: 0.987912
[9/20][300/469] train_loss: 0.000310 train_acc: 0.987256
[9/20][400/469] train_loss: 0.000310 train_acc: 0.987629
Clean dataset testing:[9/20] val_loss: 0.000323 val_acc: 0.986500
AT dataset testing:[9/20] val_loss: 0.149630 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000366 train_acc: 0.992188
[10/20][100/469] train_loss: 0.000281 train_acc: 0.987469
[10/20][200/469] train_loss: 0.000279 train_acc: 0.988650
[10/20][300/469] train_loss: 0.000279 train_acc: 0.988658
[10/20][400/469] train_loss: 0.000291 train_acc: 0.988369
Clean dataset testing:[10/20] val_loss: 0.000276 val_acc: 0.988100
AT dataset testing:[10/20] val_loss: 0.152759 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000369 train_acc: 0.992188
[11/20][100/469] train_loss: 0.000256 train_acc: 0.988629
[11/20][200/469] train_loss: 0.000267 train_acc: 0.989039
[11/20][300/469] train_loss: 0.000275 train_acc: 0.988632
[11/20][400/469] train_loss: 0.000273 train_acc: 0.988720
Clean dataset testing:[11/20] val_loss: 0.000260 val_acc: 0.988900
AT dataset testing:[11/20] val_loss: 0.151169 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000126 train_acc: 1.000000
[12/20][100/469] train_loss: 0.000234 train_acc: 0.990176
[12/20][200/469] train_loss: 0.000234 train_acc: 0.990516
[12/20][300/469] train_loss: 0.000246 train_acc: 0.989981
[12/20][400/469] train_loss: 0.000245 train_acc: 0.989928
Clean dataset testing:[12/20] val_loss: 0.000248 val_acc: 0.989900
AT dataset testing:[12/20] val_loss: 0.154965 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000106 train_acc: 1.000000
[13/20][100/469] train_loss: 0.000235 train_acc: 0.990718
[13/20][200/469] train_loss: 0.000245 train_acc: 0.990205
[13/20][300/469] train_loss: 0.000238 train_acc: 0.990241
[13/20][400/469] train_loss: 0.000240 train_acc: 0.990356
Clean dataset testing:[13/20] val_loss: 0.000269 val_acc: 0.988700
AT dataset testing:[13/20] val_loss: 0.168472 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000086 train_acc: 1.000000
[14/20][100/469] train_loss: 0.000227 train_acc: 0.990718
[14/20][200/469] train_loss: 0.000236 train_acc: 0.990477
[14/20][300/469] train_loss: 0.000232 train_acc: 0.990786
[14/20][400/469] train_loss: 0.000220 train_acc: 0.991096
Clean dataset testing:[14/20] val_loss: 0.000300 val_acc: 0.987000
AT dataset testing:[14/20] val_loss: 0.168762 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000367 train_acc: 0.976562
[15/20][100/469] train_loss: 0.000188 train_acc: 0.992265
[15/20][200/469] train_loss: 0.000182 train_acc: 0.992537
[15/20][300/469] train_loss: 0.000194 train_acc: 0.991954
[15/20][400/469] train_loss: 0.000196 train_acc: 0.992129
Clean dataset testing:[15/20] val_loss: 0.000266 val_acc: 0.989500
AT dataset testing:[15/20] val_loss: 0.181910 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000110 train_acc: 0.992188
[16/20][100/469] train_loss: 0.000179 train_acc: 0.993038
[16/20][200/469] train_loss: 0.000181 train_acc: 0.992887
[16/20][300/469] train_loss: 0.000198 train_acc: 0.992058
[16/20][400/469] train_loss: 0.000194 train_acc: 0.992207
Clean dataset testing:[16/20] val_loss: 0.000274 val_acc: 0.988200
AT dataset testing:[16/20] val_loss: 0.183408 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000037 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000165 train_acc: 0.992188
[17/20][200/469] train_loss: 0.000179 train_acc: 0.992110
[17/20][300/469] train_loss: 0.000183 train_acc: 0.991902
[17/20][400/469] train_loss: 0.000189 train_acc: 0.991973
Clean dataset testing:[17/20] val_loss: 0.000302 val_acc: 0.987100
AT dataset testing:[17/20] val_loss: 0.198352 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000213 train_acc: 0.984375
[18/20][100/469] train_loss: 0.000182 train_acc: 0.992265
[18/20][200/469] train_loss: 0.000187 train_acc: 0.992460
[18/20][300/469] train_loss: 0.000179 train_acc: 0.992992
[18/20][400/469] train_loss: 0.000179 train_acc: 0.992675
Clean dataset testing:[18/20] val_loss: 0.000282 val_acc: 0.988400
AT dataset testing:[18/20] val_loss: 0.197778 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000044 train_acc: 1.000000
[19/20][100/469] train_loss: 0.000171 train_acc: 0.992110
[19/20][200/469] train_loss: 0.000175 train_acc: 0.992226
[19/20][300/469] train_loss: 0.000178 train_acc: 0.992525
[19/20][400/469] train_loss: 0.000176 train_acc: 0.992655
Clean dataset testing:[19/20] val_loss: 0.000259 val_acc: 0.989500
AT dataset testing:[19/20] val_loss: 0.205228 val_acc: 0.000000
nbits:7
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017906 train_acc: 0.156250
[0/20][100/469] train_loss: 0.010276 train_acc: 0.615486
[0/20][200/469] train_loss: 0.006323 train_acc: 0.763254
[0/20][300/469] train_loss: 0.004789 train_acc: 0.820546
[0/20][400/469] train_loss: 0.003946 train_acc: 0.851640
Clean dataset testing:[0/20] val_loss: 0.001082 val_acc: 0.958300
AT dataset testing:[0/20] val_loss: 0.089833 val_acc: 0.000100
[1/20][0/469] train_loss: 0.000606 train_acc: 0.976562
[1/20][100/469] train_loss: 0.001166 train_acc: 0.953744
[1/20][200/469] train_loss: 0.001095 train_acc: 0.956390
[1/20][300/469] train_loss: 0.001024 train_acc: 0.959640
[1/20][400/469] train_loss: 0.000996 train_acc: 0.961074
Clean dataset testing:[1/20] val_loss: 0.000776 val_acc: 0.969200
AT dataset testing:[1/20] val_loss: 0.098252 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000782 train_acc: 0.984375
[2/20][100/469] train_loss: 0.000924 train_acc: 0.963645
[2/20][200/469] train_loss: 0.000845 train_acc: 0.966962
[2/20][300/469] train_loss: 0.000817 train_acc: 0.968568
[2/20][400/469] train_loss: 0.000782 train_acc: 0.969763
Clean dataset testing:[2/20] val_loss: 0.000531 val_acc: 0.979700
AT dataset testing:[2/20] val_loss: 0.111915 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000210 train_acc: 0.992188
[3/20][100/469] train_loss: 0.000642 train_acc: 0.974397
[3/20][200/469] train_loss: 0.000652 train_acc: 0.974464
[3/20][300/469] train_loss: 0.000637 train_acc: 0.974772
[3/20][400/469] train_loss: 0.000626 train_acc: 0.975160
Clean dataset testing:[3/20] val_loss: 0.000496 val_acc: 0.977900
AT dataset testing:[3/20] val_loss: 0.121196 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000442 train_acc: 0.984375
[4/20][100/469] train_loss: 0.000588 train_acc: 0.976021
[4/20][200/469] train_loss: 0.000539 train_acc: 0.978778
[4/20][300/469] train_loss: 0.000542 train_acc: 0.978301
[4/20][400/469] train_loss: 0.000550 train_acc: 0.977848
Clean dataset testing:[4/20] val_loss: 0.000446 val_acc: 0.981500
AT dataset testing:[4/20] val_loss: 0.129161 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000293 train_acc: 0.984375
[5/20][100/469] train_loss: 0.000479 train_acc: 0.981822
[5/20][200/469] train_loss: 0.000467 train_acc: 0.981460
[5/20][300/469] train_loss: 0.000466 train_acc: 0.981390
[5/20][400/469] train_loss: 0.000463 train_acc: 0.981550
Clean dataset testing:[5/20] val_loss: 0.000374 val_acc: 0.984800
AT dataset testing:[5/20] val_loss: 0.133536 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000225 train_acc: 0.992188
[6/20][100/469] train_loss: 0.000397 train_acc: 0.984143
[6/20][200/469] train_loss: 0.000430 train_acc: 0.983092
[6/20][300/469] train_loss: 0.000438 train_acc: 0.982662
[6/20][400/469] train_loss: 0.000432 train_acc: 0.982836
Clean dataset testing:[6/20] val_loss: 0.000322 val_acc: 0.986300
AT dataset testing:[6/20] val_loss: 0.142861 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000111 train_acc: 0.992188
[7/20][100/469] train_loss: 0.000406 train_acc: 0.983601
[7/20][200/469] train_loss: 0.000391 train_acc: 0.984336
[7/20][300/469] train_loss: 0.000390 train_acc: 0.984505
[7/20][400/469] train_loss: 0.000387 train_acc: 0.984375
Clean dataset testing:[7/20] val_loss: 0.000308 val_acc: 0.987100
AT dataset testing:[7/20] val_loss: 0.143128 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000273 train_acc: 0.984375
[8/20][100/469] train_loss: 0.000371 train_acc: 0.985149
[8/20][200/469] train_loss: 0.000370 train_acc: 0.984997
[8/20][300/469] train_loss: 0.000356 train_acc: 0.985361
[8/20][400/469] train_loss: 0.000358 train_acc: 0.985349
Clean dataset testing:[8/20] val_loss: 0.000359 val_acc: 0.984400
AT dataset testing:[8/20] val_loss: 0.154804 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000082 train_acc: 1.000000
[9/20][100/469] train_loss: 0.000294 train_acc: 0.988939
[9/20][200/469] train_loss: 0.000318 train_acc: 0.987251
[9/20][300/469] train_loss: 0.000326 train_acc: 0.987048
[9/20][400/469] train_loss: 0.000333 train_acc: 0.986888
Clean dataset testing:[9/20] val_loss: 0.000283 val_acc: 0.988100
AT dataset testing:[9/20] val_loss: 0.149868 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000374 train_acc: 0.976562
[10/20][100/469] train_loss: 0.000318 train_acc: 0.987546
[10/20][200/469] train_loss: 0.000295 train_acc: 0.988495
[10/20][300/469] train_loss: 0.000305 train_acc: 0.988009
[10/20][400/469] train_loss: 0.000305 train_acc: 0.987882
Clean dataset testing:[10/20] val_loss: 0.000324 val_acc: 0.986700
AT dataset testing:[10/20] val_loss: 0.161517 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000481 train_acc: 0.976562
[11/20][100/469] train_loss: 0.000246 train_acc: 0.991337
[11/20][200/469] train_loss: 0.000263 train_acc: 0.989972
[11/20][300/469] train_loss: 0.000268 train_acc: 0.989514
[11/20][400/469] train_loss: 0.000280 train_acc: 0.988953
Clean dataset testing:[11/20] val_loss: 0.000266 val_acc: 0.989300
AT dataset testing:[11/20] val_loss: 0.163472 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000189 train_acc: 0.992188
[12/20][100/469] train_loss: 0.000254 train_acc: 0.990331
[12/20][200/469] train_loss: 0.000258 train_acc: 0.990050
[12/20][300/469] train_loss: 0.000263 train_acc: 0.989462
[12/20][400/469] train_loss: 0.000269 train_acc: 0.989343
Clean dataset testing:[12/20] val_loss: 0.000268 val_acc: 0.988700
AT dataset testing:[12/20] val_loss: 0.167240 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000376 train_acc: 0.992188
[13/20][100/469] train_loss: 0.000255 train_acc: 0.989867
[13/20][200/469] train_loss: 0.000250 train_acc: 0.989933
[13/20][300/469] train_loss: 0.000260 train_acc: 0.989436
[13/20][400/469] train_loss: 0.000264 train_acc: 0.989285
Clean dataset testing:[13/20] val_loss: 0.000261 val_acc: 0.989300
AT dataset testing:[13/20] val_loss: 0.170291 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000068 train_acc: 1.000000
[14/20][100/469] train_loss: 0.000248 train_acc: 0.990176
[14/20][200/469] train_loss: 0.000232 train_acc: 0.990827
[14/20][300/469] train_loss: 0.000254 train_acc: 0.990033
[14/20][400/469] train_loss: 0.000249 train_acc: 0.990239
Clean dataset testing:[14/20] val_loss: 0.000288 val_acc: 0.988000
AT dataset testing:[14/20] val_loss: 0.183575 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000428 train_acc: 0.976562
[15/20][100/469] train_loss: 0.000222 train_acc: 0.991259
[15/20][200/469] train_loss: 0.000212 train_acc: 0.991799
[15/20][300/469] train_loss: 0.000212 train_acc: 0.991565
[15/20][400/469] train_loss: 0.000215 train_acc: 0.991428
Clean dataset testing:[15/20] val_loss: 0.000287 val_acc: 0.988400
AT dataset testing:[15/20] val_loss: 0.180595 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000191 train_acc: 1.000000
[16/20][100/469] train_loss: 0.000197 train_acc: 0.992497
[16/20][200/469] train_loss: 0.000210 train_acc: 0.991838
[16/20][300/469] train_loss: 0.000229 train_acc: 0.991175
[16/20][400/469] train_loss: 0.000218 train_acc: 0.991525
Clean dataset testing:[16/20] val_loss: 0.000255 val_acc: 0.989800
AT dataset testing:[16/20] val_loss: 0.189734 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000079 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000203 train_acc: 0.992033
[17/20][200/469] train_loss: 0.000202 train_acc: 0.992265
[17/20][300/469] train_loss: 0.000200 train_acc: 0.992136
[17/20][400/469] train_loss: 0.000198 train_acc: 0.992207
Clean dataset testing:[17/20] val_loss: 0.000256 val_acc: 0.989500
AT dataset testing:[17/20] val_loss: 0.190856 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000169 train_acc: 0.992188
[18/20][100/469] train_loss: 0.000185 train_acc: 0.992110
[18/20][200/469] train_loss: 0.000184 train_acc: 0.992848
[18/20][300/469] train_loss: 0.000186 train_acc: 0.992577
[18/20][400/469] train_loss: 0.000185 train_acc: 0.992441
Clean dataset testing:[18/20] val_loss: 0.000264 val_acc: 0.989200
AT dataset testing:[18/20] val_loss: 0.201665 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000113 train_acc: 0.992188
[19/20][100/469] train_loss: 0.000144 train_acc: 0.993889
[19/20][200/469] train_loss: 0.000173 train_acc: 0.992460
[19/20][300/469] train_loss: 0.000178 train_acc: 0.992188
[19/20][400/469] train_loss: 0.000186 train_acc: 0.991915
Clean dataset testing:[19/20] val_loss: 0.000247 val_acc: 0.990800
AT dataset testing:[19/20] val_loss: 0.203848 val_acc: 0.000000
nbits:8
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017948 train_acc: 0.101562
[0/20][100/469] train_loss: 0.011043 train_acc: 0.563738
[0/20][200/469] train_loss: 0.006899 train_acc: 0.727884
[0/20][300/469] train_loss: 0.005168 train_acc: 0.796174
[0/20][400/469] train_loss: 0.004207 train_acc: 0.834398
Clean dataset testing:[0/20] val_loss: 0.001095 val_acc: 0.956500
AT dataset testing:[0/20] val_loss: 0.083838 val_acc: 0.000000
[1/20][0/469] train_loss: 0.001195 train_acc: 0.945312
[1/20][100/469] train_loss: 0.000989 train_acc: 0.961015
[1/20][200/469] train_loss: 0.000978 train_acc: 0.962492
[1/20][300/469] train_loss: 0.000943 train_acc: 0.963922
[1/20][400/469] train_loss: 0.000921 train_acc: 0.964269
Clean dataset testing:[1/20] val_loss: 0.000747 val_acc: 0.970500
AT dataset testing:[1/20] val_loss: 0.093956 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000619 train_acc: 0.960938
[2/20][100/469] train_loss: 0.000739 train_acc: 0.970761
[2/20][200/469] train_loss: 0.000715 train_acc: 0.971393
[2/20][300/469] train_loss: 0.000699 train_acc: 0.971553
[2/20][400/469] train_loss: 0.000688 train_acc: 0.972082
Clean dataset testing:[2/20] val_loss: 0.000553 val_acc: 0.977700
AT dataset testing:[2/20] val_loss: 0.104906 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000250 train_acc: 0.992188
[3/20][100/469] train_loss: 0.000572 train_acc: 0.977800
[3/20][200/469] train_loss: 0.000553 train_acc: 0.978156
[3/20][300/469] train_loss: 0.000558 train_acc: 0.978327
[3/20][400/469] train_loss: 0.000563 train_acc: 0.978180
Clean dataset testing:[3/20] val_loss: 0.000457 val_acc: 0.981700
AT dataset testing:[3/20] val_loss: 0.116600 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000230 train_acc: 0.992188
[4/20][100/469] train_loss: 0.000522 train_acc: 0.978728
[4/20][200/469] train_loss: 0.000514 train_acc: 0.978972
[4/20][300/469] train_loss: 0.000495 train_acc: 0.979911
[4/20][400/469] train_loss: 0.000491 train_acc: 0.980069
Clean dataset testing:[4/20] val_loss: 0.000441 val_acc: 0.982900
AT dataset testing:[4/20] val_loss: 0.120396 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000431 train_acc: 0.992188
[5/20][100/469] train_loss: 0.000444 train_acc: 0.981590
[5/20][200/469] train_loss: 0.000461 train_acc: 0.981227
[5/20][300/469] train_loss: 0.000461 train_acc: 0.981442
[5/20][400/469] train_loss: 0.000453 train_acc: 0.981764
Clean dataset testing:[5/20] val_loss: 0.000363 val_acc: 0.984300
AT dataset testing:[5/20] val_loss: 0.129260 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000567 train_acc: 0.984375
[6/20][100/469] train_loss: 0.000415 train_acc: 0.982209
[6/20][200/469] train_loss: 0.000430 train_acc: 0.982509
[6/20][300/469] train_loss: 0.000423 train_acc: 0.982454
[6/20][400/469] train_loss: 0.000422 train_acc: 0.982875
Clean dataset testing:[6/20] val_loss: 0.000434 val_acc: 0.981400
AT dataset testing:[6/20] val_loss: 0.128527 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000453 train_acc: 0.976562
[7/20][100/469] train_loss: 0.000362 train_acc: 0.985845
[7/20][200/469] train_loss: 0.000359 train_acc: 0.985813
[7/20][300/469] train_loss: 0.000374 train_acc: 0.984894
[7/20][400/469] train_loss: 0.000382 train_acc: 0.984609
Clean dataset testing:[7/20] val_loss: 0.000369 val_acc: 0.984600
AT dataset testing:[7/20] val_loss: 0.131169 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000319 train_acc: 0.984375
[8/20][100/469] train_loss: 0.000329 train_acc: 0.986386
[8/20][200/469] train_loss: 0.000363 train_acc: 0.985191
[8/20][300/469] train_loss: 0.000359 train_acc: 0.985050
[8/20][400/469] train_loss: 0.000358 train_acc: 0.985096
Clean dataset testing:[8/20] val_loss: 0.000352 val_acc: 0.984900
AT dataset testing:[8/20] val_loss: 0.137552 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000222 train_acc: 0.992188
[9/20][100/469] train_loss: 0.000304 train_acc: 0.987237
[9/20][200/469] train_loss: 0.000326 train_acc: 0.986552
[9/20][300/469] train_loss: 0.000337 train_acc: 0.986348
[9/20][400/469] train_loss: 0.000335 train_acc: 0.986440
Clean dataset testing:[9/20] val_loss: 0.000304 val_acc: 0.987100
AT dataset testing:[9/20] val_loss: 0.142829 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000245 train_acc: 0.992188
[10/20][100/469] train_loss: 0.000304 train_acc: 0.988011
[10/20][200/469] train_loss: 0.000306 train_acc: 0.987251
[10/20][300/469] train_loss: 0.000308 train_acc: 0.987360
[10/20][400/469] train_loss: 0.000308 train_acc: 0.987570
Clean dataset testing:[10/20] val_loss: 0.000368 val_acc: 0.984800
AT dataset testing:[10/20] val_loss: 0.153589 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000102 train_acc: 1.000000
[11/20][100/469] train_loss: 0.000312 train_acc: 0.986850
[11/20][200/469] train_loss: 0.000300 train_acc: 0.987679
[11/20][300/469] train_loss: 0.000292 train_acc: 0.987853
[11/20][400/469] train_loss: 0.000295 train_acc: 0.987979
Clean dataset testing:[11/20] val_loss: 0.000289 val_acc: 0.988400
AT dataset testing:[11/20] val_loss: 0.150288 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000244 train_acc: 0.992188
[12/20][100/469] train_loss: 0.000259 train_acc: 0.988165
[12/20][200/469] train_loss: 0.000259 train_acc: 0.988884
[12/20][300/469] train_loss: 0.000268 train_acc: 0.988554
[12/20][400/469] train_loss: 0.000270 train_acc: 0.988681
Clean dataset testing:[12/20] val_loss: 0.000364 val_acc: 0.984300
AT dataset testing:[12/20] val_loss: 0.151083 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000220 train_acc: 0.992188
[13/20][100/469] train_loss: 0.000251 train_acc: 0.989480
[13/20][200/469] train_loss: 0.000238 train_acc: 0.989778
[13/20][300/469] train_loss: 0.000255 train_acc: 0.989125
[13/20][400/469] train_loss: 0.000267 train_acc: 0.988603
Clean dataset testing:[13/20] val_loss: 0.000275 val_acc: 0.989100
AT dataset testing:[13/20] val_loss: 0.154370 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000379 train_acc: 0.968750
[14/20][100/469] train_loss: 0.000229 train_acc: 0.991027
[14/20][200/469] train_loss: 0.000230 train_acc: 0.990166
[14/20][300/469] train_loss: 0.000241 train_acc: 0.989800
[14/20][400/469] train_loss: 0.000251 train_acc: 0.989460
Clean dataset testing:[14/20] val_loss: 0.000279 val_acc: 0.987100
AT dataset testing:[14/20] val_loss: 0.161637 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000168 train_acc: 0.992188
[15/20][100/469] train_loss: 0.000234 train_acc: 0.989635
[15/20][200/469] train_loss: 0.000227 train_acc: 0.990322
[15/20][300/469] train_loss: 0.000218 train_acc: 0.990812
[15/20][400/469] train_loss: 0.000235 train_acc: 0.990395
Clean dataset testing:[15/20] val_loss: 0.000299 val_acc: 0.987700
AT dataset testing:[15/20] val_loss: 0.157883 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000197 train_acc: 0.992188
[16/20][100/469] train_loss: 0.000219 train_acc: 0.990486
[16/20][200/469] train_loss: 0.000206 train_acc: 0.990788
[16/20][300/469] train_loss: 0.000211 train_acc: 0.990968
[16/20][400/469] train_loss: 0.000227 train_acc: 0.990668
Clean dataset testing:[16/20] val_loss: 0.000284 val_acc: 0.988400
AT dataset testing:[16/20] val_loss: 0.168340 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000072 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000185 train_acc: 0.992110
[17/20][200/469] train_loss: 0.000198 train_acc: 0.991410
[17/20][300/469] train_loss: 0.000205 train_acc: 0.991668
[17/20][400/469] train_loss: 0.000206 train_acc: 0.991350
Clean dataset testing:[17/20] val_loss: 0.000266 val_acc: 0.987900
AT dataset testing:[17/20] val_loss: 0.173127 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000485 train_acc: 0.984375
[18/20][100/469] train_loss: 0.000179 train_acc: 0.991646
[18/20][200/469] train_loss: 0.000178 train_acc: 0.991877
[18/20][300/469] train_loss: 0.000200 train_acc: 0.991071
[18/20][400/469] train_loss: 0.000200 train_acc: 0.991135
Clean dataset testing:[18/20] val_loss: 0.000260 val_acc: 0.989700
AT dataset testing:[18/20] val_loss: 0.174409 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000065 train_acc: 1.000000
[19/20][100/469] train_loss: 0.000152 train_acc: 0.993657
[19/20][200/469] train_loss: 0.000178 train_acc: 0.992343
[19/20][300/469] train_loss: 0.000184 train_acc: 0.992369
[19/20][400/469] train_loss: 0.000196 train_acc: 0.991856
Clean dataset testing:[19/20] val_loss: 0.000277 val_acc: 0.987600
AT dataset testing:[19/20] val_loss: 0.183028 val_acc: 0.000000
