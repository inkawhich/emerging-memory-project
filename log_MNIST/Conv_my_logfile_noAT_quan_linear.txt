nbits:1
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017992 train_acc: 0.070312
[0/20][100/469] train_loss: 0.011476 train_acc: 0.512995
[0/20][200/469] train_loss: 0.008073 train_acc: 0.665151
[0/20][300/469] train_loss: 0.006795 train_acc: 0.721034
[0/20][400/469] train_loss: 0.006173 train_acc: 0.746201
Clean dataset testing:[0/20] val_loss: 0.003711 val_acc: 0.869100
AT dataset testing:[0/20] val_loss: 0.057616 val_acc: 0.000000
[1/20][0/469] train_loss: 0.003971 train_acc: 0.828125
[1/20][100/469] train_loss: 0.004128 train_acc: 0.833385
[1/20][200/469] train_loss: 0.003830 train_acc: 0.844294
[1/20][300/469] train_loss: 0.003423 train_acc: 0.862412
[1/20][400/469] train_loss: 0.003308 train_acc: 0.867343
Clean dataset testing:[1/20] val_loss: 0.002456 val_acc: 0.914700
AT dataset testing:[1/20] val_loss: 0.060409 val_acc: 0.000000
[2/20][0/469] train_loss: 0.003733 train_acc: 0.859375
[2/20][100/469] train_loss: 0.003129 train_acc: 0.872447
[2/20][200/469] train_loss: 0.003053 train_acc: 0.876438
[2/20][300/469] train_loss: 0.002967 train_acc: 0.880814
[2/20][400/469] train_loss: 0.002869 train_acc: 0.885423
Clean dataset testing:[2/20] val_loss: 0.002467 val_acc: 0.907000
AT dataset testing:[2/20] val_loss: 0.072946 val_acc: 0.000000
[3/20][0/469] train_loss: 0.002188 train_acc: 0.929688
[3/20][100/469] train_loss: 0.002779 train_acc: 0.893023
[3/20][200/469] train_loss: 0.002919 train_acc: 0.884717
[3/20][300/469] train_loss: 0.003288 train_acc: 0.864358
[3/20][400/469] train_loss: 0.003308 train_acc: 0.865415
Clean dataset testing:[3/20] val_loss: 0.003784 val_acc: 0.840800
AT dataset testing:[3/20] val_loss: 0.081159 val_acc: 0.002600
[4/20][0/469] train_loss: 0.004320 train_acc: 0.820312
[4/20][100/469] train_loss: 0.003210 train_acc: 0.876315
[4/20][200/469] train_loss: 0.002994 train_acc: 0.884873
[4/20][300/469] train_loss: 0.002899 train_acc: 0.888419
[4/20][400/469] train_loss: 0.002894 train_acc: 0.887469
Clean dataset testing:[4/20] val_loss: 0.002630 val_acc: 0.899700
AT dataset testing:[4/20] val_loss: 0.082044 val_acc: 0.000100
[5/20][0/469] train_loss: 0.002426 train_acc: 0.914062
[5/20][100/469] train_loss: 0.002518 train_acc: 0.899134
[5/20][200/469] train_loss: 0.002720 train_acc: 0.891519
[5/20][300/469] train_loss: 0.002936 train_acc: 0.882605
[5/20][400/469] train_loss: 0.003113 train_acc: 0.876578
Clean dataset testing:[5/20] val_loss: 0.003551 val_acc: 0.861600
AT dataset testing:[5/20] val_loss: 0.089174 val_acc: 0.000000
[6/20][0/469] train_loss: 0.003437 train_acc: 0.898438
[6/20][100/469] train_loss: 0.003575 train_acc: 0.860845
[6/20][200/469] train_loss: 0.003803 train_acc: 0.853739
[6/20][300/469] train_loss: 0.003822 train_acc: 0.853016
[6/20][400/469] train_loss: 0.003947 train_acc: 0.848991
Clean dataset testing:[6/20] val_loss: 0.004827 val_acc: 0.815600
AT dataset testing:[6/20] val_loss: 0.120166 val_acc: 0.000000
[7/20][0/469] train_loss: 0.007532 train_acc: 0.726562
[7/20][100/469] train_loss: 0.005469 train_acc: 0.789140
[7/20][200/469] train_loss: 0.004702 train_acc: 0.821634
[7/20][300/469] train_loss: 0.004876 train_acc: 0.817769
[7/20][400/469] train_loss: 0.005983 train_acc: 0.765722
Clean dataset testing:[7/20] val_loss: 0.003977 val_acc: 0.837900
AT dataset testing:[7/20] val_loss: 0.140658 val_acc: 0.000000
[8/20][0/469] train_loss: 0.003046 train_acc: 0.890625
[8/20][100/469] train_loss: 0.005294 train_acc: 0.792775
[8/20][200/469] train_loss: 0.005661 train_acc: 0.775964
[8/20][300/469] train_loss: 0.006422 train_acc: 0.756255
[8/20][400/469] train_loss: 0.006223 train_acc: 0.761261
Clean dataset testing:[8/20] val_loss: 0.007222 val_acc: 0.693800
AT dataset testing:[8/20] val_loss: 0.083487 val_acc: 0.000100
[9/20][0/469] train_loss: 0.007749 train_acc: 0.640625
[9/20][100/469] train_loss: 0.008251 train_acc: 0.649288
[9/20][200/469] train_loss: 0.008554 train_acc: 0.641713
[9/20][300/469] train_loss: 0.008705 train_acc: 0.636965
[9/20][400/469] train_loss: 0.008968 train_acc: 0.626773
Clean dataset testing:[9/20] val_loss: 0.009485 val_acc: 0.614800
AT dataset testing:[9/20] val_loss: 0.088995 val_acc: 0.000000
[10/20][0/469] train_loss: 0.010444 train_acc: 0.554688
[10/20][100/469] train_loss: 0.009491 train_acc: 0.613552
[10/20][200/469] train_loss: 0.009778 train_acc: 0.596510
[10/20][300/469] train_loss: 0.009476 train_acc: 0.605456
[10/20][400/469] train_loss: 0.009317 train_acc: 0.613914
Clean dataset testing:[10/20] val_loss: 0.006569 val_acc: 0.716100
AT dataset testing:[10/20] val_loss: 0.084879 val_acc: 0.000000
[11/20][0/469] train_loss: 0.005559 train_acc: 0.765625
[11/20][100/469] train_loss: 0.007566 train_acc: 0.698561
[11/20][200/469] train_loss: 0.007793 train_acc: 0.688044
[11/20][300/469] train_loss: 0.007929 train_acc: 0.684853
[11/20][400/469] train_loss: 0.007898 train_acc: 0.686175
Clean dataset testing:[11/20] val_loss: 0.006946 val_acc: 0.713200
AT dataset testing:[11/20] val_loss: 0.069699 val_acc: 0.000300
[12/20][0/469] train_loss: 0.007343 train_acc: 0.656250
[12/20][100/469] train_loss: 0.007702 train_acc: 0.683478
[12/20][200/469] train_loss: 0.008477 train_acc: 0.656833
[12/20][300/469] train_loss: 0.008650 train_acc: 0.646179
[12/20][400/469] train_loss: 0.008663 train_acc: 0.642086
Clean dataset testing:[12/20] val_loss: 0.011436 val_acc: 0.528200
AT dataset testing:[12/20] val_loss: 0.111303 val_acc: 0.000000
[13/20][0/469] train_loss: 0.011150 train_acc: 0.578125
[13/20][100/469] train_loss: 0.008241 train_acc: 0.638150
[13/20][200/469] train_loss: 0.008790 train_acc: 0.620219
[13/20][300/469] train_loss: 0.008768 train_acc: 0.623209
[13/20][400/469] train_loss: 0.008871 train_acc: 0.618220
Clean dataset testing:[13/20] val_loss: 0.008122 val_acc: 0.606000
AT dataset testing:[13/20] val_loss: 0.050084 val_acc: 0.004700
[14/20][0/469] train_loss: 0.007815 train_acc: 0.703125
[14/20][100/469] train_loss: 0.008651 train_acc: 0.635520
[14/20][200/469] train_loss: 0.008979 train_acc: 0.621580
[14/20][300/469] train_loss: 0.009122 train_acc: 0.612879
[14/20][400/469] train_loss: 0.009120 train_acc: 0.611752
Clean dataset testing:[14/20] val_loss: 0.009704 val_acc: 0.609300
AT dataset testing:[14/20] val_loss: 0.063141 val_acc: 0.058500
[15/20][0/469] train_loss: 0.009360 train_acc: 0.601562
[15/20][100/469] train_loss: 0.009624 train_acc: 0.593363
[15/20][200/469] train_loss: 0.009867 train_acc: 0.580340
[15/20][300/469] train_loss: 0.009794 train_acc: 0.587702
[15/20][400/469] train_loss: 0.009654 train_acc: 0.592581
Clean dataset testing:[15/20] val_loss: 0.010433 val_acc: 0.586000
AT dataset testing:[15/20] val_loss: 0.053131 val_acc: 0.095300
[16/20][0/469] train_loss: 0.009917 train_acc: 0.593750
[16/20][100/469] train_loss: 0.009646 train_acc: 0.588258
[16/20][200/469] train_loss: 0.009872 train_acc: 0.593750
[16/20][300/469] train_loss: 0.009525 train_acc: 0.597877
[16/20][400/469] train_loss: 0.009490 train_acc: 0.597783
Clean dataset testing:[16/20] val_loss: 0.010522 val_acc: 0.525200
AT dataset testing:[16/20] val_loss: 0.043640 val_acc: 0.016800
[17/20][0/469] train_loss: 0.012129 train_acc: 0.437500
[17/20][100/469] train_loss: 0.009126 train_acc: 0.617110
[17/20][200/469] train_loss: 0.008778 train_acc: 0.630869
[17/20][300/469] train_loss: 0.008824 train_acc: 0.629205
[17/20][400/469] train_loss: 0.008911 train_acc: 0.626675
Clean dataset testing:[17/20] val_loss: 0.010435 val_acc: 0.618200
AT dataset testing:[17/20] val_loss: 0.047139 val_acc: 0.016500
[18/20][0/469] train_loss: 0.009149 train_acc: 0.648438
[18/20][100/469] train_loss: 0.009044 train_acc: 0.623221
[18/20][200/469] train_loss: 0.009850 train_acc: 0.581856
[18/20][300/469] train_loss: 0.010210 train_acc: 0.566030
[18/20][400/469] train_loss: 0.010114 train_acc: 0.567643
Clean dataset testing:[18/20] val_loss: 0.008146 val_acc: 0.646400
AT dataset testing:[18/20] val_loss: 0.027491 val_acc: 0.088300
[19/20][0/469] train_loss: 0.008494 train_acc: 0.648438
[19/20][100/469] train_loss: 0.010430 train_acc: 0.594833
[19/20][200/469] train_loss: 0.010126 train_acc: 0.589086
[19/20][300/469] train_loss: 0.010036 train_acc: 0.585055
[19/20][400/469] train_loss: 0.010191 train_acc: 0.580385
Clean dataset testing:[19/20] val_loss: 0.019176 val_acc: 0.113500
AT dataset testing:[19/20] val_loss: 0.019176 val_acc: 0.113500
nbits:2
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018064 train_acc: 0.101562
[0/20][100/469] train_loss: 0.011441 train_acc: 0.553450
[0/20][200/469] train_loss: 0.007293 train_acc: 0.713036
[0/20][300/469] train_loss: 0.005612 train_acc: 0.778577
[0/20][400/469] train_loss: 0.004653 train_acc: 0.816046
Clean dataset testing:[0/20] val_loss: 0.001292 val_acc: 0.947500
AT dataset testing:[0/20] val_loss: 0.077564 val_acc: 0.000000
[1/20][0/469] train_loss: 0.001541 train_acc: 0.914062
[1/20][100/469] train_loss: 0.001258 train_acc: 0.948948
[1/20][200/469] train_loss: 0.001206 train_acc: 0.952037
[1/20][300/469] train_loss: 0.001186 train_acc: 0.952736
[1/20][400/469] train_loss: 0.001170 train_acc: 0.953183
Clean dataset testing:[1/20] val_loss: 0.000957 val_acc: 0.962200
AT dataset testing:[1/20] val_loss: 0.092199 val_acc: 0.000000
[2/20][0/469] train_loss: 0.001365 train_acc: 0.945312
[2/20][100/469] train_loss: 0.001008 train_acc: 0.957611
[2/20][200/469] train_loss: 0.000953 train_acc: 0.960976
[2/20][300/469] train_loss: 0.000913 train_acc: 0.963222
[2/20][400/469] train_loss: 0.000897 train_acc: 0.963587
Clean dataset testing:[2/20] val_loss: 0.000713 val_acc: 0.970600
AT dataset testing:[2/20] val_loss: 0.106752 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000818 train_acc: 0.968750
[3/20][100/469] train_loss: 0.000816 train_acc: 0.965114
[3/20][200/469] train_loss: 0.000789 train_acc: 0.966923
[3/20][300/469] train_loss: 0.000763 train_acc: 0.967971
[3/20][400/469] train_loss: 0.000746 train_acc: 0.968984
Clean dataset testing:[3/20] val_loss: 0.000756 val_acc: 0.969300
AT dataset testing:[3/20] val_loss: 0.108592 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000687 train_acc: 0.960938
[4/20][100/469] train_loss: 0.000751 train_acc: 0.969059
[4/20][200/469] train_loss: 0.000729 train_acc: 0.970577
[4/20][300/469] train_loss: 0.000725 train_acc: 0.970567
[4/20][400/469] train_loss: 0.000706 train_acc: 0.971302
Clean dataset testing:[4/20] val_loss: 0.000445 val_acc: 0.982200
AT dataset testing:[4/20] val_loss: 0.108839 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000326 train_acc: 0.976562
[5/20][100/469] train_loss: 0.000664 train_acc: 0.972308
[5/20][200/469] train_loss: 0.000654 train_acc: 0.973220
[5/20][300/469] train_loss: 0.000670 train_acc: 0.973007
[5/20][400/469] train_loss: 0.000654 train_acc: 0.973601
Clean dataset testing:[5/20] val_loss: 0.000502 val_acc: 0.976800
AT dataset testing:[5/20] val_loss: 0.112869 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000204 train_acc: 1.000000
[6/20][100/469] train_loss: 0.000591 train_acc: 0.977568
[6/20][200/469] train_loss: 0.000613 train_acc: 0.975047
[6/20][300/469] train_loss: 0.000629 train_acc: 0.974694
[6/20][400/469] train_loss: 0.000630 train_acc: 0.974984
Clean dataset testing:[6/20] val_loss: 0.000450 val_acc: 0.981900
AT dataset testing:[6/20] val_loss: 0.112457 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000268 train_acc: 0.984375
[7/20][100/469] train_loss: 0.000579 train_acc: 0.977800
[7/20][200/469] train_loss: 0.000553 train_acc: 0.978661
[7/20][300/469] train_loss: 0.000569 train_acc: 0.977705
[7/20][400/469] train_loss: 0.000585 train_acc: 0.977225
Clean dataset testing:[7/20] val_loss: 0.000498 val_acc: 0.978200
AT dataset testing:[7/20] val_loss: 0.119951 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000246 train_acc: 0.992188
[8/20][100/469] train_loss: 0.000614 train_acc: 0.974783
[8/20][200/469] train_loss: 0.000625 train_acc: 0.973803
[8/20][300/469] train_loss: 0.000587 train_acc: 0.975317
[8/20][400/469] train_loss: 0.000578 train_acc: 0.976251
Clean dataset testing:[8/20] val_loss: 0.000637 val_acc: 0.973100
AT dataset testing:[8/20] val_loss: 0.114643 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000205 train_acc: 0.992188
[9/20][100/469] train_loss: 0.000562 train_acc: 0.977955
[9/20][200/469] train_loss: 0.000550 train_acc: 0.978117
[9/20][300/469] train_loss: 0.000540 train_acc: 0.978431
[9/20][400/469] train_loss: 0.000545 train_acc: 0.978296
Clean dataset testing:[9/20] val_loss: 0.000485 val_acc: 0.980700
AT dataset testing:[9/20] val_loss: 0.125104 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000144 train_acc: 1.000000
[10/20][100/469] train_loss: 0.000463 train_acc: 0.979734
[10/20][200/469] train_loss: 0.000484 train_acc: 0.979594
[10/20][300/469] train_loss: 0.000488 train_acc: 0.979703
[10/20][400/469] train_loss: 0.000499 train_acc: 0.979504
Clean dataset testing:[10/20] val_loss: 0.000450 val_acc: 0.982000
AT dataset testing:[10/20] val_loss: 0.127342 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000187 train_acc: 0.992188
[11/20][100/469] train_loss: 0.000472 train_acc: 0.980353
[11/20][200/469] train_loss: 0.000497 train_acc: 0.979400
[11/20][300/469] train_loss: 0.000511 train_acc: 0.978873
[11/20][400/469] train_loss: 0.000501 train_acc: 0.979056
Clean dataset testing:[11/20] val_loss: 0.000405 val_acc: 0.983600
AT dataset testing:[11/20] val_loss: 0.131497 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000544 train_acc: 0.984375
[12/20][100/469] train_loss: 0.000434 train_acc: 0.981822
[12/20][200/469] train_loss: 0.000472 train_acc: 0.980449
[12/20][300/469] train_loss: 0.000473 train_acc: 0.980586
[12/20][400/469] train_loss: 0.000470 train_acc: 0.980556
Clean dataset testing:[12/20] val_loss: 0.000364 val_acc: 0.985300
AT dataset testing:[12/20] val_loss: 0.136914 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000072 train_acc: 1.000000
[13/20][100/469] train_loss: 0.000441 train_acc: 0.981745
[13/20][200/469] train_loss: 0.000460 train_acc: 0.981304
[13/20][300/469] train_loss: 0.000469 train_acc: 0.980508
[13/20][400/469] train_loss: 0.000457 train_acc: 0.981141
Clean dataset testing:[13/20] val_loss: 0.000554 val_acc: 0.977500
AT dataset testing:[13/20] val_loss: 0.134795 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000237 train_acc: 0.984375
[14/20][100/469] train_loss: 0.000456 train_acc: 0.980739
[14/20][200/469] train_loss: 0.000431 train_acc: 0.982043
[14/20][300/469] train_loss: 0.000449 train_acc: 0.981754
[14/20][400/469] train_loss: 0.000460 train_acc: 0.981375
Clean dataset testing:[14/20] val_loss: 0.000424 val_acc: 0.981600
AT dataset testing:[14/20] val_loss: 0.140139 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000403 train_acc: 0.984375
[15/20][100/469] train_loss: 0.000484 train_acc: 0.980894
[15/20][200/469] train_loss: 0.000467 train_acc: 0.980955
[15/20][300/469] train_loss: 0.000478 train_acc: 0.980482
[15/20][400/469] train_loss: 0.000464 train_acc: 0.980888
Clean dataset testing:[15/20] val_loss: 0.000411 val_acc: 0.983000
AT dataset testing:[15/20] val_loss: 0.137017 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000142 train_acc: 0.992188
[16/20][100/469] train_loss: 0.000464 train_acc: 0.981204
[16/20][200/469] train_loss: 0.000414 train_acc: 0.983015
[16/20][300/469] train_loss: 0.000434 train_acc: 0.982506
[16/20][400/469] train_loss: 0.000438 train_acc: 0.982661
Clean dataset testing:[16/20] val_loss: 0.000576 val_acc: 0.975000
AT dataset testing:[16/20] val_loss: 0.139820 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000316 train_acc: 0.984375
[17/20][100/469] train_loss: 0.000455 train_acc: 0.981126
[17/20][200/469] train_loss: 0.000443 train_acc: 0.981343
[17/20][300/469] train_loss: 0.000433 train_acc: 0.981961
[17/20][400/469] train_loss: 0.000430 train_acc: 0.981920
Clean dataset testing:[17/20] val_loss: 0.000352 val_acc: 0.984800
AT dataset testing:[17/20] val_loss: 0.137926 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000216 train_acc: 0.992188
[18/20][100/469] train_loss: 0.000444 train_acc: 0.982441
[18/20][200/469] train_loss: 0.000455 train_acc: 0.981615
[18/20][300/469] train_loss: 0.000445 train_acc: 0.981831
[18/20][400/469] train_loss: 0.000449 train_acc: 0.982193
Clean dataset testing:[18/20] val_loss: 0.000400 val_acc: 0.984400
AT dataset testing:[18/20] val_loss: 0.140276 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000812 train_acc: 0.968750
[19/20][100/469] train_loss: 0.000403 train_acc: 0.984066
[19/20][200/469] train_loss: 0.000431 train_acc: 0.982859
[19/20][300/469] train_loss: 0.000454 train_acc: 0.982091
[19/20][400/469] train_loss: 0.000454 train_acc: 0.982251
Clean dataset testing:[19/20] val_loss: 0.000427 val_acc: 0.982100
AT dataset testing:[19/20] val_loss: 0.166120 val_acc: 0.000000
nbits:3
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017996 train_acc: 0.101562
[0/20][100/469] train_loss: 0.011297 train_acc: 0.553991
[0/20][200/469] train_loss: 0.007196 train_acc: 0.714941
[0/20][300/469] train_loss: 0.005491 train_acc: 0.783534
[0/20][400/469] train_loss: 0.004537 train_acc: 0.821423
Clean dataset testing:[0/20] val_loss: 0.001145 val_acc: 0.954500
AT dataset testing:[0/20] val_loss: 0.092503 val_acc: 0.000000
[1/20][0/469] train_loss: 0.001679 train_acc: 0.937500
[1/20][100/469] train_loss: 0.001299 train_acc: 0.947710
[1/20][200/469] train_loss: 0.001168 train_acc: 0.953591
[1/20][300/469] train_loss: 0.001107 train_acc: 0.955980
[1/20][400/469] train_loss: 0.001058 train_acc: 0.958035
Clean dataset testing:[1/20] val_loss: 0.000720 val_acc: 0.971500
AT dataset testing:[1/20] val_loss: 0.099448 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000694 train_acc: 0.960938
[2/20][100/469] train_loss: 0.000778 train_acc: 0.968131
[2/20][200/469] train_loss: 0.000766 train_acc: 0.969838
[2/20][300/469] train_loss: 0.000761 train_acc: 0.970385
[2/20][400/469] train_loss: 0.000748 train_acc: 0.970445
Clean dataset testing:[2/20] val_loss: 0.000601 val_acc: 0.976800
AT dataset testing:[2/20] val_loss: 0.101859 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000541 train_acc: 0.992188
[3/20][100/469] train_loss: 0.000597 train_acc: 0.976872
[3/20][200/469] train_loss: 0.000626 train_acc: 0.975669
[3/20][300/469] train_loss: 0.000612 train_acc: 0.976173
[3/20][400/469] train_loss: 0.000628 train_acc: 0.975394
Clean dataset testing:[3/20] val_loss: 0.000540 val_acc: 0.977400
AT dataset testing:[3/20] val_loss: 0.114567 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000562 train_acc: 0.976562
[4/20][100/469] train_loss: 0.000567 train_acc: 0.977645
[4/20][200/469] train_loss: 0.000581 train_acc: 0.977418
[4/20][300/469] train_loss: 0.000561 train_acc: 0.978068
[4/20][400/469] train_loss: 0.000563 train_acc: 0.978063
Clean dataset testing:[4/20] val_loss: 0.000551 val_acc: 0.977300
AT dataset testing:[4/20] val_loss: 0.121402 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000817 train_acc: 0.984375
[5/20][100/469] train_loss: 0.000582 train_acc: 0.976485
[5/20][200/469] train_loss: 0.000522 train_acc: 0.978856
[5/20][300/469] train_loss: 0.000524 train_acc: 0.978924
[5/20][400/469] train_loss: 0.000501 train_acc: 0.979972
Clean dataset testing:[5/20] val_loss: 0.000441 val_acc: 0.982600
AT dataset testing:[5/20] val_loss: 0.119275 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000197 train_acc: 0.992188
[6/20][100/469] train_loss: 0.000422 train_acc: 0.983524
[6/20][200/469] train_loss: 0.000454 train_acc: 0.981926
[6/20][300/469] train_loss: 0.000465 train_acc: 0.981234
[6/20][400/469] train_loss: 0.000468 train_acc: 0.981219
Clean dataset testing:[6/20] val_loss: 0.000445 val_acc: 0.981500
AT dataset testing:[6/20] val_loss: 0.126928 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000154 train_acc: 0.992188
[7/20][100/469] train_loss: 0.000438 train_acc: 0.982364
[7/20][200/469] train_loss: 0.000429 train_acc: 0.982509
[7/20][300/469] train_loss: 0.000453 train_acc: 0.981987
[7/20][400/469] train_loss: 0.000447 train_acc: 0.982193
Clean dataset testing:[7/20] val_loss: 0.000412 val_acc: 0.983900
AT dataset testing:[7/20] val_loss: 0.129803 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000211 train_acc: 0.992188
[8/20][100/469] train_loss: 0.000468 train_acc: 0.981590
[8/20][200/469] train_loss: 0.000433 train_acc: 0.982898
[8/20][300/469] train_loss: 0.000427 train_acc: 0.982688
[8/20][400/469] train_loss: 0.000433 train_acc: 0.982544
Clean dataset testing:[8/20] val_loss: 0.000425 val_acc: 0.984000
AT dataset testing:[8/20] val_loss: 0.124682 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000312 train_acc: 0.984375
[9/20][100/469] train_loss: 0.000352 train_acc: 0.985845
[9/20][200/469] train_loss: 0.000368 train_acc: 0.985541
[9/20][300/469] train_loss: 0.000390 train_acc: 0.984531
[9/20][400/469] train_loss: 0.000397 train_acc: 0.984258
Clean dataset testing:[9/20] val_loss: 0.000346 val_acc: 0.986300
AT dataset testing:[9/20] val_loss: 0.130528 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000167 train_acc: 0.992188
[10/20][100/469] train_loss: 0.000409 train_acc: 0.983137
[10/20][200/469] train_loss: 0.000381 train_acc: 0.984919
[10/20][300/469] train_loss: 0.000373 train_acc: 0.985309
[10/20][400/469] train_loss: 0.000376 train_acc: 0.985388
Clean dataset testing:[10/20] val_loss: 0.000331 val_acc: 0.985800
AT dataset testing:[10/20] val_loss: 0.137805 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000454 train_acc: 0.984375
[11/20][100/469] train_loss: 0.000335 train_acc: 0.986773
[11/20][200/469] train_loss: 0.000348 train_acc: 0.986124
[11/20][300/469] train_loss: 0.000362 train_acc: 0.985569
[11/20][400/469] train_loss: 0.000375 train_acc: 0.985096
Clean dataset testing:[11/20] val_loss: 0.000344 val_acc: 0.986100
AT dataset testing:[11/20] val_loss: 0.137898 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000330 train_acc: 0.984375
[12/20][100/469] train_loss: 0.000318 train_acc: 0.987082
[12/20][200/469] train_loss: 0.000324 train_acc: 0.987018
[12/20][300/469] train_loss: 0.000340 train_acc: 0.986218
[12/20][400/469] train_loss: 0.000336 train_acc: 0.986187
Clean dataset testing:[12/20] val_loss: 0.000461 val_acc: 0.980200
AT dataset testing:[12/20] val_loss: 0.139677 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000196 train_acc: 0.992188
[13/20][100/469] train_loss: 0.000275 train_acc: 0.988939
[13/20][200/469] train_loss: 0.000311 train_acc: 0.987446
[13/20][300/469] train_loss: 0.000313 train_acc: 0.987282
[13/20][400/469] train_loss: 0.000323 train_acc: 0.987044
Clean dataset testing:[13/20] val_loss: 0.000328 val_acc: 0.986400
AT dataset testing:[13/20] val_loss: 0.141859 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000174 train_acc: 0.992188
[14/20][100/469] train_loss: 0.000288 train_acc: 0.988165
[14/20][200/469] train_loss: 0.000292 train_acc: 0.988067
[14/20][300/469] train_loss: 0.000304 train_acc: 0.987801
[14/20][400/469] train_loss: 0.000305 train_acc: 0.987668
Clean dataset testing:[14/20] val_loss: 0.000304 val_acc: 0.987200
AT dataset testing:[14/20] val_loss: 0.151145 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000064 train_acc: 1.000000
[15/20][100/469] train_loss: 0.000248 train_acc: 0.990254
[15/20][200/469] train_loss: 0.000254 train_acc: 0.989622
[15/20][300/469] train_loss: 0.000289 train_acc: 0.987853
[15/20][400/469] train_loss: 0.000287 train_acc: 0.988096
Clean dataset testing:[15/20] val_loss: 0.000351 val_acc: 0.985800
AT dataset testing:[15/20] val_loss: 0.150460 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000026 train_acc: 1.000000
[16/20][100/469] train_loss: 0.000249 train_acc: 0.989403
[16/20][200/469] train_loss: 0.000247 train_acc: 0.990127
[16/20][300/469] train_loss: 0.000264 train_acc: 0.989281
[16/20][400/469] train_loss: 0.000268 train_acc: 0.989051
Clean dataset testing:[16/20] val_loss: 0.000339 val_acc: 0.986500
AT dataset testing:[16/20] val_loss: 0.146861 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000200 train_acc: 0.992188
[17/20][100/469] train_loss: 0.000252 train_acc: 0.989248
[17/20][200/469] train_loss: 0.000252 train_acc: 0.989195
[17/20][300/469] train_loss: 0.000255 train_acc: 0.989151
[17/20][400/469] train_loss: 0.000261 train_acc: 0.989109
Clean dataset testing:[17/20] val_loss: 0.000376 val_acc: 0.986000
AT dataset testing:[17/20] val_loss: 0.153500 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000414 train_acc: 0.984375
[18/20][100/469] train_loss: 0.000286 train_acc: 0.988861
[18/20][200/469] train_loss: 0.000261 train_acc: 0.988884
[18/20][300/469] train_loss: 0.000259 train_acc: 0.989047
[18/20][400/469] train_loss: 0.000261 train_acc: 0.989070
Clean dataset testing:[18/20] val_loss: 0.000282 val_acc: 0.989400
AT dataset testing:[18/20] val_loss: 0.158798 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000046 train_acc: 1.000000
[19/20][100/469] train_loss: 0.000219 train_acc: 0.990099
[19/20][200/469] train_loss: 0.000256 train_acc: 0.988689
[19/20][300/469] train_loss: 0.000260 train_acc: 0.988761
[19/20][400/469] train_loss: 0.000267 train_acc: 0.988778
Clean dataset testing:[19/20] val_loss: 0.000268 val_acc: 0.989000
AT dataset testing:[19/20] val_loss: 0.161046 val_acc: 0.000000
nbits:4
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018085 train_acc: 0.046875
[0/20][100/469] train_loss: 0.011528 train_acc: 0.543239
[0/20][200/469] train_loss: 0.007552 train_acc: 0.698500
[0/20][300/469] train_loss: 0.005918 train_acc: 0.764587
[0/20][400/469] train_loss: 0.004946 train_acc: 0.803070
Clean dataset testing:[0/20] val_loss: 0.001545 val_acc: 0.939000
AT dataset testing:[0/20] val_loss: 0.088394 val_acc: 0.000000
[1/20][0/469] train_loss: 0.001320 train_acc: 0.953125
[1/20][100/469] train_loss: 0.001488 train_acc: 0.942760
[1/20][200/469] train_loss: 0.001442 train_acc: 0.945312
[1/20][300/469] train_loss: 0.001382 train_acc: 0.947026
[1/20][400/469] train_loss: 0.001334 train_acc: 0.948215
Clean dataset testing:[1/20] val_loss: 0.000971 val_acc: 0.960300
AT dataset testing:[1/20] val_loss: 0.094998 val_acc: 0.000000
[2/20][0/469] train_loss: 0.001189 train_acc: 0.960938
[2/20][100/469] train_loss: 0.000955 train_acc: 0.962407
[2/20][200/469] train_loss: 0.000948 train_acc: 0.962998
[2/20][300/469] train_loss: 0.000923 train_acc: 0.964286
[2/20][400/469] train_loss: 0.000899 train_acc: 0.964522
Clean dataset testing:[2/20] val_loss: 0.000649 val_acc: 0.973600
AT dataset testing:[2/20] val_loss: 0.098941 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000912 train_acc: 0.968750
[3/20][100/469] train_loss: 0.000799 train_acc: 0.968595
[3/20][200/469] train_loss: 0.000750 train_acc: 0.970033
[3/20][300/469] train_loss: 0.000736 train_acc: 0.971086
[3/20][400/469] train_loss: 0.000717 train_acc: 0.972354
Clean dataset testing:[3/20] val_loss: 0.000625 val_acc: 0.973700
AT dataset testing:[3/20] val_loss: 0.110571 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000621 train_acc: 0.960938
[4/20][100/469] train_loss: 0.000616 train_acc: 0.976485
[4/20][200/469] train_loss: 0.000637 train_acc: 0.974502
[4/20][300/469] train_loss: 0.000623 train_acc: 0.975446
[4/20][400/469] train_loss: 0.000624 train_acc: 0.975394
Clean dataset testing:[4/20] val_loss: 0.000452 val_acc: 0.982500
AT dataset testing:[4/20] val_loss: 0.113616 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000813 train_acc: 0.960938
[5/20][100/469] train_loss: 0.000598 train_acc: 0.976717
[5/20][200/469] train_loss: 0.000556 train_acc: 0.978817
[5/20][300/469] train_loss: 0.000545 train_acc: 0.979054
[5/20][400/469] train_loss: 0.000536 train_acc: 0.979037
Clean dataset testing:[5/20] val_loss: 0.000428 val_acc: 0.982700
AT dataset testing:[5/20] val_loss: 0.120689 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000748 train_acc: 0.976562
[6/20][100/469] train_loss: 0.000521 train_acc: 0.980662
[6/20][200/469] train_loss: 0.000520 train_acc: 0.980061
[6/20][300/469] train_loss: 0.000494 train_acc: 0.980793
[6/20][400/469] train_loss: 0.000497 train_acc: 0.980654
Clean dataset testing:[6/20] val_loss: 0.000522 val_acc: 0.980200
AT dataset testing:[6/20] val_loss: 0.132636 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000386 train_acc: 0.992188
[7/20][100/469] train_loss: 0.000438 train_acc: 0.982441
[7/20][200/469] train_loss: 0.000436 train_acc: 0.982393
[7/20][300/469] train_loss: 0.000441 train_acc: 0.982350
[7/20][400/469] train_loss: 0.000439 train_acc: 0.982524
Clean dataset testing:[7/20] val_loss: 0.000359 val_acc: 0.984900
AT dataset testing:[7/20] val_loss: 0.125634 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000342 train_acc: 0.976562
[8/20][100/469] train_loss: 0.000430 train_acc: 0.982983
[8/20][200/469] train_loss: 0.000414 train_acc: 0.983753
[8/20][300/469] train_loss: 0.000415 train_acc: 0.983181
[8/20][400/469] train_loss: 0.000411 train_acc: 0.983732
Clean dataset testing:[8/20] val_loss: 0.000343 val_acc: 0.986100
AT dataset testing:[8/20] val_loss: 0.131093 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000172 train_acc: 1.000000
[9/20][100/469] train_loss: 0.000366 train_acc: 0.984375
[9/20][200/469] train_loss: 0.000366 train_acc: 0.984530
[9/20][300/469] train_loss: 0.000390 train_acc: 0.983674
[9/20][400/469] train_loss: 0.000390 train_acc: 0.983810
Clean dataset testing:[9/20] val_loss: 0.000335 val_acc: 0.987100
AT dataset testing:[9/20] val_loss: 0.137602 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000752 train_acc: 0.968750
[10/20][100/469] train_loss: 0.000361 train_acc: 0.985303
[10/20][200/469] train_loss: 0.000360 train_acc: 0.985230
[10/20][300/469] train_loss: 0.000364 train_acc: 0.985180
[10/20][400/469] train_loss: 0.000351 train_acc: 0.985524
Clean dataset testing:[10/20] val_loss: 0.000329 val_acc: 0.986100
AT dataset testing:[10/20] val_loss: 0.151061 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000037 train_acc: 1.000000
[11/20][100/469] train_loss: 0.000332 train_acc: 0.986850
[11/20][200/469] train_loss: 0.000325 train_acc: 0.986746
[11/20][300/469] train_loss: 0.000328 train_acc: 0.986919
[11/20][400/469] train_loss: 0.000332 train_acc: 0.986830
Clean dataset testing:[11/20] val_loss: 0.000296 val_acc: 0.987500
AT dataset testing:[11/20] val_loss: 0.148510 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000560 train_acc: 0.976562
[12/20][100/469] train_loss: 0.000271 train_acc: 0.989171
[12/20][200/469] train_loss: 0.000294 train_acc: 0.987912
[12/20][300/469] train_loss: 0.000311 train_acc: 0.986996
[12/20][400/469] train_loss: 0.000298 train_acc: 0.987492
Clean dataset testing:[12/20] val_loss: 0.000362 val_acc: 0.985700
AT dataset testing:[12/20] val_loss: 0.152276 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000102 train_acc: 0.992188
[13/20][100/469] train_loss: 0.000239 train_acc: 0.990408
[13/20][200/469] train_loss: 0.000248 train_acc: 0.990400
[13/20][300/469] train_loss: 0.000257 train_acc: 0.989618
[13/20][400/469] train_loss: 0.000268 train_acc: 0.989207
Clean dataset testing:[13/20] val_loss: 0.000383 val_acc: 0.984600
AT dataset testing:[13/20] val_loss: 0.162612 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000029 train_acc: 1.000000
[14/20][100/469] train_loss: 0.000238 train_acc: 0.989790
[14/20][200/469] train_loss: 0.000257 train_acc: 0.989117
[14/20][300/469] train_loss: 0.000276 train_acc: 0.988528
[14/20][400/469] train_loss: 0.000279 train_acc: 0.988486
Clean dataset testing:[14/20] val_loss: 0.000296 val_acc: 0.988400
AT dataset testing:[14/20] val_loss: 0.164044 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000239 train_acc: 0.984375
[15/20][100/469] train_loss: 0.000263 train_acc: 0.990176
[15/20][200/469] train_loss: 0.000265 train_acc: 0.989234
[15/20][300/469] train_loss: 0.000254 train_acc: 0.989514
[15/20][400/469] train_loss: 0.000253 train_acc: 0.989635
Clean dataset testing:[15/20] val_loss: 0.000327 val_acc: 0.986800
AT dataset testing:[15/20] val_loss: 0.171798 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000081 train_acc: 1.000000
[16/20][100/469] train_loss: 0.000235 train_acc: 0.990563
[16/20][200/469] train_loss: 0.000239 train_acc: 0.990438
[16/20][300/469] train_loss: 0.000244 train_acc: 0.990241
[16/20][400/469] train_loss: 0.000245 train_acc: 0.989850
Clean dataset testing:[16/20] val_loss: 0.000314 val_acc: 0.987500
AT dataset testing:[16/20] val_loss: 0.168701 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000085 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000199 train_acc: 0.991491
[17/20][200/469] train_loss: 0.000224 train_acc: 0.990361
[17/20][300/469] train_loss: 0.000227 train_acc: 0.990319
[17/20][400/469] train_loss: 0.000235 train_acc: 0.990473
Clean dataset testing:[17/20] val_loss: 0.000274 val_acc: 0.988800
AT dataset testing:[17/20] val_loss: 0.175998 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000042 train_acc: 1.000000
[18/20][100/469] train_loss: 0.000219 train_acc: 0.991259
[18/20][200/469] train_loss: 0.000213 train_acc: 0.991449
[18/20][300/469] train_loss: 0.000231 train_acc: 0.990345
[18/20][400/469] train_loss: 0.000230 train_acc: 0.990434
Clean dataset testing:[18/20] val_loss: 0.000282 val_acc: 0.988800
AT dataset testing:[18/20] val_loss: 0.172961 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000103 train_acc: 1.000000
[19/20][100/469] train_loss: 0.000209 train_acc: 0.991646
[19/20][200/469] train_loss: 0.000211 train_acc: 0.990983
[19/20][300/469] train_loss: 0.000206 train_acc: 0.991149
[19/20][400/469] train_loss: 0.000214 train_acc: 0.990980
Clean dataset testing:[19/20] val_loss: 0.000309 val_acc: 0.987600
AT dataset testing:[19/20] val_loss: 0.181937 val_acc: 0.000000
nbits:5
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017989 train_acc: 0.109375
[0/20][100/469] train_loss: 0.010870 train_acc: 0.600093
[0/20][200/469] train_loss: 0.006804 train_acc: 0.746074
[0/20][300/469] train_loss: 0.005105 train_acc: 0.808217
[0/20][400/469] train_loss: 0.004183 train_acc: 0.842386
Clean dataset testing:[0/20] val_loss: 0.001093 val_acc: 0.955900
AT dataset testing:[0/20] val_loss: 0.090113 val_acc: 0.000000
[1/20][0/469] train_loss: 0.000980 train_acc: 0.960938
[1/20][100/469] train_loss: 0.001053 train_acc: 0.958462
[1/20][200/469] train_loss: 0.000977 train_acc: 0.960627
[1/20][300/469] train_loss: 0.000955 train_acc: 0.961560
[1/20][400/469] train_loss: 0.000928 train_acc: 0.963100
Clean dataset testing:[1/20] val_loss: 0.000727 val_acc: 0.971100
AT dataset testing:[1/20] val_loss: 0.098861 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000898 train_acc: 0.984375
[2/20][100/469] train_loss: 0.000707 train_acc: 0.970452
[2/20][200/469] train_loss: 0.000731 train_acc: 0.970693
[2/20][300/469] train_loss: 0.000700 train_acc: 0.971813
[2/20][400/469] train_loss: 0.000691 train_acc: 0.972023
Clean dataset testing:[2/20] val_loss: 0.000554 val_acc: 0.976900
AT dataset testing:[2/20] val_loss: 0.113881 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000543 train_acc: 0.976562
[3/20][100/469] train_loss: 0.000652 train_acc: 0.974319
[3/20][200/469] train_loss: 0.000628 train_acc: 0.975552
[3/20][300/469] train_loss: 0.000602 train_acc: 0.976355
[3/20][400/469] train_loss: 0.000584 train_acc: 0.976835
Clean dataset testing:[3/20] val_loss: 0.000533 val_acc: 0.977400
AT dataset testing:[3/20] val_loss: 0.126725 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000665 train_acc: 0.976562
[4/20][100/469] train_loss: 0.000505 train_acc: 0.979270
[4/20][200/469] train_loss: 0.000517 train_acc: 0.978545
[4/20][300/469] train_loss: 0.000508 train_acc: 0.979495
[4/20][400/469] train_loss: 0.000530 train_acc: 0.978413
Clean dataset testing:[4/20] val_loss: 0.000431 val_acc: 0.983600
AT dataset testing:[4/20] val_loss: 0.128579 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000564 train_acc: 0.984375
[5/20][100/469] train_loss: 0.000461 train_acc: 0.981436
[5/20][200/469] train_loss: 0.000456 train_acc: 0.981538
[5/20][300/469] train_loss: 0.000457 train_acc: 0.981234
[5/20][400/469] train_loss: 0.000466 train_acc: 0.980771
Clean dataset testing:[5/20] val_loss: 0.000389 val_acc: 0.983500
AT dataset testing:[5/20] val_loss: 0.132702 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000601 train_acc: 0.976562
[6/20][100/469] train_loss: 0.000414 train_acc: 0.982828
[6/20][200/469] train_loss: 0.000424 train_acc: 0.982665
[6/20][300/469] train_loss: 0.000415 train_acc: 0.983051
[6/20][400/469] train_loss: 0.000405 train_acc: 0.983732
Clean dataset testing:[6/20] val_loss: 0.000395 val_acc: 0.983000
AT dataset testing:[6/20] val_loss: 0.136751 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000151 train_acc: 0.992188
[7/20][100/469] train_loss: 0.000351 train_acc: 0.986541
[7/20][200/469] train_loss: 0.000366 train_acc: 0.985697
[7/20][300/469] train_loss: 0.000385 train_acc: 0.984738
[7/20][400/469] train_loss: 0.000379 train_acc: 0.984745
Clean dataset testing:[7/20] val_loss: 0.000348 val_acc: 0.985900
AT dataset testing:[7/20] val_loss: 0.141868 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000058 train_acc: 1.000000
[8/20][100/469] train_loss: 0.000317 train_acc: 0.987237
[8/20][200/469] train_loss: 0.000338 train_acc: 0.986163
[8/20][300/469] train_loss: 0.000331 train_acc: 0.986633
[8/20][400/469] train_loss: 0.000334 train_acc: 0.986713
Clean dataset testing:[8/20] val_loss: 0.000318 val_acc: 0.986900
AT dataset testing:[8/20] val_loss: 0.143547 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000693 train_acc: 0.976562
[9/20][100/469] train_loss: 0.000289 train_acc: 0.987005
[9/20][200/469] train_loss: 0.000332 train_acc: 0.985735
[9/20][300/469] train_loss: 0.000325 train_acc: 0.986374
[9/20][400/469] train_loss: 0.000339 train_acc: 0.985953
Clean dataset testing:[9/20] val_loss: 0.000332 val_acc: 0.986200
AT dataset testing:[9/20] val_loss: 0.146433 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000432 train_acc: 0.984375
[10/20][100/469] train_loss: 0.000328 train_acc: 0.987314
[10/20][200/469] train_loss: 0.000317 train_acc: 0.987174
[10/20][300/469] train_loss: 0.000328 train_acc: 0.986400
[10/20][400/469] train_loss: 0.000317 train_acc: 0.986791
Clean dataset testing:[10/20] val_loss: 0.000330 val_acc: 0.986400
AT dataset testing:[10/20] val_loss: 0.153522 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000096 train_acc: 1.000000
[11/20][100/469] train_loss: 0.000301 train_acc: 0.988939
[11/20][200/469] train_loss: 0.000290 train_acc: 0.988456
[11/20][300/469] train_loss: 0.000293 train_acc: 0.988294
[11/20][400/469] train_loss: 0.000297 train_acc: 0.987745
Clean dataset testing:[11/20] val_loss: 0.000408 val_acc: 0.982700
AT dataset testing:[11/20] val_loss: 0.162811 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000188 train_acc: 0.992188
[12/20][100/469] train_loss: 0.000246 train_acc: 0.989790
[12/20][200/469] train_loss: 0.000267 train_acc: 0.988884
[12/20][300/469] train_loss: 0.000264 train_acc: 0.988761
[12/20][400/469] train_loss: 0.000271 train_acc: 0.988720
Clean dataset testing:[12/20] val_loss: 0.000320 val_acc: 0.986200
AT dataset testing:[12/20] val_loss: 0.155826 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000053 train_acc: 1.000000
[13/20][100/469] train_loss: 0.000226 train_acc: 0.991491
[13/20][200/469] train_loss: 0.000241 train_acc: 0.990127
[13/20][300/469] train_loss: 0.000245 train_acc: 0.989877
[13/20][400/469] train_loss: 0.000252 train_acc: 0.989596
Clean dataset testing:[13/20] val_loss: 0.000265 val_acc: 0.988700
AT dataset testing:[13/20] val_loss: 0.157195 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000035 train_acc: 1.000000
[14/20][100/469] train_loss: 0.000242 train_acc: 0.989403
[14/20][200/469] train_loss: 0.000256 train_acc: 0.989778
[14/20][300/469] train_loss: 0.000253 train_acc: 0.989852
[14/20][400/469] train_loss: 0.000246 train_acc: 0.990103
Clean dataset testing:[14/20] val_loss: 0.000309 val_acc: 0.987400
AT dataset testing:[14/20] val_loss: 0.167623 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000177 train_acc: 0.992188
[15/20][100/469] train_loss: 0.000259 train_acc: 0.988861
[15/20][200/469] train_loss: 0.000227 train_acc: 0.990788
[15/20][300/469] train_loss: 0.000237 train_acc: 0.990423
[15/20][400/469] train_loss: 0.000244 train_acc: 0.990454
Clean dataset testing:[15/20] val_loss: 0.000315 val_acc: 0.987900
AT dataset testing:[15/20] val_loss: 0.172674 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000111 train_acc: 0.992188
[16/20][100/469] train_loss: 0.000198 train_acc: 0.991723
[16/20][200/469] train_loss: 0.000204 train_acc: 0.991682
[16/20][300/469] train_loss: 0.000213 train_acc: 0.991409
[16/20][400/469] train_loss: 0.000225 train_acc: 0.990921
Clean dataset testing:[16/20] val_loss: 0.000282 val_acc: 0.988000
AT dataset testing:[16/20] val_loss: 0.180352 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000081 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000238 train_acc: 0.990873
[17/20][200/469] train_loss: 0.000228 train_acc: 0.990944
[17/20][300/469] train_loss: 0.000228 train_acc: 0.990630
[17/20][400/469] train_loss: 0.000218 train_acc: 0.991058
Clean dataset testing:[17/20] val_loss: 0.000239 val_acc: 0.990200
AT dataset testing:[17/20] val_loss: 0.179288 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000259 train_acc: 0.992188
[18/20][100/469] train_loss: 0.000201 train_acc: 0.992188
[18/20][200/469] train_loss: 0.000207 train_acc: 0.991799
[18/20][300/469] train_loss: 0.000205 train_acc: 0.991720
[18/20][400/469] train_loss: 0.000202 train_acc: 0.991700
Clean dataset testing:[18/20] val_loss: 0.000244 val_acc: 0.990700
AT dataset testing:[18/20] val_loss: 0.189384 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000136 train_acc: 0.992188
[19/20][100/469] train_loss: 0.000173 train_acc: 0.993193
[19/20][200/469] train_loss: 0.000182 train_acc: 0.992809
[19/20][300/469] train_loss: 0.000188 train_acc: 0.992525
[19/20][400/469] train_loss: 0.000192 train_acc: 0.992149
Clean dataset testing:[19/20] val_loss: 0.000258 val_acc: 0.989500
AT dataset testing:[19/20] val_loss: 0.185097 val_acc: 0.000000
nbits:6
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.017917 train_acc: 0.164062
[0/20][100/469] train_loss: 0.010455 train_acc: 0.600944
[0/20][200/469] train_loss: 0.006758 train_acc: 0.739778
[0/20][300/469] train_loss: 0.005143 train_acc: 0.801936
[0/20][400/469] train_loss: 0.004226 train_acc: 0.837808
Clean dataset testing:[0/20] val_loss: 0.001043 val_acc: 0.962900
AT dataset testing:[0/20] val_loss: 0.087239 val_acc: 0.000000
[1/20][0/469] train_loss: 0.000572 train_acc: 0.968750
[1/20][100/469] train_loss: 0.001000 train_acc: 0.961943
[1/20][200/469] train_loss: 0.001012 train_acc: 0.961093
[1/20][300/469] train_loss: 0.000963 train_acc: 0.962391
[1/20][400/469] train_loss: 0.000940 train_acc: 0.963178
Clean dataset testing:[1/20] val_loss: 0.000643 val_acc: 0.975700
AT dataset testing:[1/20] val_loss: 0.097984 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000634 train_acc: 0.968750
[2/20][100/469] train_loss: 0.000700 train_acc: 0.972540
[2/20][200/469] train_loss: 0.000696 train_acc: 0.972676
[2/20][300/469] train_loss: 0.000685 train_acc: 0.972462
[2/20][400/469] train_loss: 0.000662 train_acc: 0.973465
Clean dataset testing:[2/20] val_loss: 0.000529 val_acc: 0.977500
AT dataset testing:[2/20] val_loss: 0.108432 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000767 train_acc: 0.976562
[3/20][100/469] train_loss: 0.000626 train_acc: 0.976485
[3/20][200/469] train_loss: 0.000588 train_acc: 0.977146
[3/20][300/469] train_loss: 0.000569 train_acc: 0.978172
[3/20][400/469] train_loss: 0.000554 train_acc: 0.978725
Clean dataset testing:[3/20] val_loss: 0.000464 val_acc: 0.981400
AT dataset testing:[3/20] val_loss: 0.110873 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000379 train_acc: 0.984375
[4/20][100/469] train_loss: 0.000513 train_acc: 0.978960
[4/20][200/469] train_loss: 0.000483 train_acc: 0.979789
[4/20][300/469] train_loss: 0.000471 train_acc: 0.980793
[4/20][400/469] train_loss: 0.000469 train_acc: 0.981160
Clean dataset testing:[4/20] val_loss: 0.000416 val_acc: 0.981800
AT dataset testing:[4/20] val_loss: 0.120715 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000732 train_acc: 0.976562
[5/20][100/469] train_loss: 0.000438 train_acc: 0.983215
[5/20][200/469] train_loss: 0.000432 train_acc: 0.983870
[5/20][300/469] train_loss: 0.000418 train_acc: 0.983804
[5/20][400/469] train_loss: 0.000422 train_acc: 0.983440
Clean dataset testing:[5/20] val_loss: 0.000348 val_acc: 0.984700
AT dataset testing:[5/20] val_loss: 0.125213 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000453 train_acc: 0.992188
[6/20][100/469] train_loss: 0.000369 train_acc: 0.985613
[6/20][200/469] train_loss: 0.000367 train_acc: 0.985697
[6/20][300/469] train_loss: 0.000376 train_acc: 0.985232
[6/20][400/469] train_loss: 0.000375 train_acc: 0.985076
Clean dataset testing:[6/20] val_loss: 0.000301 val_acc: 0.987800
AT dataset testing:[6/20] val_loss: 0.134686 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000431 train_acc: 0.984375
[7/20][100/469] train_loss: 0.000370 train_acc: 0.984220
[7/20][200/469] train_loss: 0.000353 train_acc: 0.985191
[7/20][300/469] train_loss: 0.000348 train_acc: 0.985777
[7/20][400/469] train_loss: 0.000343 train_acc: 0.986050
Clean dataset testing:[7/20] val_loss: 0.000324 val_acc: 0.985800
AT dataset testing:[7/20] val_loss: 0.137732 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000123 train_acc: 1.000000
[8/20][100/469] train_loss: 0.000322 train_acc: 0.987082
[8/20][200/469] train_loss: 0.000318 train_acc: 0.986668
[8/20][300/469] train_loss: 0.000315 train_acc: 0.986945
[8/20][400/469] train_loss: 0.000311 train_acc: 0.987200
Clean dataset testing:[8/20] val_loss: 0.000355 val_acc: 0.986000
AT dataset testing:[8/20] val_loss: 0.142176 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000154 train_acc: 0.992188
[9/20][100/469] train_loss: 0.000294 train_acc: 0.987237
[9/20][200/469] train_loss: 0.000284 train_acc: 0.988223
[9/20][300/469] train_loss: 0.000294 train_acc: 0.988113
[9/20][400/469] train_loss: 0.000285 train_acc: 0.988408
Clean dataset testing:[9/20] val_loss: 0.000281 val_acc: 0.988100
AT dataset testing:[9/20] val_loss: 0.150168 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000154 train_acc: 0.992188
[10/20][100/469] train_loss: 0.000235 train_acc: 0.989867
[10/20][200/469] train_loss: 0.000246 train_acc: 0.989778
[10/20][300/469] train_loss: 0.000245 train_acc: 0.989774
[10/20][400/469] train_loss: 0.000258 train_acc: 0.989791
Clean dataset testing:[10/20] val_loss: 0.000253 val_acc: 0.989600
AT dataset testing:[10/20] val_loss: 0.158142 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000372 train_acc: 0.992188
[11/20][100/469] train_loss: 0.000231 train_acc: 0.991801
[11/20][200/469] train_loss: 0.000237 train_acc: 0.990788
[11/20][300/469] train_loss: 0.000237 train_acc: 0.990968
[11/20][400/469] train_loss: 0.000236 train_acc: 0.990824
Clean dataset testing:[11/20] val_loss: 0.000285 val_acc: 0.988200
AT dataset testing:[11/20] val_loss: 0.159702 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000375 train_acc: 0.984375
[12/20][100/469] train_loss: 0.000236 train_acc: 0.989635
[12/20][200/469] train_loss: 0.000250 train_acc: 0.988767
[12/20][300/469] train_loss: 0.000227 train_acc: 0.989981
[12/20][400/469] train_loss: 0.000235 train_acc: 0.989908
Clean dataset testing:[12/20] val_loss: 0.000302 val_acc: 0.987700
AT dataset testing:[12/20] val_loss: 0.169159 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000051 train_acc: 1.000000
[13/20][100/469] train_loss: 0.000231 train_acc: 0.989712
[13/20][200/469] train_loss: 0.000229 train_acc: 0.990050
[13/20][300/469] train_loss: 0.000235 train_acc: 0.990059
[13/20][400/469] train_loss: 0.000230 train_acc: 0.990298
Clean dataset testing:[13/20] val_loss: 0.000262 val_acc: 0.988900
AT dataset testing:[13/20] val_loss: 0.174790 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000248 train_acc: 0.992188
[14/20][100/469] train_loss: 0.000172 train_acc: 0.992806
[14/20][200/469] train_loss: 0.000190 train_acc: 0.992382
[14/20][300/469] train_loss: 0.000197 train_acc: 0.992213
[14/20][400/469] train_loss: 0.000198 train_acc: 0.992246
Clean dataset testing:[14/20] val_loss: 0.000240 val_acc: 0.989900
AT dataset testing:[14/20] val_loss: 0.182002 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000032 train_acc: 1.000000
[15/20][100/469] train_loss: 0.000200 train_acc: 0.991259
[15/20][200/469] train_loss: 0.000183 train_acc: 0.992032
[15/20][300/469] train_loss: 0.000185 train_acc: 0.991928
[15/20][400/469] train_loss: 0.000188 train_acc: 0.992032
Clean dataset testing:[15/20] val_loss: 0.000249 val_acc: 0.989600
AT dataset testing:[15/20] val_loss: 0.188438 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000020 train_acc: 1.000000
[16/20][100/469] train_loss: 0.000204 train_acc: 0.991955
[16/20][200/469] train_loss: 0.000189 train_acc: 0.992188
[16/20][300/469] train_loss: 0.000196 train_acc: 0.991513
[16/20][400/469] train_loss: 0.000195 train_acc: 0.991506
Clean dataset testing:[16/20] val_loss: 0.000269 val_acc: 0.989100
AT dataset testing:[16/20] val_loss: 0.189765 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000171 train_acc: 0.992188
[17/20][100/469] train_loss: 0.000138 train_acc: 0.994121
[17/20][200/469] train_loss: 0.000164 train_acc: 0.993509
[17/20][300/469] train_loss: 0.000180 train_acc: 0.992914
[17/20][400/469] train_loss: 0.000179 train_acc: 0.992558
Clean dataset testing:[17/20] val_loss: 0.000307 val_acc: 0.987700
AT dataset testing:[17/20] val_loss: 0.197360 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000333 train_acc: 0.992188
[18/20][100/469] train_loss: 0.000152 train_acc: 0.993812
[18/20][200/469] train_loss: 0.000163 train_acc: 0.993470
[18/20][300/469] train_loss: 0.000171 train_acc: 0.993148
[18/20][400/469] train_loss: 0.000176 train_acc: 0.992791
Clean dataset testing:[18/20] val_loss: 0.000266 val_acc: 0.989800
AT dataset testing:[18/20] val_loss: 0.203185 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000194 train_acc: 0.984375
[19/20][100/469] train_loss: 0.000155 train_acc: 0.993193
[19/20][200/469] train_loss: 0.000168 train_acc: 0.992732
[19/20][300/469] train_loss: 0.000161 train_acc: 0.993174
[19/20][400/469] train_loss: 0.000158 train_acc: 0.993356
Clean dataset testing:[19/20] val_loss: 0.000384 val_acc: 0.984300
AT dataset testing:[19/20] val_loss: 0.233753 val_acc: 0.000000
nbits:7
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018035 train_acc: 0.093750
[0/20][100/469] train_loss: 0.010751 train_acc: 0.574799
[0/20][200/469] train_loss: 0.006703 train_acc: 0.736901
[0/20][300/469] train_loss: 0.005063 train_acc: 0.801547
[0/20][400/469] train_loss: 0.004115 train_acc: 0.838957
Clean dataset testing:[0/20] val_loss: 0.000986 val_acc: 0.962500
AT dataset testing:[0/20] val_loss: 0.090277 val_acc: 0.000000
[1/20][0/469] train_loss: 0.000692 train_acc: 0.968750
[1/20][100/469] train_loss: 0.001061 train_acc: 0.959004
[1/20][200/469] train_loss: 0.001028 train_acc: 0.960354
[1/20][300/469] train_loss: 0.000988 train_acc: 0.961820
[1/20][400/469] train_loss: 0.000964 train_acc: 0.962165
Clean dataset testing:[1/20] val_loss: 0.000684 val_acc: 0.972400
AT dataset testing:[1/20] val_loss: 0.098053 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000742 train_acc: 0.968750
[2/20][100/469] train_loss: 0.000749 train_acc: 0.970916
[2/20][200/469] train_loss: 0.000770 train_acc: 0.969450
[2/20][300/469] train_loss: 0.000746 train_acc: 0.970775
[2/20][400/469] train_loss: 0.000721 train_acc: 0.971575
Clean dataset testing:[2/20] val_loss: 0.000526 val_acc: 0.979700
AT dataset testing:[2/20] val_loss: 0.105768 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000258 train_acc: 0.992188
[3/20][100/469] train_loss: 0.000597 train_acc: 0.977568
[3/20][200/469] train_loss: 0.000635 train_acc: 0.975124
[3/20][300/469] train_loss: 0.000625 train_acc: 0.975446
[3/20][400/469] train_loss: 0.000599 train_acc: 0.976426
Clean dataset testing:[3/20] val_loss: 0.000549 val_acc: 0.977800
AT dataset testing:[3/20] val_loss: 0.108178 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000554 train_acc: 0.968750
[4/20][100/469] train_loss: 0.000509 train_acc: 0.979966
[4/20][200/469] train_loss: 0.000496 train_acc: 0.980527
[4/20][300/469] train_loss: 0.000507 train_acc: 0.979859
[4/20][400/469] train_loss: 0.000507 train_acc: 0.979894
Clean dataset testing:[4/20] val_loss: 0.000479 val_acc: 0.981600
AT dataset testing:[4/20] val_loss: 0.111943 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000574 train_acc: 0.968750
[5/20][100/469] train_loss: 0.000446 train_acc: 0.981590
[5/20][200/469] train_loss: 0.000463 train_acc: 0.980993
[5/20][300/469] train_loss: 0.000458 train_acc: 0.981468
[5/20][400/469] train_loss: 0.000458 train_acc: 0.981511
Clean dataset testing:[5/20] val_loss: 0.000371 val_acc: 0.984800
AT dataset testing:[5/20] val_loss: 0.114470 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000039 train_acc: 1.000000
[6/20][100/469] train_loss: 0.000361 train_acc: 0.985690
[6/20][200/469] train_loss: 0.000386 train_acc: 0.984103
[6/20][300/469] train_loss: 0.000388 train_acc: 0.984375
[6/20][400/469] train_loss: 0.000393 train_acc: 0.984180
Clean dataset testing:[6/20] val_loss: 0.000338 val_acc: 0.986600
AT dataset testing:[6/20] val_loss: 0.119867 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000251 train_acc: 0.992188
[7/20][100/469] train_loss: 0.000331 train_acc: 0.985845
[7/20][200/469] train_loss: 0.000337 train_acc: 0.985308
[7/20][300/469] train_loss: 0.000348 train_acc: 0.985335
[7/20][400/469] train_loss: 0.000348 train_acc: 0.985680
Clean dataset testing:[7/20] val_loss: 0.000371 val_acc: 0.984900
AT dataset testing:[7/20] val_loss: 0.124827 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000054 train_acc: 1.000000
[8/20][100/469] train_loss: 0.000314 train_acc: 0.987933
[8/20][200/469] train_loss: 0.000320 train_acc: 0.987174
[8/20][300/469] train_loss: 0.000329 train_acc: 0.986711
[8/20][400/469] train_loss: 0.000328 train_acc: 0.986577
Clean dataset testing:[8/20] val_loss: 0.000321 val_acc: 0.987100
AT dataset testing:[8/20] val_loss: 0.131230 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000100 train_acc: 1.000000
[9/20][100/469] train_loss: 0.000310 train_acc: 0.987082
[9/20][200/469] train_loss: 0.000313 train_acc: 0.987290
[9/20][300/469] train_loss: 0.000302 train_acc: 0.987775
[9/20][400/469] train_loss: 0.000308 train_acc: 0.987278
Clean dataset testing:[9/20] val_loss: 0.000332 val_acc: 0.985900
AT dataset testing:[9/20] val_loss: 0.136589 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000389 train_acc: 0.976562
[10/20][100/469] train_loss: 0.000271 train_acc: 0.988475
[10/20][200/469] train_loss: 0.000279 train_acc: 0.988573
[10/20][300/469] train_loss: 0.000286 train_acc: 0.988087
[10/20][400/469] train_loss: 0.000290 train_acc: 0.987901
Clean dataset testing:[10/20] val_loss: 0.000338 val_acc: 0.987000
AT dataset testing:[10/20] val_loss: 0.136668 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000280 train_acc: 0.984375
[11/20][100/469] train_loss: 0.000273 train_acc: 0.989093
[11/20][200/469] train_loss: 0.000253 train_acc: 0.989661
[11/20][300/469] train_loss: 0.000260 train_acc: 0.989488
[11/20][400/469] train_loss: 0.000259 train_acc: 0.989577
Clean dataset testing:[11/20] val_loss: 0.000316 val_acc: 0.987600
AT dataset testing:[11/20] val_loss: 0.148048 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000128 train_acc: 0.992188
[12/20][100/469] train_loss: 0.000239 train_acc: 0.990486
[12/20][200/469] train_loss: 0.000235 train_acc: 0.990205
[12/20][300/469] train_loss: 0.000231 train_acc: 0.990423
[12/20][400/469] train_loss: 0.000238 train_acc: 0.990103
Clean dataset testing:[12/20] val_loss: 0.000314 val_acc: 0.987300
AT dataset testing:[12/20] val_loss: 0.149402 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000134 train_acc: 0.992188
[13/20][100/469] train_loss: 0.000207 train_acc: 0.991646
[13/20][200/469] train_loss: 0.000225 train_acc: 0.990672
[13/20][300/469] train_loss: 0.000230 train_acc: 0.990500
[13/20][400/469] train_loss: 0.000225 train_acc: 0.990765
Clean dataset testing:[13/20] val_loss: 0.000293 val_acc: 0.986800
AT dataset testing:[13/20] val_loss: 0.156000 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000018 train_acc: 1.000000
[14/20][100/469] train_loss: 0.000213 train_acc: 0.991337
[14/20][200/469] train_loss: 0.000217 train_acc: 0.990983
[14/20][300/469] train_loss: 0.000216 train_acc: 0.990682
[14/20][400/469] train_loss: 0.000217 train_acc: 0.990765
Clean dataset testing:[14/20] val_loss: 0.000278 val_acc: 0.988600
AT dataset testing:[14/20] val_loss: 0.157882 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000134 train_acc: 0.984375
[15/20][100/469] train_loss: 0.000220 train_acc: 0.991027
[15/20][200/469] train_loss: 0.000234 train_acc: 0.990711
[15/20][300/469] train_loss: 0.000228 train_acc: 0.990968
[15/20][400/469] train_loss: 0.000216 train_acc: 0.991311
Clean dataset testing:[15/20] val_loss: 0.000238 val_acc: 0.989700
AT dataset testing:[15/20] val_loss: 0.169185 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000233 train_acc: 0.992188
[16/20][100/469] train_loss: 0.000197 train_acc: 0.991955
[16/20][200/469] train_loss: 0.000191 train_acc: 0.992576
[16/20][300/469] train_loss: 0.000186 train_acc: 0.992499
[16/20][400/469] train_loss: 0.000188 train_acc: 0.992324
Clean dataset testing:[16/20] val_loss: 0.000283 val_acc: 0.988700
AT dataset testing:[16/20] val_loss: 0.172576 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000028 train_acc: 1.000000
[17/20][100/469] train_loss: 0.000165 train_acc: 0.993735
[17/20][200/469] train_loss: 0.000171 train_acc: 0.993198
[17/20][300/469] train_loss: 0.000177 train_acc: 0.993122
[17/20][400/469] train_loss: 0.000187 train_acc: 0.992402
Clean dataset testing:[17/20] val_loss: 0.000312 val_acc: 0.987800
AT dataset testing:[17/20] val_loss: 0.174177 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000071 train_acc: 0.992188
[18/20][100/469] train_loss: 0.000167 train_acc: 0.993038
[18/20][200/469] train_loss: 0.000159 train_acc: 0.993898
[18/20][300/469] train_loss: 0.000171 train_acc: 0.993096
[18/20][400/469] train_loss: 0.000182 train_acc: 0.992382
Clean dataset testing:[18/20] val_loss: 0.000261 val_acc: 0.989000
AT dataset testing:[18/20] val_loss: 0.182813 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000048 train_acc: 1.000000
[19/20][100/469] train_loss: 0.000148 train_acc: 0.993889
[19/20][200/469] train_loss: 0.000153 train_acc: 0.993626
[19/20][300/469] train_loss: 0.000155 train_acc: 0.993459
[19/20][400/469] train_loss: 0.000162 train_acc: 0.993123
Clean dataset testing:[19/20] val_loss: 0.000254 val_acc: 0.989300
AT dataset testing:[19/20] val_loss: 0.187111 val_acc: 0.000000
nbits:8
quantilized:True
training data AT:False
all_conv_quan(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1))
  )
)
[0/20][0/469] train_loss: 0.018002 train_acc: 0.093750
[0/20][100/469] train_loss: 0.010539 train_acc: 0.610535
[0/20][200/469] train_loss: 0.006521 train_acc: 0.755675
[0/20][300/469] train_loss: 0.004920 train_acc: 0.814628
[0/20][400/469] train_loss: 0.004033 train_acc: 0.847082
Clean dataset testing:[0/20] val_loss: 0.001017 val_acc: 0.960200
AT dataset testing:[0/20] val_loss: 0.086464 val_acc: 0.000000
[1/20][0/469] train_loss: 0.000906 train_acc: 0.968750
[1/20][100/469] train_loss: 0.001050 train_acc: 0.957457
[1/20][200/469] train_loss: 0.000998 train_acc: 0.959538
[1/20][300/469] train_loss: 0.000967 train_acc: 0.961327
[1/20][400/469] train_loss: 0.000930 train_acc: 0.962379
Clean dataset testing:[1/20] val_loss: 0.000644 val_acc: 0.972300
AT dataset testing:[1/20] val_loss: 0.099689 val_acc: 0.000000
[2/20][0/469] train_loss: 0.000462 train_acc: 0.984375
[2/20][100/469] train_loss: 0.000754 train_acc: 0.967512
[2/20][200/469] train_loss: 0.000735 train_acc: 0.969488
[2/20][300/469] train_loss: 0.000703 train_acc: 0.971787
[2/20][400/469] train_loss: 0.000679 train_acc: 0.972549
Clean dataset testing:[2/20] val_loss: 0.000505 val_acc: 0.980000
AT dataset testing:[2/20] val_loss: 0.107989 val_acc: 0.000000
[3/20][0/469] train_loss: 0.000638 train_acc: 0.968750
[3/20][100/469] train_loss: 0.000522 train_acc: 0.977568
[3/20][200/469] train_loss: 0.000547 train_acc: 0.978117
[3/20][300/469] train_loss: 0.000548 train_acc: 0.977912
[3/20][400/469] train_loss: 0.000559 train_acc: 0.977887
Clean dataset testing:[3/20] val_loss: 0.000487 val_acc: 0.979300
AT dataset testing:[3/20] val_loss: 0.119962 val_acc: 0.000000
[4/20][0/469] train_loss: 0.000609 train_acc: 0.984375
[4/20][100/469] train_loss: 0.000463 train_acc: 0.980894
[4/20][200/469] train_loss: 0.000484 train_acc: 0.980527
[4/20][300/469] train_loss: 0.000473 train_acc: 0.980923
[4/20][400/469] train_loss: 0.000465 train_acc: 0.981453
Clean dataset testing:[4/20] val_loss: 0.000441 val_acc: 0.981400
AT dataset testing:[4/20] val_loss: 0.121004 val_acc: 0.000000
[5/20][0/469] train_loss: 0.000248 train_acc: 0.992188
[5/20][100/469] train_loss: 0.000415 train_acc: 0.983215
[5/20][200/469] train_loss: 0.000402 train_acc: 0.984064
[5/20][300/469] train_loss: 0.000403 train_acc: 0.984245
[5/20][400/469] train_loss: 0.000413 train_acc: 0.984083
Clean dataset testing:[5/20] val_loss: 0.000375 val_acc: 0.985200
AT dataset testing:[5/20] val_loss: 0.131059 val_acc: 0.000000
[6/20][0/469] train_loss: 0.000348 train_acc: 0.976562
[6/20][100/469] train_loss: 0.000360 train_acc: 0.986077
[6/20][200/469] train_loss: 0.000373 train_acc: 0.985347
[6/20][300/469] train_loss: 0.000389 train_acc: 0.984557
[6/20][400/469] train_loss: 0.000380 train_acc: 0.985018
Clean dataset testing:[6/20] val_loss: 0.000389 val_acc: 0.983100
AT dataset testing:[6/20] val_loss: 0.135484 val_acc: 0.000000
[7/20][0/469] train_loss: 0.000247 train_acc: 0.984375
[7/20][100/469] train_loss: 0.000329 train_acc: 0.986928
[7/20][200/469] train_loss: 0.000330 train_acc: 0.986863
[7/20][300/469] train_loss: 0.000356 train_acc: 0.985803
[7/20][400/469] train_loss: 0.000348 train_acc: 0.986265
Clean dataset testing:[7/20] val_loss: 0.000411 val_acc: 0.983400
AT dataset testing:[7/20] val_loss: 0.134445 val_acc: 0.000000
[8/20][0/469] train_loss: 0.000236 train_acc: 0.992188
[8/20][100/469] train_loss: 0.000326 train_acc: 0.986463
[8/20][200/469] train_loss: 0.000311 train_acc: 0.987290
[8/20][300/469] train_loss: 0.000315 train_acc: 0.986996
[8/20][400/469] train_loss: 0.000324 train_acc: 0.986830
Clean dataset testing:[8/20] val_loss: 0.000371 val_acc: 0.985200
AT dataset testing:[8/20] val_loss: 0.146277 val_acc: 0.000000
[9/20][0/469] train_loss: 0.000220 train_acc: 0.992188
[9/20][100/469] train_loss: 0.000268 train_acc: 0.988707
[9/20][200/469] train_loss: 0.000275 train_acc: 0.988884
[9/20][300/469] train_loss: 0.000290 train_acc: 0.988113
[9/20][400/469] train_loss: 0.000290 train_acc: 0.987960
Clean dataset testing:[9/20] val_loss: 0.000289 val_acc: 0.987500
AT dataset testing:[9/20] val_loss: 0.153932 val_acc: 0.000000
[10/20][0/469] train_loss: 0.000177 train_acc: 1.000000
[10/20][100/469] train_loss: 0.000307 train_acc: 0.987624
[10/20][200/469] train_loss: 0.000315 train_acc: 0.986863
[10/20][300/469] train_loss: 0.000291 train_acc: 0.988242
[10/20][400/469] train_loss: 0.000277 train_acc: 0.988817
Clean dataset testing:[10/20] val_loss: 0.000283 val_acc: 0.988300
AT dataset testing:[10/20] val_loss: 0.166158 val_acc: 0.000000
[11/20][0/469] train_loss: 0.000232 train_acc: 0.992188
[11/20][100/469] train_loss: 0.000274 train_acc: 0.989944
[11/20][200/469] train_loss: 0.000250 train_acc: 0.990089
[11/20][300/469] train_loss: 0.000259 train_acc: 0.989566
[11/20][400/469] train_loss: 0.000256 train_acc: 0.989830
Clean dataset testing:[11/20] val_loss: 0.000291 val_acc: 0.987300
AT dataset testing:[11/20] val_loss: 0.167784 val_acc: 0.000000
[12/20][0/469] train_loss: 0.000278 train_acc: 0.984375
[12/20][100/469] train_loss: 0.000212 train_acc: 0.991337
[12/20][200/469] train_loss: 0.000221 train_acc: 0.990633
[12/20][300/469] train_loss: 0.000234 train_acc: 0.990397
[12/20][400/469] train_loss: 0.000238 train_acc: 0.990064
Clean dataset testing:[12/20] val_loss: 0.000330 val_acc: 0.985900
AT dataset testing:[12/20] val_loss: 0.171878 val_acc: 0.000000
[13/20][0/469] train_loss: 0.000248 train_acc: 0.984375
[13/20][100/469] train_loss: 0.000206 train_acc: 0.991027
[13/20][200/469] train_loss: 0.000195 train_acc: 0.991915
[13/20][300/469] train_loss: 0.000204 train_acc: 0.991668
[13/20][400/469] train_loss: 0.000216 train_acc: 0.991291
Clean dataset testing:[13/20] val_loss: 0.000386 val_acc: 0.984700
AT dataset testing:[13/20] val_loss: 0.179747 val_acc: 0.000000
[14/20][0/469] train_loss: 0.000358 train_acc: 0.984375
[14/20][100/469] train_loss: 0.000202 train_acc: 0.991801
[14/20][200/469] train_loss: 0.000206 train_acc: 0.991760
[14/20][300/469] train_loss: 0.000203 train_acc: 0.991902
[14/20][400/469] train_loss: 0.000207 train_acc: 0.991681
Clean dataset testing:[14/20] val_loss: 0.000280 val_acc: 0.988500
AT dataset testing:[14/20] val_loss: 0.178337 val_acc: 0.000000
[15/20][0/469] train_loss: 0.000027 train_acc: 1.000000
[15/20][100/469] train_loss: 0.000189 train_acc: 0.992265
[15/20][200/469] train_loss: 0.000205 train_acc: 0.991449
[15/20][300/469] train_loss: 0.000208 train_acc: 0.991357
[15/20][400/469] train_loss: 0.000202 train_acc: 0.991720
Clean dataset testing:[15/20] val_loss: 0.000354 val_acc: 0.987000
AT dataset testing:[15/20] val_loss: 0.190721 val_acc: 0.000000
[16/20][0/469] train_loss: 0.000543 train_acc: 0.968750
[16/20][100/469] train_loss: 0.000194 train_acc: 0.990795
[16/20][200/469] train_loss: 0.000195 train_acc: 0.991449
[16/20][300/469] train_loss: 0.000193 train_acc: 0.991746
[16/20][400/469] train_loss: 0.000192 train_acc: 0.991934
Clean dataset testing:[16/20] val_loss: 0.000282 val_acc: 0.989500
AT dataset testing:[16/20] val_loss: 0.201367 val_acc: 0.000000
[17/20][0/469] train_loss: 0.000132 train_acc: 0.992188
[17/20][100/469] train_loss: 0.000215 train_acc: 0.991646
[17/20][200/469] train_loss: 0.000205 train_acc: 0.991954
[17/20][300/469] train_loss: 0.000196 train_acc: 0.992239
[17/20][400/469] train_loss: 0.000189 train_acc: 0.992421
Clean dataset testing:[17/20] val_loss: 0.000295 val_acc: 0.987900
AT dataset testing:[17/20] val_loss: 0.203277 val_acc: 0.000000
[18/20][0/469] train_loss: 0.000008 train_acc: 1.000000
[18/20][100/469] train_loss: 0.000169 train_acc: 0.993502
[18/20][200/469] train_loss: 0.000164 train_acc: 0.993354
[18/20][300/469] train_loss: 0.000168 train_acc: 0.993459
[18/20][400/469] train_loss: 0.000172 train_acc: 0.993220
Clean dataset testing:[18/20] val_loss: 0.000286 val_acc: 0.988900
AT dataset testing:[18/20] val_loss: 0.215948 val_acc: 0.000000
[19/20][0/469] train_loss: 0.000072 train_acc: 1.000000
[19/20][100/469] train_loss: 0.000171 train_acc: 0.993502
[19/20][200/469] train_loss: 0.000164 train_acc: 0.993548
[19/20][300/469] train_loss: 0.000168 train_acc: 0.993174
[19/20][400/469] train_loss: 0.000171 train_acc: 0.993006
Clean dataset testing:[19/20] val_loss: 0.000272 val_acc: 0.989600
AT dataset testing:[19/20] val_loss: 0.217341 val_acc: 0.000000
